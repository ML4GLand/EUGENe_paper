{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ray et al 2013 Extract-Transform-Load\n",
    "**Authorship:**\n",
    "Adam Klie, *08/11/2022*\n",
    "***\n",
    "**Description:**\n",
    "Notebook to extract, transform, and load (ETL) data from the Ray et al (2013) dataset.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if 'autoreload' not in get_ipython().extension_manager.loaded:\n",
    "    %load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import eugene as eu\n",
    "eu.settings.dataset_dir = \"/cellar/users/aklie/data/eugene\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and load in the dataset to a raw `SeqData` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load in the downloaded data, or download it if it's not there\n",
    "sdata_raw = eu.datasets.ray13()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Subset to set type (A -- training or B -- testing)\n",
    "sdata_setA_raw = sdata_raw[sdata_raw.seqs_annot[\"Probe_Set\"] == \"SetA\"]\n",
    "sdata_setB_raw = sdata_raw[sdata_raw.seqs_annot[\"Probe_Set\"] == \"SetB\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save raw versions of these three\n",
    "sdata_raw.write_h5sd(os.path.join(eu.settings.dataset_dir, eu.settings.dataset_dir, \"ray13\", \"norm_raw.h5sd\"))\n",
    "sdata_setA_raw.write_h5sd(os.path.join(eu.settings.dataset_dir, eu.settings.dataset_dir, \"ray13\", \"norm_setA_raw.h5sd\"))\n",
    "sdata_setB_raw.write_h5sd(os.path.join(eu.settings.dataset_dir, eu.settings.dataset_dir, \"ray13\", \"norm_setB_raw.h5sd\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the seqs\n",
    "- Padded elements of sequences are replaced with a one hot encoded value of 0.25 spanning each base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eu.pp.ohe_seqs_sdata(sdata_setA_raw, vocab=\"RNA\", seq_align=\"center\", fill_value=0.25)\n",
    "eu.pp.ohe_seqs_sdata(sdata_setB_raw, vocab=\"RNA\", seq_align=\"center\", fill_value=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the targets\n",
    "- The values of probe intensities are clamped at 99.95% percentile per binding protein to eliminate outliers and balance the data.\n",
    "- The probe intensities are normalized to a mean of 0 and a standard deviation of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get a list of only the target columns\n",
    "target_mask = sdata_setA_raw.seqs_annot.columns.str.contains(\"RNCMPT\")\n",
    "target_cols = sdata_setA_raw.seqs_annot.columns[target_mask]\n",
    "random_cols = np.random.choice(target_cols, 9)\n",
    "len(target_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split only those training sequences in SetA into train and validation sets\n",
    "eu.pp.train_test_split_sdata(sdata_setA_raw, train_key=\"train_val\", split=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the distribution of the targets\n",
    "eu.pl.violinplot(\n",
    "    sdata_setA_raw, \n",
    "    keys=random_cols\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Clamp the targets based on percentiles\n",
    "eu.pp.clamp_targets_sdata(sdata_setA_raw, percentile=0.9995, target_keys=target_cols, train_key=\"train_val\", store_clamp_nums=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check the distribution of the clamped targets\n",
    "sdata_setA_raw.seqs_annot[random_cols].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make sure they match up with stored values\n",
    "sdata_setA_raw.uns[\"clamp_nums\"][random_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the distribution of the clamped targets\n",
    "eu.pl.violinplot(\n",
    "    sdata_setA_raw, \n",
    "    keys=random_cols\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Scale the targets have mean 0 and variance 1\n",
    "eu.pp.scale_targets_sdata(sdata_setA_raw, target_keys=target_cols, train_key=\"train_val\", suffix=False, store_scaler=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check the distribution of the scaled targets, should be approximately normal but not exactly\n",
    "sdata_setA_raw.seqs_annot[target_cols].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the distribution of the scaled targets\n",
    "eu.pl.violinplot(\n",
    "    sdata_setA_raw, \n",
    "    keys=random_cols\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the test set\n",
    "- We need to apply the clamping numbers from the training set to the test set.\n",
    "- We need to apply the mean and standard deviation from the training set to the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Apply the same clamping to the test set\n",
    "eu.pp.clamp_targets_sdata(sdata_setB_raw, target_keys=target_cols, clamp_nums=sdata_setA_raw.uns[\"clamp_nums\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check the clamping\n",
    "sdata_setB_raw.seqs_annot[random_cols].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Apply the same scaling to the test set\n",
    "eu.pp.scale_targets_sdata(sdata_setB_raw, target_keys=target_cols, scaler=sdata_setA_raw.uns[\"scaler\"], suffix=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check the scaling\n",
    "sdata_setB_raw.seqs_annot[random_cols].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Take subset for testing, only for tests/use_cases/ray13\n",
    "sdata_setA_sub = sdata_setA_raw[:100]\n",
    "sdata_setB_sub = sdata_setB_raw[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the processed data\n",
    "sdata_setA_sub.write_h5sd(os.path.join(eu.settings.dataset_dir, eu.settings.dataset_dir, \"ray13\", \"norm_setA_sub_ST.h5sd\"))\n",
    "sdata_setB_sub.write_h5sd(os.path.join(eu.settings.dataset_dir, eu.settings.dataset_dir, \"ray13\", \"norm_setB_sub_ST.h5sd\"))\n",
    "sdata_setA_raw.write_h5sd(os.path.join(eu.settings.dataset_dir, eu.settings.dataset_dir, \"ray13\", \"norm_setA_processed_ST.h5sd\"))\n",
    "sdata_setB_raw.write_h5sd(os.path.join(eu.settings.dataset_dir, eu.settings.dataset_dir, \"ray13\", \"norm_setB_processed_ST.h5sd\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate multitask ready data\n",
    " - With single task training, we can just filter out NaNs and train on the remaining data.\n",
    " - We can't do this for multitask training, so we need to generate a separate `SeqData` object where there are no NaNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the columns that you would keep if you removed columns with a certain percentage of missing values\n",
    "nan_cutoff = 0.01\n",
    "nan_percents = sdata_setA_raw.seqs_annot[target_cols].isna().sum(axis=0).sort_values(ascending=False)/sdata_setA_raw.seqs_annot.shape[0]\n",
    "remove_cols = nan_percents[nan_percents > nan_cutoff].index\n",
    "keep_cols = target_cols.drop(remove_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make a copy of the training data and subset it to only the columns with < nan_cutoff missing values\n",
    "sdata_setA_MT = sdata_setA_raw.copy()\n",
    "sdata_setA_MT.seqs_annot = sdata_setA_MT.seqs_annot.drop(remove_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get rid of any sequences that have missing values in the remaining target columns\n",
    "keep_rows = np.where(sdata_setA_MT.seqs_annot[keep_cols].isna().sum(axis=1) == 0)[0]\n",
    "sdata_setA_MT = sdata_setA_MT[keep_rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We also need to remove the columns from the Set B object, but we don't need to remove any rows since we can just ignore those in the evaluation stage\n",
    "sdata_setB_MT = sdata_setB_raw.copy()\n",
    "sdata_setB_MT.seqs_annot = sdata_setB_MT.seqs_annot.drop(remove_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Double check that the shapes make sense (Set A object has 2 extra columns, one set and one for train/val split. Set B object has 1 extra column, jus the set)\n",
    "sdata_setA_MT.seqs_annot.shape, sdata_setB_MT.seqs_annot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check if copy worked\n",
    "sdata_setA_raw.seqs_annot.shape, sdata_setB_raw.seqs_annot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Doubke check that there are no missing values in the remaining columns\n",
    "sdata_setA_MT.seqs_annot[keep_cols].isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Take subset for testing\n",
    "sdata_setA_MT_sub = sdata_setA_MT[:100]\n",
    "sdata_setB_MT_sub = sdata_setB_MT[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sdata_setA_MT_sub.write_h5sd(os.path.join(eu.settings.dataset_dir, eu.settings.dataset_dir, \"ray13\", \"norm_setA_sub_MT.h5sd\"))\n",
    "sdata_setB_MT_sub.write_h5sd(os.path.join(eu.settings.dataset_dir, eu.settings.dataset_dir, \"ray13\", \"norm_setB_sub_MT.h5sd\"))\n",
    "sdata_setA_MT.write_h5sd(os.path.join(eu.settings.dataset_dir, eu.settings.dataset_dir, \"ray13\", \"norm_setA_processed_MT.h5sd\"))\n",
    "sdata_setB_MT.write_h5sd(os.path.join(eu.settings.dataset_dir, eu.settings.dataset_dir, \"ray13\", \"norm_setB_processed_MT.h5sd\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating a presence/absence matrix per probe\n",
    "- We need to generate a presence/absence matrix per probe to use for evaluation\n",
    "    - This presence/absence matrix is a binary matrix where the rows are all possible k-mers and the columns are probes.\n",
    "    - The value of a cell is 1 if the k-mer is present in that probe and 0 otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note**\n",
    "> Each one of these matrices takes about 15 minutes to generate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Helper function to generate a presence/absence matrix\n",
    "from eugene.evaluate.utils import generate_all_possible_kmers, kmer_in_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate all possible 7-mers and check\n",
    "a_probes = pd.Series(sdata_setA_raw.seqs)\n",
    "a_probes_MT = pd.Series(sdata_setA_MT.seqs)\n",
    "b_probes = pd.Series(sdata_setB_raw.seqs)\n",
    "kmers = generate_all_possible_kmers(n=7, alphabet=\"ACGU\")\n",
    "len(a_probes), len(a_probes_MT), len(b_probes), len(kmers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate the Set A presence/absence matrix\n",
    "a_hits = np.array([a_probes.str.contains(kmer).astype(int).values for i, kmer in tqdm(enumerate(kmers), desc=\"Searching for kmers in probes\", total=len(kmers))])\n",
    "np.save(os.path.join(eu.settings.dataset_dir, \"ray13\", \"setA_binary_ST\"), a_hits)\n",
    "a_hits.shape, np.all((a_hits == 1).sum(axis=1) >= 155)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the Set A presence/absence matrix\n",
    "a_hits_MT = np.array([a_probes_MT.str.contains(kmer).astype(int).values for i, kmer in tqdm(enumerate(kmers), desc=\"Searching for kmers in probes\", total=len(kmers))])\n",
    "np.save(os.path.join(eu.settings.dataset_dir, \"ray13\", \"setA_binary_MT\"), a_hits)\n",
    "a_hits_MT.shape, np.all((a_hits_MT == 1).sum(axis=1) >= 155)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate the Set B presence/absence matrix\n",
    "b_hits = np.array([b_probes.str.contains(kmer).astype(int).values for i, kmer in tqdm(enumerate(kmers), desc=\"Searching for kmers in probes\", total=len(kmers))])\n",
    "np.save(os.path.join(eu.settings.dataset_dir, \"ray13\", \"setB_binary\"), b_hits)\n",
    "b_hits.shape,  np.all((b_hits == 1).sum(axis=1) >= 155)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 eugene_dev",
   "language": "python",
   "name": "eugene_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
