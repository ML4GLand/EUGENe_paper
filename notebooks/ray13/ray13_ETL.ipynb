{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ray et al 2013 Extract-Transform-Load\n",
    "**Authorship:**\n",
    "Adam Klie (last updated: *06/08/2023*)\n",
    "***\n",
    "**Description:**\n",
    "Notebook to extract, transform, and load (ETL) data from the Ray et al (2013) dataset.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# General imports\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# EUGENe imports\n",
    "import eugene as eu\n",
    "from eugene import preprocess as pp\n",
    "from eugene import plot as pl\n",
    "from eugene import settings\n",
    "settings.dataset_dir = \"/cellar/users/aklie/data/eugene/revision/ray13\"\n",
    "\n",
    "# EUGENe packages\n",
    "import seqdatasets\n",
    "import seqdata as sd\n",
    "import seqpro as sp\n",
    "\n",
    "# Print versions\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"Xarray version: {xr.__version__}\")\n",
    "print(f\"Eugene version: {eu.__version__}\")\n",
    "print(f\"SeqDatasets version: {seqdatasets.__version__}\")\n",
    "print(f\"SeqData version: {sd.__version__}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and load in the dataset to a raw `SeqData` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load in the downloaded data, or download it if it's not there\n",
    "sdata = sd.open_zarr(os.path.join(settings.dataset_dir, \"ray13_norm.zarr\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load auxiliary data as well\n",
    "# wget https://hugheslab.ccbr.utoronto.ca/supplementary-data/RNAcompete_eukarya/z_scores.txt.gz -O /cellar/users/aklie/data/eugene/revision/ray13/z_scores.txt.gz\n",
    "# wget https://hugheslab.ccbr.utoronto.ca/supplementary-data/RNAcompete_eukarya/e_scores.txt.gz -O /cellar/users/aklie/data/eugene/revision/ray13/e_scores.txt.gz\n",
    "# wget https://hugheslab.ccbr.utoronto.ca/supplementary-data/RNAcompete_eukarya/hg19_motif_hits.tar.gz -O /cellar/users/aklie/data/eugene/revision/ray13/hg19_motif_hits.tar.gz\n",
    "# tar -xvzf cellar/users/aklie/data/eugene/revision/ray13/hg19_motif_hits.tar.gz -C /cellar/users/aklie/data/eugene/revision/ray13/\n",
    "# wget https://static-content.springer.com/esm/art%3A10.1038%2Fnbt.3300/MediaObjects/41587_2015_BFnbt3300_MOESM53_ESM.xlsx -O /cellar/users/aklie/data/eugene/revision/ray13/41587_2015_BFnbt3300_MOESM53_ESM.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of only the target columns\n",
    "column_vars = pd.Index(sdata.data_vars.keys())\n",
    "target_mask = column_vars.str.contains(\"RNCMPT\")\n",
    "target_cols = column_vars[target_mask]\n",
    "random_idxs = np.random.choice(np.arange(len(target_cols)), size=9, replace=False)\n",
    "random_cols = target_cols[random_idxs]\n",
    "len(target_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset to set type (A -- training or B -- testing)\n",
    "sdata_setA = sdata.sel(_sequence=sdata[\"Probe_Set\"].compute() == \"SetA\")\n",
    "sdata_setB = sdata.sel(_sequence=sdata[\"Probe_Set\"].compute() == \"SetB\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the training set"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the seqs\n",
    "- Padded elements of sequences are replaced with a one hot encoded value of 0.25 spanning each base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Max seq len: {np.max(sp.length(sdata['seq'].values))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad sequences to max length with Ns\n",
    "pp.pad_seqs_sdata(sdata_setA, length=41, seq_var=\"seq\", pad=\"both\", pad_value=\"N\")\n",
    "pp.pad_seqs_sdata(sdata_setB, length=41, seq_var=\"seq\", pad=\"both\", pad_value=\"N\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode sequences and add fill value\n",
    "pp.ohe_seqs_sdata(sdata_setA, alphabet=\"RNA\", seq_var=\"seq_padded\", fill_value=0.25)\n",
    "pp.ohe_seqs_sdata(sdata_setB, alphabet=\"RNA\", seq_var=\"seq_padded\", fill_value=0.25)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the targets\n",
    "- The values of probe intensities are clamped at 99.95% percentile per binding protein to eliminate outliers and balance the data.\n",
    "- The probe intensities are normalized to a mean of 0 and a standard deviation of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split only those training sequences in SetA into train and validation sets\n",
    "pp.train_test_random_split(sdata_setA, \"_sequence\", test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the distribution of the targets\n",
    "pl.violinplot(\n",
    "    sdata_setA, \n",
    "    vars=random_cols\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Clamp the targets based on percentiles\n",
    "pp.clamp_targets_sdata(sdata_setA, target_vars=target_cols, percentile=0.9995, train_var=\"train_val\", store_clamp_nums=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check the distribution of the clamped targets\n",
    "sdata_setA[random_cols].to_dataframe().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make sure they match up with stored values\n",
    "sdata_setA[\"clamp_nums\"][random_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the distribution of the clamped targets\n",
    "pl.violinplot(\n",
    "    sdata_setA, \n",
    "    vars=random_cols\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Scale the targets have mean 0 and variance 1\n",
    "scaler = pp.scale_targets_sdata(sdata_setA, target_vars=target_cols, train_var=\"train_val\", return_scaler=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check the distribution of the scaled targets, should be approximately normal but not exactly\n",
    "sdata_setA[random_cols].to_dataframe().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the distribution of the scaled targets\n",
    "pl.violinplot(\n",
    "    sdata_setA, \n",
    "    vars=random_cols\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the test set\n",
    "- We need to apply the clamping numbers from the training set to the test set.\n",
    "- We need to apply the mean and standard deviation from the training set to the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Apply the same clamping to the test set\n",
    "pp.clamp_targets_sdata(sdata_setB, target_vars=target_cols, clamp_nums=sdata_setA[\"clamp_nums\"].to_series())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check the clamping\n",
    "sdata_setB[random_cols].to_dataframe().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Apply the same scaling to the test set\n",
    "pp.scale_targets_sdata(sdata_setB, target_vars=target_cols, scaler=scaler, suffix=False, return_scaler=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check the scaling\n",
    "sdata_setB[random_cols].to_dataframe().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Take subset for testing, only for tests/use_cases/ray13\n",
    "sdata_setA_sub = sdata_setA.isel(_sequence=slice(100))\n",
    "sdata_setB_sub = sdata_setB.isel(_sequence=slice(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the processed data\n",
    "sd.to_zarr(sdata_setA_sub, os.path.join(settings.dataset_dir, \"ray13\", \"norm_setA_sub_ST.zarr\"), mode=\"w\")\n",
    "sd.to_zarr(sdata_setB_sub, os.path.join(settings.dataset_dir, \"ray13\", \"norm_setB_sub_ST.zarr\"), mode=\"w\")\n",
    "sd.to_zarr(sdata_setA, os.path.join(settings.dataset_dir, \"ray13\", \"norm_setA_ST.zarr\"), mode=\"w\")\n",
    "sd.to_zarr(sdata_setB, os.path.join(settings.dataset_dir, \"ray13\", \"norm_setB_ST.zarr\"), mode=\"w\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate multitask ready data\n",
    " - With single task training, we can just filter out NaNs and train on the remaining data.\n",
    " - We can't do this for multitask training, so we need to generate a separate `SeqData` object where there are no NaNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the columns that you would keep if you removed columns with a certain percentage of missing values\n",
    "nan_cutoff = 0.01\n",
    "nan_percents = sdata[target_cols].to_dataframe().isna().sum(axis=0).sort_values(ascending=False)/sdata.dims[\"_sequence\"]\n",
    "remove_cols = nan_percents[nan_percents > nan_cutoff].index\n",
    "keep_cols = target_cols.drop(remove_cols)\n",
    "len(keep_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make a copy of the training data and subset it to only the columns with < nan_cutoff missing values\n",
    "sdata_setA_MT = sdata_setA.copy()\n",
    "sdata_setA_MT = sdata_setA_MT.drop(list(remove_cols) + [\"_targets\", \"clamp_nums\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get rid of any sequences that have missing values in the remaining target columns\n",
    "keep_rows = np.where(sdata_setA_MT[keep_cols].to_dataframe().isna().sum(axis=1) == 0)[0]\n",
    "sdata_setA_MT = sdata_setA_MT.isel(_sequence=keep_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We also need to remove the columns from the Set B object, but we don't need to remove any rows since we can just ignore those in the evaluation stage\n",
    "sdata_setB_MT = sdata_setB.copy()\n",
    "sdata_setB_MT = sdata_setB_MT.drop(list(remove_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Double check that the shapes make sense (Set A object has 2 extra columns, one set and one for train/val split. Set B object has 1 extra column, jus the set)\n",
    "(sdata_setA_MT.dims[\"_sequence\"], len(sdata_setA_MT.data_vars)), (sdata_setB_MT.dims[\"_sequence\"], len(sdata_setB_MT.data_vars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check if copy worked\n",
    "(sdata_setA.dims[\"_sequence\"], len(sdata_setA.data_vars)), (sdata_setB.dims[\"_sequence\"], len(sdata_setB.data_vars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Doubke check that there are no missing values in the remaining columns\n",
    "sdata_setA_MT[keep_cols].to_dataframe().isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Take subset for testing\n",
    "sdata_setA_MT_sub = sdata_setA_MT.isel(_sequence=slice(100))\n",
    "sdata_setB_MT_sub = sdata_setB_MT.isel(_sequence=slice(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the processed data\n",
    "sd.to_zarr(sdata_setA_MT_sub, os.path.join(settings.dataset_dir, \"ray13\", \"norm_setA_sub_MT.zarr\"), mode=\"w\")\n",
    "sd.to_zarr(sdata_setB_MT_sub, os.path.join(settings.dataset_dir, \"ray13\", \"norm_setB_sub_MT.zarr\"), mode=\"w\")\n",
    "sd.to_zarr(sdata_setA_MT, os.path.join(settings.dataset_dir, \"ray13\", \"norm_setA_MT.zarr\"), mode=\"w\")\n",
    "sd.to_zarr(sdata_setB_MT, os.path.join(settings.dataset_dir, \"ray13\", \"norm_setB_MT.zarr\"), mode=\"w\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating a presence/absence matrix per probe\n",
    "- We need to generate a presence/absence matrix per probe to use for evaluation\n",
    "    - This presence/absence matrix is a binary matrix where the rows are all possible k-mers and the columns are probes.\n",
    "    - The value of a cell is 1 if the k-mer is present in that probe and 0 otherwise."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note**\n",
    "> Each one of these matrices takes about 15 minutes to generate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Helper function to generate a presence/absence matrix\n",
    "from ray13_helpers import generate_all_possible_kmers, kmer_in_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate all possible 7-mers and check\n",
    "a_probes = pd.Series(sdata_setA[\"seq\"].to_series())\n",
    "a_probes_MT = pd.Series(sdata_setA_MT[\"seq\"].to_series())\n",
    "b_probes = pd.Series(sdata_setB[\"seq\"].to_series())\n",
    "kmers = generate_all_possible_kmers(n=7, alphabet=\"ACGU\")\n",
    "len(a_probes), len(a_probes_MT), len(b_probes), len(kmers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate the Set A presence/absence matrix\n",
    "a_hits = np.array([a_probes.str.contains(kmer).astype(int).values for i, kmer in tqdm(enumerate(kmers), desc=\"Searching for kmers in probes\", total=len(kmers))])\n",
    "np.save(os.path.join(eu.settings.dataset_dir, \"ray13\", \"setA_binary_ST\"), a_hits)\n",
    "a_hits.shape, np.all((a_hits == 1).sum(axis=1) >= 155)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the Set A presence/absence matrix\n",
    "a_hits_MT = np.array([a_probes_MT.str.contains(kmer).astype(int).values for i, kmer in tqdm(enumerate(kmers), desc=\"Searching for kmers in probes\", total=len(kmers))])\n",
    "np.save(os.path.join(eu.settings.dataset_dir, \"ray13\", \"setA_binary_MT\"), a_hits)\n",
    "a_hits_MT.shape, np.all((a_hits_MT == 1).sum(axis=1) >= 155)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate the Set B presence/absence matrix\n",
    "b_hits = np.array([b_probes.str.contains(kmer).astype(int).values for i, kmer in tqdm(enumerate(kmers), desc=\"Searching for kmers in probes\", total=len(kmers))])\n",
    "np.save(os.path.join(eu.settings.dataset_dir, \"ray13\", \"setB_binary\"), b_hits)\n",
    "b_hits.shape,  np.all((b_hits == 1).sum(axis=1) >= 155)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DONE!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings.dataset_dir = \"/cellar/users/aklie/data/eugene/revision/ray13\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for zarr in [\"norm_setA_sub_MT.zarr\", \"norm_setB_sub_MT.zarr\", \"norm_setA_MT.zarr\", \"norm_setB_MT.zarr\"]:\n",
    "    sdata = sd.open_zarr(os.path.join(settings.dataset_dir, zarr))\n",
    "    print(zarr, sdata.dims[\"_sequence\"], len(sdata.data_vars))\n",
    "    if \"train_val\" in sdata.data_vars:\n",
    "        print(np.unique(sdata[\"train_val\"].values, return_counts=True))\n",
    "    else:\n",
    "        print(\"No train_val column found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for zarr in [\"norm_setA_sub_ST.zarr\", \"norm_setB_sub_ST.zarr\", \"norm_setA_ST.zarr\", \"norm_setB_ST.zarr\"]:\n",
    "    sdata = sd.open_zarr(os.path.join(settings.dataset_dir, zarr))\n",
    "    print(zarr, sdata.dims[\"_sequence\"], len(sdata.data_vars))\n",
    "    if \"train_val\" in sdata.data_vars:\n",
    "        print(np.unique(sdata[\"train_val\"].values, return_counts=True))\n",
    "    else:\n",
    "        print(\"No train_val column found\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 ml4gland",
   "language": "python",
   "name": "ml4gland"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
