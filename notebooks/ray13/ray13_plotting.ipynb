{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ray et al 2013 Plotting \n",
    "**Authorship:**\n",
    "Adam Klie, *09/03/2022*\n",
    "***\n",
    "**Description:**\n",
    "Notebook to generate plots for the Ray et al (2013) dataset that are not included in the other notebooks.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if 'autoreload' not in get_ipython().extension_manager.loaded:\n",
    "    %load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import glob\n",
    "from tqdm.auto import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import eugene as eu\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eu.settings.dpi = 300\n",
    "eu.settings.dataset_dir = \"/cellar/users/aklie/data/eugene/ray13\"\n",
    "eu.settings.output_dir = \"/cellar/users/aklie/projects/EUGENe/EUGENe_paper/output/ray13\"\n",
    "eu.settings.logging_dir = \"/cellar/users/aklie/projects/EUGENe/EUGENe_paper/logs/ray13\"\n",
    "eu.settings.config_dir = \"/cellar/users/aklie/projects/EUGENe/EUGENe_paper/configs/ray13\"\n",
    "eu.settings.figure_dir = \"/cellar/users/aklie/projects/EUGENe/EUGENe_paper/figures/ray13\"\n",
    "eu.settings.verbosity = logging.ERROR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performances from Alipanahi et al\n",
    "Downloaded and will load in Supllementary Table 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read in the results from the ray13 analysis\n",
    "sheet_name = [\"Pearson of E-scores\",\n",
    "              \"Spearman of E-scores\",\n",
    "              \"Pearson of AUCs\",\n",
    "              \"Spearman of AUCs\",\n",
    "              \"Pearson of Z-scores\",\n",
    "              \"Spearman of Z-scores\",\n",
    "              \"Pearson with Intensities\",\n",
    "              \"Spearman with intensities\"]\n",
    "performance_df = pd.DataFrame()\n",
    "for sheet in sheet_name:\n",
    "    x = pd.read_excel(os.path.join(eu.settings.dataset_dir, \"41587_2015_BFnbt3300_MOESM53_ESM.xlsx\"), sheet_name=sheet, skiprows=1, index_col=0)\n",
    "    x[\"Metric\"] = sheet.split(\" \")[2]\n",
    "    x[\"Correlation\"] = sheet.split(\" \")[0]\n",
    "    x[\"Metric\"] = x[\"Metric\"].replace({\"intensities\": \"Intensities\"})\n",
    "    x = x.rename({\"Intensities\": \"Observed intensities\", \"MatrixREDUE\": \"MatrixREDUCE\"}, axis=1)\n",
    "    performance_df = pd.concat([performance_df, x], axis=0)\n",
    "performance_summary = performance_df.melt(id_vars=[\"Correlation\", \"Metric\"], var_name=\"Method\", value_name=\"Value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot similar to Supplementary Figure 3 in Alipahani et al\n",
    "my_pal = {\"Ray et al.\": \"dimgrey\", \"MatrixREDUCE\": \"lightgrey\", \"DeepBind\": \"red\", \"Observed intensities\": \"white\"}\n",
    "order = [\"Observed intensities\", \"DeepBind\", \"MatrixREDUCE\", \"Ray et al.\"]\n",
    "g = sns.FacetGrid(\n",
    "    performance_summary, \n",
    "    row=\"Correlation\", \n",
    "    col=\"Metric\", \n",
    "    row_order=[\"Pearson\", \"Spearman\"], \n",
    "    col_order=[\"E-scores\", \n",
    "               \"Z-scores\", \n",
    "               \"AUCs\", \n",
    "               \"Intensities\"],\n",
    "    height=6,\n",
    "    aspect=0.66\n",
    ")\n",
    "g.map(sns.boxplot, \"Method\", \"Value\", palette=my_pal, order=order, showfliers = False)\n",
    "patches = [matplotlib.patches.Patch(color=v, label=k, edgecolor=\"k\", linewidth=3) for k,v in my_pal.items()]\n",
    "plt.legend(handles=patches)\n",
    "g.set(xticks=[])\n",
    "g.fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performances from EUGENe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load in the long tables that calculated all 4 metrics for all 244 RBPs (Pearson and Spearman)\n",
    "n_kmers = None\n",
    "pearson_long = pd.DataFrame()\n",
    "spearman_long = pd.DataFrame()\n",
    "for method in [\"setA\", \"ST\", \"MT\", \"kipoi\"]:\n",
    "    print(f\"spearman/pearson_performance_{n_kmers}kmers_{method}.tsv\")\n",
    "    x_pearson = pd.read_csv(os.path.join(eu.settings.output_dir, f\"pearson_performance_{n_kmers}kmers_{method}.tsv\"), sep=\"\\t\")\n",
    "    pearson_long = pd.concat([pearson_long, x_pearson], axis=0)\n",
    "    x_spearman = pd.read_csv(os.path.join(eu.settings.output_dir, f\"spearman_performance_{n_kmers}kmers_{method}.tsv\"), sep=\"\\t\")\n",
    "    spearman_long = pd.concat([spearman_long, x_spearman], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert my performances into the same format as the paper table above\n",
    "spearman_df = spearman_long.pivot(index=['RBP', 'Metric'], columns='Model', values='Spearman').reset_index()\n",
    "spearman_df[\"Correlation\"] = \"Spearman\"\n",
    "pearson_df = pearson_long.pivot(index=['RBP', 'Metric'], columns='Model', values='Pearson').reset_index()\n",
    "pearson_df[\"Correlation\"] = \"Pearson\"\n",
    "trained_perfromance_df = pd.concat([pearson_df, spearman_df], axis=0)\n",
    "trained_perfromance_df[\"Metric\"] = trained_perfromance_df[\"Metric\"].replace({\"Z-score\":\"Z-scores\", \"AUC\":\"AUCs\", \"E-score\":\"E-scores\", \"Intensity\": \"Intensities\"})\n",
    "trained_perfromance_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Harmonize the paper table\n",
    "paper_performance_df = performance_df.reset_index().rename({\"index\": \"RBP\"}, axis=1)\n",
    "paper_performance_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make sure they have the same length\n",
    "len(paper_performance_df), len(trained_perfromance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the aggregated table\n",
    "full_performance_df = pd.merge(trained_perfromance_df, paper_performance_df, on=[\"RBP\", \"Metric\", \"Correlation\"]).set_index(\"RBP\")\n",
    "full_performance_summary = full_performance_df.melt(id_vars=[\"Correlation\", \"Metric\"], var_name=\"Method\", value_name=\"Value\")\n",
    "full_performance_summary[\"Method\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the full table results for supplement\n",
    "full_performance_df.to_csv(os.path.join(eu.settings.output_dir, \"full_performance_df.tsv\"), sep=\"\\t\", index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_pal = {\"Ray et al.\": \"dimgrey\", \"MatrixREDUCE\": \"lightgrey\", \"DeepBind\": \"red\", \"Observed intensities\": \"white\",\n",
    "         \"SetA\": \"lightcoral\", \"SingleTask\": \"forestgreen\", \"MultiTask\": \"navy\", \"Kipoi\": \"goldenrod\"}\n",
    "order = [\"Observed intensities\", \"DeepBind\", \"SetA\", \"SingleTask\", \"MultiTask\", \"Kipoi\", \"MatrixREDUCE\", \"Ray et al.\"]\n",
    "g = sns.FacetGrid(\n",
    "    full_performance_summary, \n",
    "    row=\"Correlation\", \n",
    "    col=\"Metric\", \n",
    "    row_order=[\"Pearson\", \"Spearman\"], \n",
    "    col_order=[\"E-scores\", \n",
    "               \"Z-scores\", \n",
    "               \"AUCs\", \n",
    "               \"Intensities\"],\n",
    "    height=6,\n",
    "    aspect=0.66\n",
    ")\n",
    "g.map(sns.boxplot, \"Method\", \"Value\", palette=my_pal, order=order, showfliers = False)\n",
    "patches = [matplotlib.patches.Patch(color=v, label=k, edgecolor=\"k\", linewidth=3) for k,v in my_pal.items()]\n",
    "g.set(xticks=[])\n",
    "g.fig.tight_layout()\n",
    "plt.legend(handles=patches, loc='upper right', bbox_to_anchor=(1.2, 1))\n",
    "plt.savefig(os.path.join(eu.settings.figure_dir, f\"correlation_boxplots_{n_kmers}kmers_all.pdf\"), dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison scatterplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Helper function to plot the a line to apply to FacetGrid\n",
    "def const_line(*args, **kwargs):\n",
    "    x = np.arange(0, 1.01, 0.01)\n",
    "    plt.plot(x, x, c='dimgrey', ls='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "order = [\"SingleTask\", \"MultiTask\", \"SetA\", \"Kipoi\", \"Observed intensities\", \"DeepBind\",  \"MatrixREDUCE\", \"Ray et al.\"]\n",
    "for method_x, method_y in list(itertools.combinations(order, 2)):\n",
    "    g = sns.FacetGrid(full_performance_df, col=\"Metric\", col_order=[\"Z-scores\", \"AUCs\", \"E-scores\", \"Intensities\"])\n",
    "    g.map(sns.scatterplot, method_x, method_y, s=10, color=\"royalblue\", alpha=0.75, edgecolor=\"k\", linewidth=0.3)\n",
    "    g.map(const_line)\n",
    "    method_x_save = method_x.replace(\" \", \"-\").split(\".\")[0]\n",
    "    method_y_save = method_y.replace(\" \", \"-\").split(\".\")[0]\n",
    "    plt.savefig(os.path.join(eu.settings.figure_dir, \"scatterplot_comparisons\", f\"model_pearson_scatterplot_comparisons_{n_kmers}kmers_{method_x_save}_{method_y_save}.pdf\"), dpi=300)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best model intensity correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Grab these for generating interpetations on a subset\n",
    "intensity_df = trained_perfromance_df[trained_perfromance_df[\"Metric\"] == \"Intensities\"].set_index(\"RBP\")\n",
    "intensity_df[\"SingleTask\"].sort_values(ascending=False)[:10].to_csv(os.path.join(eu.settings.output_dir, \"top_10_ST_intensities.tsv\"), sep=\"\\t\")\n",
    "intensity_df[\"MultiTask\"].sort_values(ascending=False)[:10].to_csv(os.path.join(eu.settings.output_dir, \"top_10_MT_intensities.tsv\"), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TomTom Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the signficant single task filter annotations for a given RBP\n",
    "rbp = \"RNCMPT00238\"\n",
    "single_res = pd.read_csv(os.path.join(eu.settings.output_dir, f\"{rbp}_filters_0.75_ST_tomtom.tsv\"), sep=\"\\t\", index_col=0)\n",
    "single_res_sig = single_res[single_res[\"q-value\"] < 0.05].sort_values(\"q-value\")\n",
    "single_res_sig[single_res_sig[\"Target_ID\"] == rbp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get signficant single task filter annotations and print for given RBP\n",
    "multi_res = pd.read_csv(os.path.join(eu.settings.output_dir, \"filters_0.75_MT_tomtom.tsv\"), sep=\"\\t\", comment=\"#\")\n",
    "multi_res_sig = multi_res[multi_res[\"q-value\"] < 0.05].sort_values(\"q-value\")\n",
    "multi_res_sig[multi_res_sig[\"Target_ID\"] == \"RNCMPT00238\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a dataframe that relates performance to number of annotated filters assigned to that RBP\n",
    "intensity_df = trained_perfromance_df[trained_perfromance_df[\"Correlation\"] == \"Pearson\"].reset_index()\n",
    "intensity_df = intensity_df[intensity_df [\"Metric\"] == \"Z-scores\"].reset_index()\n",
    "mt_intensity = intensity_df.set_index(\"RBP\")[\"MultiTask\"]\n",
    "filter_val_counts = pd.DataFrame(multi_res_sig.value_counts(\"Target_ID\")).astype(int)\n",
    "filter_val_counts.columns = [\"num_sig_filters\"]\n",
    "df = pd.concat([mt_intensity, filter_val_counts], axis=1).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot this relationship and output a correlation\n",
    "fig, ax = plt.subplots(figsize=(5, 2))\n",
    "sns.stripplot(data=df, x=\"num_sig_filters\", y=\"MultiTask\", color=\"royalblue\", alpha=0.75, edgecolor=\"k\", linewidth=0.3)\n",
    "plt.savefig(os.path.join(eu.settings.figure_dir, \"num_sig_filters_vs_MT_intensity.pdf\"), dpi=300)\n",
    "spearmanr(df[\"MultiTask\"], df[\"num_sig_filters\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate a merged TomTom results df for the supplement\n",
    "merged_df = pd.DataFrame()\n",
    "for file in sorted(glob.glob(os.path.join(eu.settings.output_dir, \"*0.75*_tomtom.tsv\"))):\n",
    "    name = file.split(\"/\")[-1].split(\"_\")[0]\n",
    "    if name == \"filters\":\n",
    "        name = \"multitask\"\n",
    "    x[\"model\"] = name\n",
    "    x = pd.read_csv(file, comment=\"#\", sep=\"\\t\")\n",
    "    merged_df = pd.concat([merged_df, x])\n",
    "merged_df.to_csv(os.path.join(eu.settings.output_dir, \"all_0.75_tomtom.tsv\"), index=False, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the PFMs in a SeqData\n",
    "sdata_test = eu.dl.read_h5sd(os.path.join(eu.settings.output_dir, \"norm_test_predictions_and_intepretations_noMTfilters_0.75.h5sd\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eu.pl.multifilter_viz(\n",
    "    sdata_test,\n",
    "    filter_ids=range(0,32),\n",
    "    uns_key=f\"pfms_{rbp}_ST\",\n",
    "    titles=[f\"filter {i}\" for i in range(32)],\n",
    "    vocab=\"RNA\",\n",
    "    num_rows=8,\n",
    "    num_cols=4,\n",
    "    save=os.path.join(eu.settings.figure_dir, \"filter_viz\", f\"filters_viz_{rbp}_0.75_ST.pdf\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 eugene_dev",
   "language": "python",
   "name": "eugene_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "f0aab14ae665ca4264878e5867720697752ca4d3a67458798aa51c276bf829a9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
