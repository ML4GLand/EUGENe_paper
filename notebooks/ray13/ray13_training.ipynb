{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ray et al 2013 Training \n",
    "**Authorship:**\n",
    "Adam Klie (last updated: *06/08/2023*)\n",
    "***\n",
    "**Description:**\n",
    "Notebook to perform simple training of *single task* and *multitask* models on the Ray et al (2013) dataset.\n",
    "Also take a look at the `ray13_training_ST.py` script for usage. The script was run because all 244 models took several hours to train.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.9.16 | packaged by conda-forge | (main, Feb  1 2023, 21:39:03) \n",
      "[GCC 11.3.0]\n",
      "NumPy version: 1.23.5\n",
      "Pandas version: 1.5.2\n",
      "Eugene version: 0.0.8\n",
      "SeqData version: 0.0.1\n",
      "PyTorch version: 2.0.0\n",
      "PyTorch Lightning version: 2.0.0\n"
     ]
    }
   ],
   "source": [
    "# General imports\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning\n",
    "\n",
    "# EUGENe imports and settings\n",
    "import eugene as eu\n",
    "from eugene import models, train, evaluate, settings\n",
    "from eugene.models import zoo\n",
    "settings.dataset_dir = \"/cellar/users/aklie/data/eugene/revision/ray13\"\n",
    "settings.output_dir = \"/cellar/users/aklie/projects/ML4GLand/EUGENe_paper/output/revision/ray13\"\n",
    "settings.logging_dir = \"/cellar/users/aklie/projects/ML4GLand/EUGENe_paper/logs/revision/ray13\"\n",
    "settings.config_dir = \"/cellar/users/aklie/projects/ML4GLand/EUGENe_paper/configs/ray13\"\n",
    "\n",
    "# EUGENe packages\n",
    "import seqdata as sd\n",
    "\n",
    "# Print versions\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"Eugene version: {eu.__version__}\")\n",
    "print(f\"SeqData version: {sd.__version__}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"PyTorch Lightning version: {pytorch_lightning.__version__}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load in the SetA training `SeqData`'s for single task and multi-task models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the training SetA processed data for single task and multitask models\n",
    "sdata_training_ST = sd.open_zarr(os.path.join(settings.dataset_dir, \"norm_setA_ST.zarr\"))\n",
    "sdata_training_MT = sd.open_zarr(os.path.join(settings.dataset_dir, \"norm_setA_MT.zarr\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Grab the prediction columns for single task and multitask\n",
    "ST_keys = pd.Index(sdata_training_ST.data_vars.keys())\n",
    "target_mask_ST = ST_keys.str.contains(\"RNCMPT\")\n",
    "target_cols_ST = ST_keys[target_mask_ST]\n",
    "MT_keys = pd.Index(sdata_training_MT.data_vars.keys())\n",
    "target_mask_MT = MT_keys.str.contains(\"RNCMPT\")\n",
    "target_cols_MT = MT_keys[target_mask_MT]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train single task models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Instantiation function\n",
    "from pytorch_lightning import seed_everything\n",
    "def prep_new_model(\n",
    "    seed,\n",
    "    conv_dropout = 0,\n",
    "    dense_dropout = 0,\n",
    "    batchnorm = True\n",
    "):\n",
    "    # Set a seed\n",
    "    seed_everything(seed)\n",
    "\n",
    "    model = models.zoo.DeepBind(\n",
    "        input_len=41, # Length of padded sequences\n",
    "        output_dim=1, # Number of multitask outputs\n",
    "        conv_kwargs=dict(input_channels=4, conv_channels=[16], conv_kernels=[16], dropout_rates=conv_dropout, batchnorm=batchnorm),\n",
    "        dense_kwargs=dict(hidden_dims=[32], dropout_rates=dense_dropout, batchnorm=batchnorm),\n",
    "    )\n",
    "    \n",
    "    # Initialize the model prior to conv filter initialization\n",
    "    models.init_weights(model)\n",
    "\n",
    "    module = models.SequenceModule(\n",
    "        arch=model,\n",
    "        task=\"regression\",\n",
    "        loss_fxn=\"mse\",\n",
    "        optimizer=\"adam\",\n",
    "        optimizer_lr=0.0005,\n",
    "        scheduler_kwargs=dict(patience=2)\n",
    "    )\n",
    "\n",
    "    # Return the model\n",
    "    return module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[rank: 0] Global seed set to 13\n"
     ]
    }
   ],
   "source": [
    "# Test out the function to grab a model\n",
    "model = prep_new_model(seed=13, conv_dropout=0.5, dense_dropout=0.5, batchnorm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train a model on each target prediction! NOTE: this is configured for testing purposes, see the ray13_training_ST.py script for the full training\n",
    "for i, target_col in enumerate(target_cols_ST[:1]):\n",
    "    print(f\"Training DeepBind SingleTask model on {target_col}\")\n",
    "\n",
    "    # Initialize the model\n",
    "    model = prep_new_model(seed=i, conv_dropout=0.5, dense_dropout=0.5, batchnorm=True)\n",
    "\n",
    "    # Fit the model\n",
    "    train.fit_sequence_module(\n",
    "        model,\n",
    "        sdata_training_ST,\n",
    "        seq_key=\"ohe_seq\",\n",
    "        target_keys=target_col,\n",
    "        in_memory=True,\n",
    "        train_key=\"train_val\",\n",
    "        epochs=5,\n",
    "        batch_size=100,\n",
    "        num_workers=4,\n",
    "        prefetch_factor=2,\n",
    "        drop_last=False,\n",
    "        early_stopping_patience=3,\n",
    "        name=\"DeepBind_ST\",\n",
    "        version=target_col,\n",
    "        transforms={\"ohe_seq\": lambda x: torch.tensor(x, dtype=torch.float32), \"target\": lambda x: torch.tensor(x, dtype=torch.float32)},\n",
    "        seed=i\n",
    "    )\n",
    "\n",
    "    evaluate.train_val_predictions_sequence_module(\n",
    "        model,\n",
    "        sdata=sdata_training_ST,\n",
    "        seq_key=\"ohe_seq\",\n",
    "        target_keys=target_col,\n",
    "        in_memory=True,\n",
    "        train_key=\"train_val\",\n",
    "        batch_size=1024,\n",
    "        num_workers=4,\n",
    "        prefetch_factor=2,\n",
    "        name=\"DeepBind_ST\",\n",
    "        version=target_col,\n",
    "        transforms={\"ohe_seq\": lambda x: torch.tensor(x, dtype=torch.float32), \"target\": lambda x: torch.tensor(x, dtype=torch.float32)},\n",
    "        suffix=\"_ST\"\n",
    "    )\n",
    "\n",
    "# Save the predictions!\n",
    "sd.to_zarr(sdata_training_ST, os.path.join(settings.output_dir, f\"norm_setA_predictions_ST.zarr\"), load_first=True, mode=\"w\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train multi-task model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the version for saving\n",
    "model_version = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the architecture to be trained\n",
    "arch = models.zoo.DeepBind(\n",
    "    input_len=41, # Length of padded sequences\n",
    "    output_dim=len(target_cols_MT), # Number of multitask outputs\n",
    "    conv_kwargs=dict(input_channels=4, conv_channels=[1024], conv_kernels=[16], dropout_rates=0.25, batchnorm=0.25),\n",
    "    dense_kwargs=dict(hidden_dims=[512], dropout_rates=0.25, batchnorm=True),\n",
    ")\n",
    "\n",
    "# Initialize the model prior to conv filter initialization\n",
    "models.init_weights(arch)\n",
    "\n",
    "# Wrap the model in a SequenceModule\n",
    "model = models.SequenceModule(\n",
    "    arch=arch,\n",
    "    task=\"regression\",\n",
    "    loss_fxn=\"mse\",\n",
    "    optimizer=\"adam\",\n",
    "    optimizer_lr=0.0005,\n",
    "    scheduler_kwargs=dict(patience=2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "train.fit_sequence_module(\n",
    "    model,\n",
    "    sdata_training_MT,\n",
    "    seq_key=\"ohe_seq\",\n",
    "    target_keys=target_cols_MT,\n",
    "    in_memory=True,\n",
    "    train_key=\"train_val\",\n",
    "    epochs=100,\n",
    "    batch_size=1024,\n",
    "    num_workers=4,\n",
    "    prefetch_factor=2,\n",
    "    drop_last=False,\n",
    "    early_stopping_patience=5,\n",
    "    name=\"DeepBind_MT\",\n",
    "    version=f\"v{model_version}\",\n",
    "    transforms={\"ohe_seq\": lambda x: torch.tensor(x, dtype=torch.float32), \"target\": lambda x: torch.tensor(x, dtype=torch.float32)},\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Get training predictions\n",
    "evaluate.train_val_predictions_sequence_module(\n",
    "    model,\n",
    "    sdata=sdata_training_MT,\n",
    "    seq_key=\"ohe_seq\",\n",
    "    target_keys=target_cols_MT,\n",
    "    in_memory=True,\n",
    "    train_key=\"train_val\",\n",
    "    batch_size=1024,\n",
    "    num_workers=4,\n",
    "    prefetch_factor=2,\n",
    "    name=\"DeepBind_MT\",\n",
    "    version=f\"v{model_version}\",\n",
    "    transforms={\"ohe_seq\": lambda x: torch.tensor(x, dtype=torch.float32), \"target\": lambda x: torch.tensor(x, dtype=torch.float32)},\n",
    "    suffix=\"_MT\"\n",
    ")\n",
    "\n",
    "# Save the predictions!\n",
    "sd.to_zarr(sdata_training_MT, os.path.join(settings.output_dir, f\"norm_setA_predictions_v{model_version}_MT.zarr\"), load_first=True, mode=\"w\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DONE!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm_setA_predictions_ST.zarr 120326 252\n",
      "245\n",
      "norm_setA_predictions_v0_MT.zarr 110645 472\n",
      "466\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Double check we predicted on all the columns\n",
    "for zarr in [f\"norm_setA_predictions_ST.zarr\", f\"norm_setA_predictions_v{model_version}_MT.zarr\"]:\n",
    "    sdata = sd.open_zarr(os.path.join(settings.output_dir, zarr))\n",
    "    keys = pd.Index(sdata.data_vars.keys())\n",
    "    print(zarr, sdata.dims[\"_sequence\"], len(sdata.data_vars))\n",
    "    print(np.sum(keys.str.contains(\"RNCMPT\")))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 ml4gland",
   "language": "python",
   "name": "ml4gland"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
