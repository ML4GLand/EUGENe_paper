{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ray et al 2013 Training \n",
    "**Authorship:**\n",
    "Adam Klie, *08/31/2022*\n",
    "***\n",
    "**Description:**\n",
    "Notebook to perform simple training of *single task* and *multitask* models on the Ray et al dataset.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-07T02:48:57.067212Z",
     "iopub.status.busy": "2022-09-07T02:48:57.066679Z",
     "iopub.status.idle": "2022-09-07T02:50:27.271702Z",
     "shell.execute_reply": "2022-09-07T02:50:27.271069Z",
     "shell.execute_reply.started": "2022-09-07T02:48:57.067148Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available: True\n",
      "Number of GPUs: 1\n",
      "Current GPU: 0\n",
      "GPUs: Quadro RTX 5000\n"
     ]
    }
   ],
   "source": [
    "if 'autoreload' not in get_ipython().extension_manager.loaded:\n",
    "    %load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import logging\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import eugene as eu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-07T02:50:27.273244Z",
     "iopub.status.busy": "2022-09-07T02:50:27.272785Z",
     "iopub.status.idle": "2022-09-07T02:50:31.078439Z",
     "shell.execute_reply": "2022-09-07T02:50:31.077924Z",
     "shell.execute_reply.started": "2022-09-07T02:50:27.273227Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "eu.settings.dataset_dir = \"/cellar/users/aklie/data/eugene/ray13\"\n",
    "eu.settings.output_dir = \"/cellar/users/aklie/projects/EUGENe/EUGENe_paper/output/ray13\"\n",
    "eu.settings.logging_dir = \"/cellar/users/aklie/projects/EUGENe/EUGENe_paper/logs/ray13\"\n",
    "eu.settings.config_dir = \"/cellar/users/aklie/projects/EUGENe/EUGENe_paper/configs/ray13\"\n",
    "eu.settings.verbosity = logging.ERROR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load in the SetA training `SeqData`'s for single task and multi-task models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-07T02:50:31.079195Z",
     "iopub.status.busy": "2022-09-07T02:50:31.079041Z",
     "iopub.status.idle": "2022-09-07T02:50:36.114196Z",
     "shell.execute_reply": "2022-09-07T02:50:36.113519Z",
     "shell.execute_reply.started": "2022-09-07T02:50:31.079180Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load in the training SetA processed data for single task and multitask models\n",
    "sdata_training_ST = eu.dl.read_h5sd(os.path.join(eu.settings.dataset_dir, eu.settings.dataset_dir, \"norm_setA_processed_ST.h5sd\"))\n",
    "sdata_training_MT = eu.dl.read_h5sd(os.path.join(eu.settings.dataset_dir, eu.settings.dataset_dir, \"norm_setA_processed_MT.h5sd\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-07T02:50:36.115645Z",
     "iopub.status.busy": "2022-09-07T02:50:36.115427Z",
     "iopub.status.idle": "2022-09-07T02:50:39.841282Z",
     "shell.execute_reply": "2022-09-07T02:50:39.840647Z",
     "shell.execute_reply.started": "2022-09-07T02:50:36.115629Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Grab the prediction columns for single task and multitask\n",
    "target_mask_ST = sdata_training_ST.seqs_annot.columns.str.contains(\"RNCMPT\")\n",
    "target_cols_ST = sdata_training_ST.seqs_annot.columns[target_mask_ST]\n",
    "target_mask_MT = sdata_training_MT.seqs_annot.columns.str.contains(\"RNCMPT\")\n",
    "target_cols_MT = sdata_training_MT.seqs_annot.columns[target_mask_MT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RNCMPT00268'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_cols_MT[215]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train single task models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-05T17:02:05.595562Z",
     "iopub.status.busy": "2022-09-05T17:02:05.595073Z",
     "iopub.status.idle": "2022-09-05T17:02:08.841565Z",
     "shell.execute_reply": "2022-09-05T17:02:08.841042Z",
     "shell.execute_reply.started": "2022-09-05T17:02:05.595540Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Instantiation function\n",
    "from pytorch_lightning import seed_everything\n",
    "def prep_new_model(\n",
    "    seed,\n",
    "    conv_dropout = 0,\n",
    "    fc_dropout = 0,\n",
    "    batchnorm = True\n",
    "):\n",
    "    model = eu.models.DeepBind(\n",
    "        input_len=41, # Length of padded sequences\n",
    "        output_dim=1, # Number of multitask outputs\n",
    "        strand=\"ss\",\n",
    "        task=\"regression\",\n",
    "        conv_kwargs=dict(channels=[4, 16], conv_kernels=[16], dropout_rates=conv_dropout, batchnorm=batchnorm),\n",
    "        mp_kwargs=dict(kernel_size=8),\n",
    "        fc_kwargs=dict(hidden_dims=[32], dropout_rate=fc_dropout, batchnorm=batchnorm),\n",
    "        optimizer=\"sgd\",\n",
    "        lr=0.0005,\n",
    "        scheduler_patience=3\n",
    "    )\n",
    "\n",
    "    # Set a seed\n",
    "    seed_everything(seed)\n",
    "    \n",
    "    # Initialize the model prior to conv filter initialization\n",
    "    eu.models.init_weights(model)\n",
    "\n",
    "    # Return the model\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-05T17:02:09.405091Z",
     "iopub.status.busy": "2022-09-05T17:02:09.404823Z",
     "iopub.status.idle": "2022-09-05T17:02:24.673240Z",
     "shell.execute_reply": "2022-09-05T17:02:24.672555Z",
     "shell.execute_reply.started": "2022-09-05T17:02:09.405075Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: DeepBind\n",
      "Input length: 41\n",
      "Output dimension: 1\n",
      "Strand: ss\n",
      "Task: regression\n",
      "Aggregation: max\n",
      "Loss function: mse_loss\n",
      "Optimizer: sgd\n",
      "\tOptimizer parameters: {}\n",
      "Learning rate: 0.0005\n",
      "Scheduler: lr_scheduler\n",
      "Scheduler patience: 3\n",
      "  | Name      | Type                      | Params\n",
      "--------------------------------------------------------\n",
      "0 | hp_metric | R2Score                   | 0     \n",
      "1 | convnet   | BasicConv1D               | 1.1 K \n",
      "2 | max_pool  | MaxPool1d                 | 0     \n",
      "3 | avg_pool  | AvgPool1d                 | 0     \n",
      "4 | fcn       | BasicFullyConnectedModule | 1.2 K \n",
      "--------------------------------------------------------\n",
      "2.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.2 K     Total params\n",
      "0.009     Total estimated model params size (MB)\n",
      "No transforms given, assuming just need to tensorize.\n",
      "torch.Size([64, 1])\n"
     ]
    }
   ],
   "source": [
    "# Test out a model before training\n",
    "model = prep_new_model(0)\n",
    "print(model.summary())\n",
    "sdataloader = sdata_training_ST[:64].to_dataset().to_dataloader()\n",
    "test_seqs = next(iter(sdataloader))\n",
    "print(model(test_seqs[1], test_seqs[2]).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-05T17:03:42.777128Z",
     "iopub.status.busy": "2022-09-05T17:03:42.776916Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n",
      "Global seed set to 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training DeepBind SingleTask model on RNCMPT00001\n",
      "Dropping 610 sequences with NaN targets.\n",
      "No transforms given, assuming just need to tensorize.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Set SLURM handle signals.\n",
      "\n",
      "  | Name      | Type                      | Params\n",
      "--------------------------------------------------------\n",
      "0 | hp_metric | R2Score                   | 0     \n",
      "1 | convnet   | BasicConv1D               | 1.1 K \n",
      "2 | max_pool  | MaxPool1d                 | 0     \n",
      "3 | avg_pool  | AvgPool1d                 | 0     \n",
      "4 | fcn       | BasicFullyConnectedModule | 1.2 K \n",
      "--------------------------------------------------------\n",
      "2.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.2 K     Total params\n",
      "0.009     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No transforms given, assuming just need to tensorize.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "746561f473f14b27912a87b6b58b839c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cellar/users/aklie/opt/miniconda3/envs/eugene_dev/lib/python3.7/site-packages/pytorch_lightning/trainer/data_loading.py:133: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f\"The dataloader, {name}, does not have many workers which may be a bottleneck.\"\n",
      "Global seed set to 0\n",
      "/cellar/users/aklie/opt/miniconda3/envs/eugene_dev/lib/python3.7/site-packages/pytorch_lightning/trainer/data_loading.py:133: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f\"The dataloader, {name}, does not have many workers which may be a bottleneck.\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be5481df25b84a6faca26e35c82d6388",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ad13da344c4405ba3f9f5ab8b4a8655",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0b98f63c65c42deb4156e6555d720ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dd53eee24e347b299667597cf9318f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc7ba9af9acd499ea0adf816f2d98210",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceb98d6711954a89a3fc1ee4daf5265b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No transforms given, assuming just need to tensorize.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No transforms given, assuming just need to tensorize.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/cellar/users/aklie/opt/miniconda3/envs/eugene_dev/lib/python3.7/site-packages/pytorch_lightning/trainer/data_loading.py:133: UserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f\"The dataloader, {name}, does not have many workers which may be a bottleneck.\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccc1626853a24650ad817d9a3c2e2577",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c10c74b1f9b438b833e174bbe6d9077",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1\n",
      "Global seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SeqData object modified:\n",
      "    seqs_annot:\n",
      "        + RNCMPT00001_predictions_ST\n",
      "Training DeepBind SingleTask model on RNCMPT00002\n",
      "Dropping 609 sequences with NaN targets.\n",
      "No transforms given, assuming just need to tensorize.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Set SLURM handle signals.\n",
      "\n",
      "  | Name      | Type                      | Params\n",
      "--------------------------------------------------------\n",
      "0 | hp_metric | R2Score                   | 0     \n",
      "1 | convnet   | BasicConv1D               | 1.1 K \n",
      "2 | max_pool  | MaxPool1d                 | 0     \n",
      "3 | avg_pool  | AvgPool1d                 | 0     \n",
      "4 | fcn       | BasicFullyConnectedModule | 1.2 K \n",
      "--------------------------------------------------------\n",
      "2.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.2 K     Total params\n",
      "0.009     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No transforms given, assuming just need to tensorize.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4018287082854ac184811cc4345792ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab83c95882a244f9951eca8f4ea4360c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54f21a1d387c4b42b44c5b67640704a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65bf76f2667c4eb68eadf8f06326b388",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6ecf998c4094285831f3538a90778da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d411d60db064770981f456dea151bcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be8168a799f64608a7531db6f7f33e82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No transforms given, assuming just need to tensorize.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No transforms given, assuming just need to tensorize.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c52d9191fad446259ae1a56d77c9755b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcbd9c919890470f9b21e877659dbdbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SeqData object modified:\n",
      "    seqs_annot:\n",
      "        + RNCMPT00002_predictions_ST\n"
     ]
    }
   ],
   "source": [
    "# Train a model on each target prediction!\n",
    "for i, target_col in enumerate(target_cols_ST[:2]):\n",
    "    print(f\"Training DeepBind SingleTask model on {target_col}\")\n",
    "\n",
    "    # Initialize the model\n",
    "    model = prep_new_model(seed=i, conv_dropout=0.5, fc_dropout=0.5, batchnorm=True)\n",
    "\n",
    "    # Train the model\n",
    "    eu.train.fit(\n",
    "        model=model, \n",
    "        sdata=sdata_training_ST, \n",
    "        gpus=1, \n",
    "        target_keys=target_col,\n",
    "        train_key=\"train_val\",\n",
    "        epochs=5,\n",
    "        early_stopping_metric=\"val_loss\",\n",
    "        early_stopping_patience=3,\n",
    "        batch_size=64,\n",
    "        num_workers=0,\n",
    "        name=\"DeepBind_ST\",\n",
    "        seed=i,\n",
    "        version=target_col,\n",
    "        verbosity=logging.ERROR\n",
    "    )\n",
    "    \n",
    "    # Get predictions on the training data\n",
    "    eu.evaluate.train_val_predictions(\n",
    "        model,\n",
    "        sdata=sdata_training_ST, \n",
    "        target_keys=target_col,\n",
    "        train_key=\"train_val\",\n",
    "        batch_size=1024,\n",
    "        num_workers=0,\n",
    "        name=\"DeepBind_ST\",\n",
    "        suffix=\"_ST\",\n",
    "        version=target_col\n",
    "    )\n",
    "    del model \n",
    "#sdata_training_ST.write_h5sd(os.path.join(eu.settings.output_dir, \"DeepBind_ST\", \"norm_training_predictions_ST.h5sd\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train multi-task model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-07T02:50:39.842186Z",
     "iopub.status.busy": "2022-09-07T02:50:39.842028Z",
     "iopub.status.idle": "2022-09-07T02:50:43.297848Z",
     "shell.execute_reply": "2022-09-07T02:50:43.297195Z",
     "shell.execute_reply.started": "2022-09-07T02:50:39.842171Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the version for saving\n",
    "model_version = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-07T03:10:27.856734Z",
     "iopub.status.busy": "2022-09-07T03:10:27.856521Z",
     "iopub.status.idle": "2022-09-07T03:10:31.373397Z",
     "shell.execute_reply": "2022-09-07T03:10:31.372778Z",
     "shell.execute_reply.started": "2022-09-07T03:10:27.856717Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: DeepBind\n",
      "Input length: 41\n",
      "Output dimension: 233\n",
      "Strand: ss\n",
      "Task: regression\n",
      "Aggregation: max\n",
      "Loss function: mse_loss\n",
      "Optimizer: adam\n",
      "\tOptimizer parameters: {}\n",
      "Learning rate: 0.0005\n",
      "Scheduler: lr_scheduler\n",
      "Scheduler patience: 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(  | Name      | Type                      | Params\n",
       " --------------------------------------------------------\n",
       " 0 | hp_metric | R2Score                   | 0     \n",
       " 1 | convnet   | BasicConv1D               | 68.6 K\n",
       " 2 | max_pool  | MaxPool1d                 | 0     \n",
       " 3 | avg_pool  | AvgPool1d                 | 0     \n",
       " 4 | fcn       | BasicFullyConnectedModule | 1.2 M \n",
       " --------------------------------------------------------\n",
       " 1.2 M     Trainable params\n",
       " 0         Non-trainable params\n",
       " 1.2 M     Total params\n",
       " 4.953     Total estimated model params size (MB),\n",
       " 0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "conv_dropout = 0.25\n",
    "fc_dropout = 0.25\n",
    "batchnorm = True\n",
    "model = eu.models.DeepBind(\n",
    "    input_len=41, # Length of padded sequences\n",
    "    output_dim=len(target_cols_MT), # Number of multitask outputs\n",
    "    strand=\"ss\", # Strand information to include, only forward strand\n",
    "    task=\"regression\", # Task type, regression in this case\n",
    "    optimizer=\"adam\", # Optimizer to use\n",
    "    optimizer_kwargs={}, # Default optimizer kwargs\n",
    "    lr=0.0005, # Learning rate to start with\n",
    "    scheduler_patience=2, # Number of epochs to wait before reducing learning rate\n",
    "    conv_kwargs=dict(channels=[4, 1024], conv_kernels=[16], dropout_rates=conv_dropout, batchnorm=batchnorm), # Convolutional layer kwargs\n",
    "    fc_kwargs=dict(hidden_dims=[512], dropout_rate=fc_dropout, batchnorm=batchnorm) # Fully connected layer kwargs\n",
    ")\n",
    "model.summary(), model_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-07T03:24:14.806252Z",
     "iopub.status.busy": "2022-09-07T03:24:14.805997Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping 0 sequences with NaN targets.\n",
      "No transforms given, assuming just need to tensorize.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No transforms given, assuming just need to tensorize.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Set SLURM handle signals.\n",
      "\n",
      "  | Name      | Type                      | Params\n",
      "--------------------------------------------------------\n",
      "0 | hp_metric | R2Score                   | 0     \n",
      "1 | convnet   | BasicConv1D               | 68.6 K\n",
      "2 | max_pool  | MaxPool1d                 | 0     \n",
      "3 | avg_pool  | AvgPool1d                 | 0     \n",
      "4 | fcn       | BasicFullyConnectedModule | 1.2 M \n",
      "--------------------------------------------------------\n",
      "1.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 M     Total params\n",
      "4.953     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e9c4e42c91e4b589414cdfd3f511d70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cellar/users/aklie/opt/miniconda3/envs/eugene_dev/lib/python3.7/site-packages/pytorch_lightning/trainer/data_loading.py:133: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f\"The dataloader, {name}, does not have many workers which may be a bottleneck.\"\n",
      "Global seed set to 42\n",
      "/cellar/users/aklie/opt/miniconda3/envs/eugene_dev/lib/python3.7/site-packages/pytorch_lightning/trainer/data_loading.py:133: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f\"The dataloader, {name}, does not have many workers which may be a bottleneck.\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d4953e2912947db8ce5e67230059f98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d500399ae65f406ab646d4758197b118",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7fdee3795e744d7836ab59d547e41ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c23890be186f4b70962851b82b8ec7b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d5018544c6f45b4a60f553c084fe0ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c3f0009573b4f6cbb03e6b60d92ad5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71c03f24758041dfadb20f4e032f07f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a30f6b5004748bea0dafffd42a102eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f53b03daa94f4ab486a952e44dfcaffe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2db478c70cb04f6c8718238deedd6e77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f135940ad8a42e1870fdc10e258f9e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46ab7b120d2442a789fd7b3e29238ee2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0af872095b8b460eba8af8f3f250019b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fdfb04ffd974f81a40779a352a0ed1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0969af51ac9b4eea8edf2339e910cc23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f42af53432fb483b88e356fe135d5a58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e0ff9cb57d64a658c767cce062268cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bbaad4736504b9aa114bd5e12425694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93e95e0e20594127b7bdcf00f4e9db79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c161f278ed044b1f9341427cd3c041d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b625d693a3c446428e6b6d89b53996bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29994eeb804b4de3a4309c05c4315ba1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20049597884d459db5c4b01eac51dd0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "579706c107cb4cf9b32ac8d6b2182791",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28ed8716f7af4ece8ed885141777e8be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce6d52545f45461f9f9b736c5dcaa69c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c368d47a8c754f20b1e0c4b2d3b18bb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02aa9d89441d451f93c305cb7c5cb8d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa6d0321e27f4a1b9d89745fd04eeabc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d979f0df482425b95c7cd25d172c2b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec1ef97c6d4245b7bb4aacc99b34ecd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62fb92952d384817b7f0ab9233279661",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2f3ba12ead540baa8f80d30ab7c4dde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81153d1fd5c24c7e977f4606354ae705",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d18f4e43b9f47b19849b9a24131f31e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fabe884b326047d78027949cf69a139b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No transforms given, assuming just need to tensorize.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No transforms given, assuming just need to tensorize.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cellar/users/aklie/opt/miniconda3/envs/eugene_dev/lib/python3.7/site-packages/pytorch_lightning/trainer/data_loading.py:133: UserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f\"The dataloader, {name}, does not have many workers which may be a bottleneck.\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3af0798868f444158e20cb2b78e0fa8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebe61782000346fb9cacfe666e4c8623",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cellar/users/aklie/opt/miniconda3/envs/eugene_dev/lib/python3.7/site-packages/pandas/core/frame.py:3636: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self[k1] = value[k2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SeqData object modified:\n",
      "    seqs_annot:\n",
      "        + RNCMPT00017_predictions_MT, RNCMPT00075_predictions_MT, RNCMPT00142_predictions_MT, RNCMPT00146_predictions_MT, RNCMPT00255_predictions_MT, RNCMPT00074_predictions_MT, RNCMPT00291_predictions_MT, RNCMPT00073_predictions_MT, RNCMPT00093_predictions_MT, RNCMPT00287_predictions_MT, RNCMPT00147_predictions_MT, RNCMPT00088_predictions_MT, RNCMPT00116_predictions_MT, RNCMPT00113_predictions_MT, RNCMPT00079_predictions_MT, RNCMPT00064_predictions_MT, RNCMPT00217_predictions_MT, RNCMPT00150_predictions_MT, RNCMPT00024_predictions_MT, RNCMPT00141_predictions_MT, RNCMPT00235_predictions_MT, RNCMPT00022_predictions_MT, RNCMPT00256_predictions_MT, RNCMPT00153_predictions_MT, RNCMPT00253_predictions_MT, RNCMPT00215_predictions_MT, RNCMPT00240_predictions_MT, RNCMPT00176_predictions_MT, RNCMPT00059_predictions_MT, RNCMPT00027_predictions_MT, RNCMPT00225_predictions_MT, RNCMPT00023_predictions_MT, RNCMPT00122_predictions_MT, RNCMPT00178_predictions_MT, RNCMPT00237_predictions_MT, RNCMPT00095_predictions_MT, RNCMPT00126_predictions_MT, RNCMPT00241_predictions_MT, RNCMPT00037_predictions_MT, RNCMPT00062_predictions_MT, RNCMPT00026_predictions_MT, RNCMPT00159_predictions_MT, RNCMPT00263_predictions_MT, RNCMPT00167_predictions_MT, RNCMPT00238_predictions_MT, RNCMPT00123_predictions_MT, RNCMPT00220_predictions_MT, RNCMPT00273_predictions_MT, RNCMPT00177_predictions_MT, RNCMPT00268_predictions_MT, RNCMPT00139_predictions_MT, RNCMPT00012_predictions_MT, RNCMPT00038_predictions_MT, RNCMPT00270_predictions_MT, RNCMPT00181_predictions_MT, RNCMPT00168_predictions_MT, RNCMPT00056_predictions_MT, RNCMPT00149_predictions_MT, RNCMPT00045_predictions_MT, RNCMPT00182_predictions_MT, RNCMPT00261_predictions_MT, RNCMPT00143_predictions_MT, RNCMPT00288_predictions_MT, RNCMPT00044_predictions_MT, RNCMPT00103_predictions_MT, RNCMPT00066_predictions_MT, RNCMPT00224_predictions_MT, RNCMPT00137_predictions_MT, RNCMPT00170_predictions_MT, RNCMPT00120_predictions_MT, RNCMPT00090_predictions_MT, RNCMPT00262_predictions_MT, RNCMPT00121_predictions_MT, RNCMPT00063_predictions_MT, RNCMPT00171_predictions_MT, RNCMPT00028_predictions_MT, RNCMPT00068_predictions_MT, RNCMPT00203_predictions_MT, RNCMPT00163_predictions_MT, RNCMPT00209_predictions_MT, RNCMPT00018_predictions_MT, RNCMPT00174_predictions_MT, RNCMPT00035_predictions_MT, RNCMPT00131_predictions_MT, RNCMPT00070_predictions_MT, RNCMPT00148_predictions_MT, RNCMPT00161_predictions_MT, RNCMPT00124_predictions_MT, RNCMPT00004_predictions_MT, RNCMPT00252_predictions_MT, RNCMPT00033_predictions_MT, RNCMPT00020_predictions_MT, RNCMPT00200_predictions_MT, RNCMPT00289_predictions_MT, RNCMPT00228_predictions_MT, RNCMPT00076_predictions_MT, RNCMPT00055_predictions_MT, RNCMPT00021_predictions_MT, RNCMPT00234_predictions_MT, RNCMPT00105_predictions_MT, RNCMPT00013_predictions_MT, RNCMPT00057_predictions_MT, RNCMPT00050_predictions_MT, RNCMPT00112_predictions_MT, RNCMPT00205_predictions_MT, RNCMPT00152_predictions_MT, RNCMPT00029_predictions_MT, RNCMPT00087_predictions_MT, RNCMPT00284_predictions_MT, RNCMPT00212_predictions_MT, RNCMPT00248_predictions_MT, RNCMPT00230_predictions_MT, RNCMPT00165_predictions_MT, RNCMPT00001_predictions_MT, RNCMPT00127_predictions_MT, RNCMPT00151_predictions_MT, RNCMPT00239_predictions_MT, RNCMPT00245_predictions_MT, RNCMPT00133_predictions_MT, RNCMPT00040_predictions_MT, RNCMPT00206_predictions_MT, RNCMPT00199_predictions_MT, RNCMPT00258_predictions_MT, RNCMPT00283_predictions_MT, RNCMPT00089_predictions_MT, RNCMPT00078_predictions_MT, RNCMPT00155_predictions_MT, RNCMPT00118_predictions_MT, RNCMPT00229_predictions_MT, RNCMPT00069_predictions_MT, RNCMPT00065_predictions_MT, RNCMPT00081_predictions_MT, RNCMPT00091_predictions_MT, RNCMPT00083_predictions_MT, RNCMPT00111_predictions_MT, RNCMPT00071_predictions_MT, RNCMPT00187_predictions_MT, RNCMPT00218_predictions_MT, RNCMPT00049_predictions_MT, RNCMPT00172_predictions_MT, RNCMPT00183_predictions_MT, RNCMPT00054_predictions_MT, RNCMPT00067_predictions_MT, RNCMPT00202_predictions_MT, RNCMPT00173_predictions_MT, RNCMPT00114_predictions_MT, RNCMPT00039_predictions_MT, RNCMPT00259_predictions_MT, RNCMPT00223_predictions_MT, RNCMPT00110_predictions_MT, RNCMPT00102_predictions_MT, RNCMPT00053_predictions_MT, RNCMPT00031_predictions_MT, RNCMPT00156_predictions_MT, RNCMPT00086_predictions_MT, RNCMPT00007_predictions_MT, RNCMPT00280_predictions_MT, RNCMPT00052_predictions_MT, RNCMPT00278_predictions_MT, RNCMPT00006_predictions_MT, RNCMPT00285_predictions_MT, RNCMPT00246_predictions_MT, RNCMPT00094_predictions_MT, RNCMPT00232_predictions_MT, RNCMPT00002_predictions_MT, RNCMPT00051_predictions_MT, RNCMPT00282_predictions_MT, RNCMPT00032_predictions_MT, RNCMPT00046_predictions_MT, RNCMPT00016_predictions_MT, RNCMPT00169_predictions_MT, RNCMPT00132_predictions_MT, RNCMPT00249_predictions_MT, RNCMPT00166_predictions_MT, RNCMPT00117_predictions_MT, RNCMPT00175_predictions_MT, RNCMPT00043_predictions_MT, RNCMPT00099_predictions_MT, RNCMPT00134_predictions_MT, RNCMPT00042_predictions_MT, RNCMPT00216_predictions_MT, RNCMPT00019_predictions_MT, RNCMPT00236_predictions_MT, RNCMPT00072_predictions_MT, RNCMPT00274_predictions_MT, RNCMPT00109_predictions_MT, RNCMPT00101_predictions_MT, RNCMPT00184_predictions_MT, RNCMPT00108_predictions_MT, RNCMPT00254_predictions_MT, RNCMPT00100_predictions_MT, RNCMPT00281_predictions_MT, RNCMPT00011_predictions_MT, RNCMPT00162_predictions_MT, RNCMPT00034_predictions_MT, RNCMPT00272_predictions_MT, RNCMPT00005_predictions_MT, RNCMPT00085_predictions_MT, RNCMPT00119_predictions_MT, RNCMPT00279_predictions_MT, RNCMPT00185_predictions_MT, RNCMPT00138_predictions_MT, RNCMPT00077_predictions_MT, RNCMPT00226_predictions_MT, RNCMPT00036_predictions_MT, RNCMPT00186_predictions_MT, RNCMPT00179_predictions_MT, RNCMPT00140_predictions_MT, RNCMPT00136_predictions_MT, RNCMPT00082_predictions_MT, RNCMPT00160_predictions_MT, RNCMPT00104_predictions_MT, RNCMPT00157_predictions_MT, RNCMPT00251_predictions_MT, RNCMPT00265_predictions_MT, RNCMPT00269_predictions_MT, RNCMPT00197_predictions_MT, RNCMPT00106_predictions_MT, RNCMPT00010_predictions_MT, RNCMPT00096_predictions_MT, RNCMPT00257_predictions_MT, RNCMPT00080_predictions_MT, RNCMPT00041_predictions_MT, RNCMPT00219_predictions_MT, RNCMPT00003_predictions_MT, RNCMPT00180_predictions_MT, RNCMPT00025_predictions_MT, RNCMPT00164_predictions_MT, RNCMPT00158_predictions_MT, RNCMPT00107_predictions_MT, RNCMPT00047_predictions_MT, RNCMPT00014_predictions_MT, RNCMPT00084_predictions_MT\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "eu.train.fit(\n",
    "    model=model,\n",
    "    sdata=sdata_training_MT,\n",
    "    gpus=1,\n",
    "    target_keys=target_cols_MT,\n",
    "    train_key=\"train_val\",\n",
    "    epochs=100,\n",
    "    early_stopping_metric=\"val_loss\",\n",
    "    early_stopping_patience=5,\n",
    "    batch_size=1024,\n",
    "    num_workers=0,\n",
    "    name=\"DeepBind_MT\",\n",
    "    seed=42,\n",
    "    version=f\"v{model_version}\",\n",
    "    verbosity=logging.ERROR\n",
    ")\n",
    "\n",
    "# Get predictions on the training data\n",
    "eu.evaluate.train_val_predictions(\n",
    "    model,\n",
    "    sdata=sdata_training_MT, \n",
    "    target_keys=target_cols_MT,\n",
    "    train_key=\"train_val\",\n",
    "    batch_size=1024,\n",
    "    num_workers=0,\n",
    "    name=\"DeepBind_MT\",\n",
    "    suffix=\"_MT\",\n",
    "    version=f\"v{model_version}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-07T04:23:24.853613Z",
     "iopub.status.busy": "2022-09-07T04:23:24.853386Z",
     "iopub.status.idle": "2022-09-07T04:23:28.842788Z",
     "shell.execute_reply": "2022-09-07T04:23:28.842293Z",
     "shell.execute_reply.started": "2022-09-07T04:23:24.853595Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the predictions!\n",
    "sdata_training_MT.write_h5sd(os.path.join(eu.settings.output_dir, \"DeepBind_MT\", f\"norm_training_predictions_v{model_version}_MT.h5sd\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-07T04:23:28.843835Z",
     "iopub.status.busy": "2022-09-07T04:23:28.843657Z",
     "iopub.status.idle": "2022-09-07T04:23:31.242395Z",
     "shell.execute_reply": "2022-09-07T04:23:31.241919Z",
     "shell.execute_reply.started": "2022-09-07T04:23:28.843819Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "466"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Double check we predicted on all the columns\n",
    "np.sum(sdata_training_MT.seqs_annot.columns.str.contains(\"RNCMPT\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-07T04:23:31.243166Z",
     "iopub.status.busy": "2022-09-07T04:23:31.242990Z",
     "iopub.status.idle": "2022-09-07T04:23:35.108126Z",
     "shell.execute_reply": "2022-09-07T04:23:35.107601Z",
     "shell.execute_reply.started": "2022-09-07T04:23:31.243151Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Move on to the next model version if training multiple\n",
    "model_version = model_version + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test conv kernel initialization, this needs a fix!\n",
    "cnn = prep_new_model(seed=0, arch=\"CNN\", config=os.path.join(eu.settings.config_dir, \"ssCNN.yaml\"))\n",
    "jores = prep_new_model(seed=0, arch=\"Jores21CNN\", config=os.path.join(eu.settings.config_dir, \"Jores21CNN.yaml\"))\n",
    "torch.all(cnn.convnet.module[0].weight[0] == jores.biconv.kernels[0][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 eugene_dev",
   "language": "python",
   "name": "eugene_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
