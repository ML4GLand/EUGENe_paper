{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ray et al 2013 Intepretation\n",
    "**Authorship:**\n",
    "Adam Klie (last updated: *06/09/2023*)\n",
    "***\n",
    "**Description:**\n",
    "Notebook to interpret the trained models on the Ray et al (2013) dataset.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# General imports\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# EUGENe imports and settings\n",
    "import eugene as eu\n",
    "from eugene import preprocess as pp\n",
    "from eugene import models, interpret\n",
    "from eugene.models import zoo\n",
    "from eugene import plot as pl\n",
    "from eugene import settings\n",
    "settings.dataset_dir = \"/cellar/users/aklie/data/eugene/revision/ray13\"\n",
    "settings.output_dir = \"/cellar/users/aklie/projects/ML4GLand/EUGENe_paper/output/revision/ray13\"\n",
    "settings.logging_dir = \"/cellar/users/aklie/projects/ML4GLand/EUGENe_paper/logs/revision/ray13\"\n",
    "settings.config_dir = \"/cellar/users/aklie/projects/ML4GLand/EUGENe_paper/configs/ray13\"\n",
    "settings.figure_dir = \"/cellar/users/aklie/projects/ML4GLand/EUGENe_paper/figures//revision/ray13\"\n",
    "\n",
    "# EUGENe packages\n",
    "import seqdata as sd\n",
    "import motifdata as md\n",
    "import seqpro as sp\n",
    "from seqexplainer import evolution, attribute\n",
    "\n",
    "# Other imports\n",
    "import logomaker as lm\n",
    "\n",
    "# For illustrator editing\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "# Print versions\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"Eugene version: {eu.__version__}\")\n",
    "print(f\"SeqData version: {sd.__version__}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the test `SeqData`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the test data\n",
    "sdata_test = sd.open_zarr(os.path.join(settings.dataset_dir, \"norm_setB_ST.zarr\"))\n",
    "keys = pd.Index(sdata_test.data_vars.keys())\n",
    "target_mask = keys.str.contains(\"RNCMPT\")\n",
    "target_cols = keys[target_mask]\n",
    "sdata_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the MT training labels\n",
    "sdata_training = sd.open_zarr(os.path.join(settings.dataset_dir, \"norm_setA_sub_MT.zarr\"))\n",
    "keys_MT = pd.Index(sdata_training.data_vars.keys())\n",
    "target_mask_MT = keys_MT.str.contains(\"RNCMPT\")\n",
    "target_cols_MT = keys_MT[target_mask_MT]\n",
    "del sdata_training\n",
    "len(target_cols_MT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the targets to make sure they are 244 and 233\n",
    "len(target_cols), len(target_cols_MT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in top 10 single task and multitask models\n",
    "top_ST_tasks = pd.read_csv(\"/cellar/users/aklie/projects/ML4GLand/EUGENe_paper/output/ray13/performance/top_10_ST_intensities.tsv\", sep=\"\\t\", index_col=0)\n",
    "top_MT_tasks = pd.read_csv(\"/cellar/users/aklie/projects/ML4GLand/EUGENe_paper/output/ray13/performance/top_10_MT_intensities.tsv\", sep=\"\\t\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the shared index\n",
    "shared_top_10 = sorted(top_ST_tasks.index.intersection(top_MT_tasks.index))\n",
    "shared_top_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the indeces of the shared cols in the MT target cols\n",
    "shared_top_10_MT_idx = np.where(target_cols_MT.isin(shared_top_10))[0]\n",
    "shared_top_10_MT_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the arch for the single task model\n",
    "arch_ST = models.zoo.DeepBind(\n",
    "    input_len=41, # Length of padded sequences\n",
    "    output_dim=1, # Number of multitask outputs\n",
    "    conv_kwargs=dict(input_channels=4, conv_channels=[16], conv_kernels=[16], dropout_rates=0.5, batchnorm=True),\n",
    "    dense_kwargs=dict(hidden_dims=[32], dropout_rates=0.5, batchnorm=True),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the arch for the multitask model\n",
    "version = 0\n",
    "arch_MT = models.zoo.DeepBind(\n",
    "    input_len=41, # Length of padded sequences\n",
    "    output_dim=len(target_cols_MT), # Number of multitask outputs\n",
    "    conv_kwargs=dict(input_channels=4, conv_channels=[1024], conv_kernels=[16], dropout_rates=0.25, batchnorm=0.25),\n",
    "    dense_kwargs=dict(hidden_dims=[512], dropout_rates=0.25, batchnorm=True),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Attribution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single task models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get per nuceotide feature attibutions for each of the shared top 10 RBP prediction tasks\n",
    "for i, target_col in enumerate(shared_top_10):\n",
    "    print(f\"Intepreting DeepBind SingleTask model on {target_col}\")\n",
    "    model_file = glob.glob(os.path.join(settings.logging_dir, \"DeepBind_ST\", target_col, \"checkpoints\", \"*\"))[0]\n",
    "    model = models.SequenceModule.load_from_checkpoint(model_file, arch=arch_ST)\n",
    "    interpret.attribute_sdata(\n",
    "        model,\n",
    "        sdata_test,\n",
    "        method=\"InputXGradient\",\n",
    "        suffix=f\"_{target_col}_ST\",\n",
    "        batch_size=512,\n",
    "        transforms={\"ohe_seq\": lambda x: torch.tensor(x, dtype=torch.float32)}\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the multitask model\n",
    "model_file = glob.glob(os.path.join(settings.logging_dir, \"DeepBind_MT\", f\"v{version}\", \"checkpoints\", \"*\"))[0]\n",
    "model = models.SequenceModule.load_from_checkpoint(model_file, arch=arch_MT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get per nuceotide feature attibutions for each of the shared top 10 RBP prediction tasks\n",
    "for i, target_col in zip(shared_top_10_MT_idx, shared_top_10):\n",
    "    print(f\"Intepreting version{version} DeepBind MultiTask model on {target_col}, which is the {i}th index of prediction\")\n",
    "    interpret.attribute_sdata(\n",
    "        model,\n",
    "        sdata_test,\n",
    "        method=\"InputXGradient\",\n",
    "        target=int(i),\n",
    "        suffix=f\"_{target_col}_MT\",\n",
    "        batch_size=512,\n",
    "        transforms={\"ohe_seq\": lambda x: torch.tensor(x, dtype=torch.float32)}\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot feature attributions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata_test = sdata_test.set_index(_sequence=\"Probe_ID\")\n",
    "for i, target_col in enumerate(shared_top_10):\n",
    "    print(f\"Plotting feature attribution scores for DeepBind models on {target_col}\")\n",
    "    top5_index = sdata_test[target_col].to_series().sort_values(ascending=False).index[:5]\n",
    "    pl.multiseq_track(\n",
    "        sdata_test,\n",
    "        seq_ids=top5_index,\n",
    "        attrs_vars=[f\"InputXGradient_attrs_{target_col}_ST\", f\"InputXGradient_attrs_{target_col}_MT\"],\n",
    "        id_var=\"_sequence\",\n",
    "        vocab=\"RNA\",\n",
    "        width=30,\n",
    "        height=6,\n",
    "        ylabs=[\"InputXGradient SingleTask\", \"InputXGradient MultiTask\"],\n",
    "        save=os.path.join(eu.settings.figure_dir, \"feature_attr\", f\"model_top5_feature_attr_{target_col}_STandMT.pdf\")\n",
    "    )\n",
    "    plt.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the layer you want to interpret\n",
    "layer_name = \"arch.conv1d_tower.layers.1\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single task "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Grab the pfms for the 16 filters of each single task model\n",
    "for i, target_col in enumerate(shared_top_10):\n",
    "    print(f\"Generating pfms for single task DeepBind models on {target_col}\")\n",
    "    model_file = glob.glob(os.path.join(settings.logging_dir, \"DeepBind_ST\", target_col, \"checkpoints\", \"*\"))[0]\n",
    "    model = models.SequenceModule.load_from_checkpoint(model_file, arch=arch_ST)\n",
    "    interpret.generate_pfms_sdata(\n",
    "        model=model, \n",
    "        sdata=sdata_test,\n",
    "        seq_var=\"ohe_seq\",\n",
    "        layer_name=layer_name,\n",
    "        activation_threshold=0.75, \n",
    "        batch_size=2048,\n",
    "        kernel_size=16,\n",
    "        transforms={\"ohe_seq\": lambda x: torch.tensor(x, dtype=torch.float32)},\n",
    "        suffix=f\"{target_col}_ST\"\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multitask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the multitask model\n",
    "model_file = glob.glob(os.path.join(settings.logging_dir, \"DeepBind_MT\", f\"v{version}\", \"checkpoints\", \"*\"))[0]\n",
    "model = models.SequenceModule.load_from_checkpoint(model_file, arch=arch_MT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Grab the pfms for all filters of the multitask model, this requires a lot of mem!\n",
    "interpret.generate_pfms_sdata(\n",
    "    model=model, \n",
    "    sdata=sdata_test,\n",
    "    seq_var=\"ohe_seq\",\n",
    "    layer_name=layer_name,\n",
    "    activation_threshold=0.75, \n",
    "    kernel_size=16,\n",
    "    batch_size=2048,\n",
    "    transforms={\"ohe_seq\": lambda x: torch.tensor(x, dtype=torch.float32)},\n",
    "    suffix=f\"_MT\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a filter of choice\n",
    "pl.filter_viz(\n",
    "    sdata_test,\n",
    "    filter_num=0,\n",
    "    pfms_var=f\"{layer_name}_pfms\",\n",
    "    vocab=\"RNA\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot filter viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualizations for all 16 filters for DeepBind SingleTask models\n",
    "for i, target_col in enumerate(shared_top_10):\n",
    "    print(f\"Plotting and saving filter visualizations for DeepBind models on {target_col}\")\n",
    "    pl.multifilter_viz(\n",
    "        sdata_test,\n",
    "        filter_nums=range(0,16),\n",
    "        pfms_var=f\"arch.conv1d_tower.layers.1_pfms{target_col}_ST\",\n",
    "        titles=[f\"filter {i}\" for i in range(16)],\n",
    "        vocab=\"RNA\",\n",
    "        num_rows=4,\n",
    "        num_cols=4,\n",
    "        save=os.path.join(settings.figure_dir, \"filter_viz\", f\"filters_viz_{target_col}_0.75_ST.pdf\")\n",
    "    )\n",
    "    # Save all the filter pfms from above as meme format for submission to TomTom\n",
    "    interpret.filters_to_meme_sdata(\n",
    "        sdata_test,\n",
    "        filters_var=f\"arch.conv1d_tower.layers.1_pfms{target_col}_ST\", \n",
    "        alphabet=\"ACGU\",\n",
    "        bg={\"A\": 0.25, \"C\": 0.25, \"G\": 0.25, \"U\": 0.25},\n",
    "        axis_order=(\"_arch.conv1d_tower.layers.1_None_filters\", \"_ohe\", \"_arch.conv1d_tower.layers.1_16\"),\n",
    "        output_dir=os.path.join(settings.output_dir),\n",
    "        filename=f\"{target_col}_filters_0.75_ST.meme\"\n",
    "    )\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualizations for all filters of the multitask model\n",
    "for i in range(32):\n",
    "    start_filter = i*32\n",
    "    end_filter = (i*32) + 32\n",
    "    print(f\"Plotting and saving filters {start_filter+1}-{end_filter}\")\n",
    "    pl.multifilter_viz(\n",
    "        sdata_test,\n",
    "        filter_nums=range(start_filter, end_filter),\n",
    "        pfms_var=f\"{layer_name}_pfms\",\n",
    "        vocab=\"RNA\",\n",
    "        num_rows=8,\n",
    "        num_cols=4,\n",
    "        titles=[f\"filter {i}\" for i in range(start_filter, end_filter)],\n",
    "        save=os.path.join(settings.figure_dir, \"filter_viz\", f\"filters{start_filter+1}-{end_filter}_viz_MT.pdf\")\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all the filter pfms from above as meme format for submission to TomTom\n",
    "interpret.filters_to_meme_sdata(\n",
    "    sdata_test,\n",
    "    filters_var=f\"arch.conv1d_tower.layers.1_pfms\", \n",
    "    alphabet=\"ACGU\",\n",
    "    bg={\"A\": 0.25, \"C\": 0.25, \"G\": 0.25, \"U\": 0.25},\n",
    "    axis_order=(\"_arch.conv1d_tower.layers.1_1024_filters\", \"_ohe\", \"_arch.conv1d_tower.layers.1_16_kernel_size\"),\n",
    "    output_dir=os.path.join(settings.output_dir),\n",
    "    filename=f\"filters_0.75_MT.meme\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *in silico*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ST model for an RBP of interest\n",
    "rbp = shared_top_10[6]\n",
    "model_file = glob.glob(os.path.join(settings.logging_dir, \"DeepBind_ST\", rbp, \"checkpoints\", \"*\"))[0]\n",
    "model = models.SequenceModule.load_from_checkpoint(model_file, arch=arch_ST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evolve a set of 10 random sequences across 5 rounds\n",
    "random_seqs = sp.ohe(sp.random_seqs(10, 41), alphabet=sp.ALPHABETS[\"RNA\"]).transpose(0, 2, 1)\n",
    "X_random = torch.tensor(random_seqs, dtype=torch.float32)\n",
    "evolved_seqs = []\n",
    "mutation_pos = []\n",
    "for random_seq in random_seqs:\n",
    "    evolved_res = evolution(\n",
    "        model=model,\n",
    "        X=random_seq,\n",
    "        rounds=5,\n",
    "    )\n",
    "    evolved_seqs.append(evolved_res[0])\n",
    "    mutation_pos.append(evolved_res[2])\n",
    "X_evolved = torch.tensor(np.array(evolved_seqs), dtype=torch.float32)\n",
    "mutation_pos = np.array(mutation_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the scores and the feature attributions for both the original random and the evolved\n",
    "random_scores = model.predict(X_random)\n",
    "random_explains = attribute(\n",
    "    model=model,\n",
    "    inputs=X_random,\n",
    "    method=\"InputXGradient\",\n",
    ")\n",
    "evolved_scores = model.predict(X_evolved)\n",
    "evolved_explains = attribute(\n",
    "    model=model,\n",
    "    inputs=X_evolved,\n",
    "    method=\"InputXGradient\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complicated plotting that we will eventually turn into a built in function\n",
    "for i in range(len(random_explains)):\n",
    "    fig, ax = plt.subplots(2, 1, figsize=(10, 4))\n",
    "    random_viz_seq = pd.DataFrame(random_explains[i].T, columns=[\"A\", \"C\", \"G\", \"U\"])\n",
    "    random_viz_seq.index.name = \"pos\"\n",
    "    random_logo = lm.Logo(random_viz_seq, color_scheme=\"classic\", figsize=(10, 2), ax=ax[0])\n",
    "    random_logo.style_spines(visible=False)\n",
    "    random_logo.style_spines(spines=['left'], visible=True)\n",
    "    random_logo.ax.set_xticks([])\n",
    "    ax[0].vlines(mutation_pos[i]-0.5, 0, 1, transform=ax[0].get_xaxis_transform(), colors='r', linestyle='--')\n",
    "    ax[0].vlines(mutation_pos[i]+0.5, 0, 1, transform=ax[0].get_xaxis_transform(), colors='r', linestyle='--')\n",
    "    ax[0].set_title(f\"{random_scores[i].item():.2f} -> {evolved_scores[i].item():.2f}\")\n",
    "    ax_bottom = ax[0].get_ylim()[0]\n",
    "    for j in range(len(mutation_pos[i])):\n",
    "        ax[0].annotate(f\"{j+1}\", xy=(mutation_pos[i][j]-0.25, ax_bottom))\n",
    "    evolved_viz_seq = pd.DataFrame(evolved_explains[i].T, columns=[\"A\", \"C\", \"G\", \"U\"])\n",
    "    evolved_viz_seq.index.name = \"pos\"\n",
    "    evolved_logo = lm.Logo(evolved_viz_seq, color_scheme=\"classic\", figsize=(10, 2), ax=ax[1])\n",
    "    evolved_logo.style_spines(visible=False)\n",
    "    evolved_logo.style_spines(spines=['left'], visible=True)\n",
    "    evolved_logo.ax.set_xticks([])\n",
    "    ax[1].vlines(mutation_pos[i]-0.5, 0, 1, transform=ax[1].get_xaxis_transform(), colors='r', linestyle='--')\n",
    "    ax[1].vlines(mutation_pos[i]+0.5, 0, 1, transform=ax[1].get_xaxis_transform(), colors='r', linestyle='--')\n",
    "    plt.savefig(os.path.join(settings.figure_dir, \"ise\", f\"randseq{i}_evolution_{rbp}.pdf\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the SeqData with predictions and interpretations\n",
    "sd.to_zarr(sdata_test, os.path.join(settings.output_dir, \"norm_test_predictions_and_intepretations_0.75.zarr\"), mode=\"w\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DONE!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the SeqData with predictions and interpretations\n",
    "sdata = sd.open_zarr(os.path.join(settings.output_dir, \"norm_test_predictions_and_intepretations_0.75.zarr\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 ml4gland",
   "language": "python",
   "name": "ml4gland"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "f0aab14ae665ca4264878e5867720697752ca4d3a67458798aa51c276bf829a9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
