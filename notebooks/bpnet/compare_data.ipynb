{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bpnet-lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bpnetlite.io import extract_loci\n",
    "from bpnetlite.io import PeakGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "data_dir = Path(\"/cellar/shared/carterlab/data/ml4gland/ENCSR000EGM/data\")\n",
    "reference_dir = \"/cellar/users/aklie/data/eugene/avsec21/reference\"\n",
    "peaks = os.path.join(data_dir, \"peaks.bed\")\n",
    "seqs = \"/cellar/users/aklie/data/ml4gland/use_cases/avsec21/reference/hg38.fa\"\n",
    "signals = [os.path.join(data_dir, \"plus.bw\"), os.path.join(data_dir, \"minus.bw\")]\n",
    "controls = [os.path.join(data_dir, \"control_plus.bw\"), os.path.join(data_dir, \"control_minus.bw\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training and validation chromosomes\n",
    "training_chroms = ['chr{}'.format(i) for i in range(1, 17)]\n",
    "valid_chroms = ['chr{}'.format(i) for i in range(18, 23)]\n",
    "\n",
    "# Create a dataloader for the training peaks, this takes about just under 4 minutes to complete\n",
    "training_data = PeakGenerator(peaks, seqs, signals, controls, chroms=training_chroms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1432"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the validation data, no jittering, augmenting, or shuffling, takes about 30 seconds\n",
    "X_valid, y_valid, X_ctl_valid = extract_loci(peaks, seqs, signals, controls, chroms=valid_chroms, max_jitter=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SeqData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import seqdata as sd\n",
    "import seqpro as sp\n",
    "from eugene import preprocess as pp\n",
    "\n",
    "# Define paths\n",
    "data_dir = Path(\"/cellar/shared/carterlab/data/ml4gland/ENCSR000EGM/data\")\n",
    "fasta = Path(\"/cellar/users/aklie/data/ml4gland/use_cases/avsec21/reference/hg38.fa\")\n",
    "peaks = data_dir / \"peaks.bed\"\n",
    "signals = [data_dir / \"plus.bw\", data_dir / \"minus.bw\"]\n",
    "controls = [data_dir / \"control_plus.bw\", data_dir / \"control_minus.bw\"]\n",
    "control_samples = ['plus', 'minus']\n",
    "bigwigs = signals + controls\n",
    "sample_names = ['signal+', 'signal-', 'control+', 'control-']\n",
    "out = '/cellar/users/dlaub/projects/ML4GLand/use_cases/avsec21/avsec21.zarr'\n",
    "\n",
    "# Define training and validation chromosomes\n",
    "training_chroms = ['chr{}'.format(i) for i in range(1, 17)]\n",
    "valid_chroms = ['chr{}'.format(i) for i in range(18, 23)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the SeqData\n",
    "sdata = sd.open_zarr(out)\n",
    "\n",
    "# Split cov into control and signal\n",
    "sdata['control'] = (\n",
    "    sdata.cov.sel(cov_sample=['control+', 'control-'])\n",
    "    .rename({'cov_sample': 'cov_strand'})\n",
    "    .assign_coords({'cov_strand': ['+', '-']})\n",
    ")\n",
    "sdata['signal'] = (\n",
    "    sdata.cov.sel(cov_sample=['signal+', 'signal-'])\n",
    "    .rename({'cov_sample': 'cov_strand'})\n",
    "    .assign_coords({'cov_strand': ['+', '-']})\n",
    ")\n",
    "sdata = sdata.drop_vars(['cov', 'cov_sample'])\n",
    "\n",
    "# Need to upper case the seqs for ohe\n",
    "sdata[\"cleaned_seq\"] = xr.DataArray(np.char.upper(sdata[\"seq\"]), dims=[\"_sequence\", \"_length\"])\n",
    "\n",
    "# Load the training data into memory for faster training\n",
    "sdata[['cleaned_seq', 'control', 'signal']].load()\n",
    "\n",
    "# Keep only training and validation chromosomes\n",
    "sdata = sdata.sel(_sequence=((sdata[\"chrom\"].isin(training_chroms)) | (sdata[\"chrom\"].isin(valid_chroms))).compute())\n",
    "\n",
    "# Train-test split based on chromosomes\n",
    "pp.train_test_chrom_split(sdata, test_chroms=valid_chroms)\n",
    "sdata_train = sdata.sel(_sequence=(sdata[\"train_val\"]==True).compute())\n",
    "sdata_valid = sdata.sel(_sequence=(sdata[\"train_val\"]==False).compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Define training transformations\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39meugene\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdataload\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_augment\u001b[39;00m \u001b[39mimport\u001b[39;00m RandomRC\n\u001b[1;32m      4\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mseq_trans\u001b[39m(x):\n\u001b[1;32m      5\u001b[0m     x \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mchar\u001b[39m.\u001b[39mupper(x)\n",
      "File \u001b[0;32m~/projects/ML4GLand/EUGENe/eugene/__init__.py:6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39m# Set default logging handler to avoid logging with logging.lastResort logger.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mlogging\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_settings\u001b[39;00m \u001b[39mimport\u001b[39;00m settings\n\u001b[1;32m      8\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m      9\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mimportlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetadata\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mimportlib_metadata\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/ML4GLand/EUGENe/eugene/_settings.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpathlib\u001b[39;00m \u001b[39mimport\u001b[39;00m Path\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m Union\n\u001b[0;32m----> 4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mEugeneConfig\u001b[39;00m:\n\u001b[1;32m      8\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[39m    Config manager for eugene.\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39m    >>> eugene.settings.dl_pin_memory_gpu_training = True\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/ml4gland/lib/python3.9/site-packages/torch/__init__.py:228\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    218\u001b[0m     \u001b[39m# Easy way.  You want this most of the time, because it will prevent\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[39m# C++ symbols from libtorch clobbering C++ symbols from other\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[39m#\u001b[39;00m\n\u001b[1;32m    226\u001b[0m     \u001b[39m# See Note [Global dependencies]\u001b[39;00m\n\u001b[1;32m    227\u001b[0m     \u001b[39mif\u001b[39;00m USE_GLOBAL_DEPS:\n\u001b[0;32m--> 228\u001b[0m         _load_global_deps()\n\u001b[1;32m    229\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_C\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m  \u001b[39m# noqa: F403\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[39m# Appease the type checker; ordinarily this binding is inserted by the\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \u001b[39m# torch._C module initialization code in C\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/ml4gland/lib/python3.9/site-packages/torch/__init__.py:168\u001b[0m, in \u001b[0;36m_load_global_deps\u001b[0;34m()\u001b[0m\n\u001b[1;32m    165\u001b[0m lib_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mdirname(here), \u001b[39m'\u001b[39m\u001b[39mlib\u001b[39m\u001b[39m'\u001b[39m, lib_name)\n\u001b[1;32m    167\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 168\u001b[0m     ctypes\u001b[39m.\u001b[39;49mCDLL(lib_path, mode\u001b[39m=\u001b[39;49mctypes\u001b[39m.\u001b[39;49mRTLD_GLOBAL)\n\u001b[1;32m    169\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    170\u001b[0m     \u001b[39m# Can only happen for wheel with cuda libs as PYPI deps\u001b[39;00m\n\u001b[1;32m    171\u001b[0m     \u001b[39m# As PyTorch is not purelib, but nvidia-*-cu11 is\u001b[39;00m\n\u001b[1;32m    172\u001b[0m     cuda_libs: Dict[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m {\n\u001b[1;32m    173\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mcublas\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mlibcublas.so.*[0-9]\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m    174\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mcudnn\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mlibcudnn.so.*[0-9]\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mnvtx\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mlibnvToolsExt.so.*[0-9]\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m    184\u001b[0m     }\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/ml4gland/lib/python3.9/ctypes/__init__.py:374\u001b[0m, in \u001b[0;36mCDLL.__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_FuncPtr \u001b[39m=\u001b[39m _FuncPtr\n\u001b[1;32m    373\u001b[0m \u001b[39mif\u001b[39;00m handle \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 374\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle \u001b[39m=\u001b[39m _dlopen(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name, mode)\n\u001b[1;32m    375\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    376\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle \u001b[39m=\u001b[39m handle\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define training transformations\n",
    "from eugene.dataload._augment import RandomRC\n",
    "\n",
    "def seq_trans(x):\n",
    "    x = np.char.upper(x)\n",
    "    x = sp.ohe(x, sp.alphabets.DNA)\n",
    "    x = x.swapaxes(1, 2)\n",
    "    return x\n",
    "\n",
    "def cov_dtype(x):\n",
    "    return tuple(arr.astype('f4') for arr in x)\n",
    "\n",
    "def jitter(x):\n",
    "    return sp.jitter(*x, max_jitter=128, length_axis=-1, jitter_axes=0)\n",
    "\n",
    "def to_tensor(x):\n",
    "    return tuple(torch.tensor(arr, dtype=torch.float32) for arr in x)\n",
    "\n",
    "def random_rc(x):\n",
    "    return RandomRC()(*x)\n",
    "\n",
    "# Get the train dataloader\n",
    "dl = sd.get_torch_dataloader(\n",
    "    sdata_train,\n",
    "    sample_dims=['_sequence'],\n",
    "    variables=['cleaned_seq', 'control', 'signal'],\n",
    "    prefetch_factor=None,\n",
    "    batch_size=32,\n",
    "    transforms={\n",
    "        ('cleaned_seq', 'control', 'signal'): jitter,\n",
    "        'cleaned_seq': seq_trans,\n",
    "        'signal': lambda x: x[..., 557:-557],\n",
    "        ('control', 'signal'): cov_dtype,\n",
    "        ('control', 'cleaned_seq', 'signal'): to_tensor,\n",
    "        ('signal', 'control', 'cleaned_seq'): random_rc\n",
    "    },\n",
    "    shuffle=True,\n",
    "    return_tuples=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1432"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eugene import plot as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.training_summary(\"/cellar/users/aklie/projects/ML4GLand/EUGENe_paper/logs/revision/bpnet/BPNet/v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many b'N' characters exist in \"cleaned_seq\"\n",
    "(sdata[\"cleaned_seq\"] == b\"N\").sum().values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 ml4gland",
   "language": "python",
   "name": "ml4gland"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
