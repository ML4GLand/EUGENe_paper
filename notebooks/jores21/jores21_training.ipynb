{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jores et al 2021 Training \n",
    "**Authorship:**\n",
    "Adam Klie (last updated: *06/08/2023*)\n",
    "***\n",
    "**Description:**\n",
    "Notebook to perform simple training of models on the Jores et al (2021) dataset. You can also use the `jores21_training.py` script as well if you want to run it that way.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cellar/users/aklie/opt/miniconda3/envs/ml4gland/lib/python3.9/site-packages/lightning_utilities/core/imports.py:116: UserWarning: Unbuilt egg for seqpro [unknown version] (/cellar/users/aklie/projects/ML4GLand/SeqPro)\n",
      "  pkg_resources.require(self.requirement)\n",
      "/cellar/users/aklie/opt/miniconda3/envs/ml4gland/lib/python3.9/site-packages/lightning_utilities/core/imports.py:116: UserWarning: Unbuilt egg for seqpro [unknown version] (/cellar/users/aklie/projects/ML4GLand/SeqPro)\n",
      "  pkg_resources.require(self.requirement)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.9.16 | packaged by conda-forge | (main, Feb  1 2023, 21:39:03) \n",
      "[GCC 11.3.0]\n",
      "NumPy version: 1.23.5\n",
      "Pandas version: 1.5.2\n",
      "Eugene version: 0.0.8\n",
      "SeqData version: 0.0.1\n",
      "MotifData version: 0.0.1\n",
      "PyTorch version: 2.0.0\n",
      "PyTorch Lightning version: 2.0.0\n"
     ]
    }
   ],
   "source": [
    "# General imports\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from copy import deepcopy \n",
    "import pytorch_lightning\n",
    "\n",
    "# EUGENe imports and settings\n",
    "import eugene as eu\n",
    "from eugene import dataload as dl\n",
    "from eugene import models\n",
    "from eugene import train\n",
    "from eugene import settings\n",
    "settings.dataset_dir = \"/cellar/users/aklie/data/eugene/revision/jores21\"\n",
    "settings.output_dir = \"/cellar/users/aklie/projects/ML4GLand/EUGENe_paper/output/jores21\"\n",
    "settings.logging_dir = \"/cellar/users/aklie/projects/ML4GLand/EUGENe_paper/logs/jores21\"\n",
    "settings.config_dir = \"/cellar/users/aklie/projects/ML4GLand/EUGENe_paper/configs/jores21\"\n",
    "\n",
    "# EUGENe packages\n",
    "import seqdata as sd\n",
    "import motifdata as md\n",
    "\n",
    "# Print versions\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"Eugene version: {eu.__version__}\")\n",
    "print(f\"SeqData version: {sd.__version__}\")\n",
    "print(f\"MotifData version: {md.__version__}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"PyTorch Lightning version: {pytorch_lightning.__version__}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load in the `leaf`, `proto` and `combined` `SeqData`s "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the preprocessed training data\n",
    "sdata_leaf = sd.open_zarr(os.path.join(settings.dataset_dir, \"jores21_leaf_train.zarr\"))\n",
    "sdata_proto = sd.open_zarr(os.path.join(settings.dataset_dir, \"jores21_proto_train.zarr\"))\n",
    "sdata_combined = dl.concat_seqdatas([sdata_leaf, sdata_proto], [\"leaf\", \"proto\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in PFMs to initialize the 1st layer of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MotifSet with 78 motifs"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grab motifs\n",
    "core_promoter_elements = md.read_meme(os.path.join(settings.dataset_dir, \"CPEs.meme\"))\n",
    "tf_clusters = md.read_meme(os.path.join(settings.dataset_dir, \"TF-clusters.meme\"))\n",
    "\n",
    "# Smush them together, make function in the future\n",
    "all_motifs = deepcopy(core_promoter_elements)\n",
    "for motif in tf_clusters:\n",
    "    all_motifs.add_motif(motif)\n",
    "all_motifs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[rank: 0] Global seed set to 0\n",
      "[rank: 0] Global seed set to 0\n",
      "[rank: 0] Global seed set to 0\n",
      "[rank: 0] Global seed set to 0\n"
     ]
    }
   ],
   "source": [
    "# Function for instantiating a new randomly initialized model\n",
    "def prep_new_model(\n",
    "    config,\n",
    "    seed\n",
    "):\n",
    "    # Instantiate the model\n",
    "    model = models.load_config(config_path=config, seed=seed)\n",
    "    \n",
    "    # Initialize the model prior to conv filter initialization\n",
    "    models.init_weights(model, initializer=\"kaiming_normal\")\n",
    "\n",
    "    # Initialize the conv filters\n",
    "    if model.arch_name == \"Jores21CNN\":\n",
    "        layer_name = \"arch.biconv.kernels\"\n",
    "        list_index = 0\n",
    "    elif model.arch_name in [\"CNN\", \"Hybrid\", \"DeepSTARR\"]:\n",
    "        layer_name = \"arch.conv1d_tower.layers.0\"\n",
    "        list_index = None\n",
    "    models.init_motif_weights(\n",
    "        model=model,\n",
    "        layer_name=layer_name,\n",
    "        list_index=list_index,\n",
    "        initializer=\"xavier_uniform\",\n",
    "        motifs=all_motifs,\n",
    "        convert_to_pwm=False,\n",
    "        divide_by_bg=True,\n",
    "        motif_align=\"left\",\n",
    "        kernel_align=\"left\"\n",
    "    )\n",
    "\n",
    "    # Return the model\n",
    "    return model \n",
    "\n",
    "# Test the instantiation of each model to make sure this is working properly\n",
    "model = prep_new_model(\"cnn.yaml\", seed=0)\n",
    "model = prep_new_model(\"hybrid.yaml\", seed=0)\n",
    "model = prep_new_model(\"jores21_cnn.yaml\", seed=0)\n",
    "model = prep_new_model(\"deepstarr.yaml\", seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceModule(\n",
       "  (arch): DeepSTARR(\n",
       "    (conv1d_tower): Conv1DTower(\n",
       "      (layers): Sequential(\n",
       "        (0): Conv1d(4, 246, kernel_size=(7,), stride=(1,), padding=same)\n",
       "        (1): BatchNorm1d(246, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): MaxPool1d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "        (4): Conv1d(246, 60, kernel_size=(3,), stride=(1,), padding=same)\n",
       "        (5): BatchNorm1d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): ReLU()\n",
       "        (7): MaxPool1d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "        (8): Conv1d(60, 60, kernel_size=(5,), stride=(1,), padding=same)\n",
       "        (9): BatchNorm1d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (10): ReLU()\n",
       "        (11): MaxPool1d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "        (12): Conv1d(60, 120, kernel_size=(3,), stride=(1,), padding=same)\n",
       "        (13): BatchNorm1d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (14): ReLU()\n",
       "        (15): MaxPool1d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_block): DenseBlock(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=19920, out_features=256, bias=True)\n",
       "        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Dropout(p=0.4, inplace=False)\n",
       "        (4): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): ReLU()\n",
       "        (7): Dropout(p=0.4, inplace=False)\n",
       "        (8): Linear(in_features=256, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (train_metric): R2Score()\n",
       "  (val_metric): R2Score()\n",
       "  (test_metric): R2Score()\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train 5 models with 5 different random initializations -- NOTE: this is just configured for testing, run jores21_training.py for the full training\n",
    "training_sets = {\"leaf\": sdata_leaf, \"proto\": sdata_proto, \"combined\": sdata_combined}\n",
    "configs = [\"cnn.yaml\", \"hybrid.yaml\", \"jores21_cnn.yaml\", \"deepstarr.yaml\"]\n",
    "trials = 1\n",
    "for training_set in training_sets:\n",
    "    for trial in range(1, trials+1):\n",
    "        for config in configs:\n",
    "\n",
    "            # Print the model name\n",
    "            sdata = training_sets[training_set]\n",
    "            model_name = config.split(\".\")[0]\n",
    "            print(f\"{training_set} {model_name} trial {trial}\")\n",
    "\n",
    "            # Initialize the model\n",
    "            model = prep_new_model(config, seed=trial)\n",
    "\n",
    "            # Fit the model\n",
    "            train.fit_sequence_module(\n",
    "                model,\n",
    "                sdata,\n",
    "                seq_key=\"ohe_seq\",\n",
    "                target_keys=[\"enrichment\"],\n",
    "                in_memory=True,\n",
    "                train_key=\"train_val\",\n",
    "                epochs=5,\n",
    "                batch_size=128,\n",
    "                num_workers=4,\n",
    "                prefetch_factor=2,\n",
    "                drop_last=False,\n",
    "                name=model_name,\n",
    "                version=f\"{training_set}_trial_{trial}\",\n",
    "                seq_transforms={\"ohe_seq\": lambda x: torch.tensor(x, dtype=torch.float32).transpose(1, 2), \"target\": lambda x: torch.tensor(x, dtype=torch.float32)},\n",
    "                seed=trial\n",
    "            )\n",
    "\n",
    "            # Make room for the next model \n",
    "            del model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DONE!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check file generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the logging directory for all the models\n",
    "!tree -L 3 /cellar/users/aklie/projects/ML4GLand/EUGENe_paper/logs/fix_full/jores21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that the logging directory has the correct number of models using Python\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Get the list of models\n",
    "model_dirs = glob.glob(\"/cellar/users/aklie/projects/ML4GLand/EUGENe_paper/logs/fix_full/jores21/*\")\n",
    "model_dirs = [x for x in model_dirs if os.path.isdir(x)]\n",
    "for model_dir in model_dirs:\n",
    "    model_type = model_dir.split(\"/\")[-1]\n",
    "    print(f\"{model_type}: {len(glob.glob(os.path.join(model_dir, '*')))}\")\n",
    "\n",
    "    # Make sure their is a ckpt file in the checkpoint directory within each model directory\n",
    "    num_ckpt = len(glob.glob(os.path.join(model_dir, \"*\", \"checkpoints\", \"*\")))\n",
    "    print(\"  \", f\"checkpoints: {num_ckpt}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 ml4gland",
   "language": "python",
   "name": "ml4gland"
  },
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
