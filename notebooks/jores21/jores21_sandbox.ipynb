{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'autoreload' not in get_ipython().extension_manager.loaded:\n",
    "    %load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from copy import deepcopy \n",
    "\n",
    "# EUGENe imports and settings\n",
    "from eugene import models\n",
    "from eugene import train\n",
    "from eugene import settings\n",
    "settings.dataset_dir = \"/cellar/users/aklie/data/eugene/revision/jores21\"\n",
    "settings.output_dir = \"/cellar/users/aklie/projects/ML4GLand/EUGENe_paper/output/revision/jores21\"\n",
    "settings.logging_dir = \"/cellar/users/aklie/projects/ML4GLand/EUGENe_paper/logs/revision/jores21\"\n",
    "settings.config_dir = \"/cellar/users/aklie/projects/ML4GLand/EUGENe_paper/configs/jores21\"\n",
    "\n",
    "# EUGENe packages\n",
    "import seqdata as sd\n",
    "import motifdata as md"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Jores21CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "from eugene.models.base import _layers as layers\n",
    "from eugene.models.base import _blocks as blocks\n",
    "from eugene.models.base import _towers as towers\n",
    "\n",
    "\n",
    "class BiConv1DTower(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        filters: int,\n",
    "        kernel_size: int,\n",
    "        input_size: int = 4, \n",
    "        n_layers: int = 1, \n",
    "        stride: int = 1, \n",
    "        dropout_rate: float = 0.15\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.input_size = input_size\n",
    "        if n_layers < 1:\n",
    "            raise ValueError(\"At least one layer needed\")\n",
    "        self.n_layers = n_layers\n",
    "        if (dropout_rate < 0) or (dropout_rate > 1):\n",
    "            raise ValueError(\"Dropout rate must be a float between 0 and 1\")\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.stride = stride\n",
    "        self.layers = nn.ModuleList()\n",
    "        for i in range(0, self.n_layers):\n",
    "            if i == 0:\n",
    "                in_channels = self.input_size\n",
    "            else:\n",
    "                in_channels = self.filters\n",
    "            layer = nn.Conv1d(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=self.filters,\n",
    "                kernel_size=self.kernel_size,\n",
    "                stride=self.stride,\n",
    "                padding=\"same\",\n",
    "            )\n",
    "            kernel = nn.Parameter(torch.empty((self.filters, in_channels, self.kernel_size)))\n",
    "            nn.init.xavier_uniform_(kernel)\n",
    "            bias = nn.Parameter(torch.empty((self.filters)))\n",
    "            nn.init.zeros_(bias)\n",
    "            layer.weight = kernel\n",
    "            layer.bias = bias\n",
    "            self.layers.append(layer)\n",
    "            self.layers.append(nn.ReLU(inplace=False))\n",
    "            self.layers.append(nn.Dropout(p=self.dropout_rate))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_fwd = F.conv1d(x, self.layers[0].weight, stride=self.stride, padding=\"same\")\n",
    "        x_fwd = torch.add(x_fwd.transpose(1, 2), self.layers[0].bias).transpose(1, 2)\n",
    "        x_fwd = self.layers[1](x_fwd)\n",
    "        x_fwd = self.layers[2](x_fwd)\n",
    "        x_rev = F.conv1d(x, torch.flip(self.layers[0].weight, dims=[0, 1]), stride=self.stride, padding=\"same\")\n",
    "        x_rev = torch.add(x_rev.transpose(1, 2), self.layers[0].bias).transpose(1, 2)\n",
    "        x_rev = self.layers[1](x_rev)\n",
    "        x_rev = self.layers[2](x_rev)\n",
    "        for i in range(1, self.n_layers):\n",
    "            x_fwd = F.conv1d(x_fwd, self.layers[i*3].weight, stride=self.stride, padding=\"same\")\n",
    "            x_fwd = torch.add(x_fwd.transpose(1, 2), self.layers[i*3].bias).transpose(1, 2)\n",
    "            x_fwd = self.layers[i*3+1](x_fwd)\n",
    "            x_fwd = self.layers[i*3+2](x_fwd)\n",
    "            x_rev = F.conv1d(x_rev, torch.flip(self.layers[i*3].weight, dims=[0, 1]), stride=self.stride, padding=\"same\")\n",
    "            x_rev = torch.add(x_rev.transpose(1, 2), self.layers[i*3].bias).transpose(1, 2)\n",
    "            x_rev = self.layers[i*3+1](x_rev)\n",
    "            x_rev = self.layers[i*3+2](x_rev)\n",
    "        return torch.add(x_fwd, x_rev)\n",
    "\n",
    "class Jores21CNN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_len: int,\n",
    "        output_dim: int,\n",
    "        filters: int = 128,\n",
    "        kernel_size: int = 13,\n",
    "        layers: int = 2,\n",
    "        stride: int = 1,\n",
    "        dropout: float = 0.15,\n",
    "        hidden_dim: int = 64,\n",
    "    ):\n",
    "        super(Jores21CNN, self).__init__()\n",
    "\n",
    "        # Set the attributes\n",
    "        self.input_len = input_len\n",
    "        self.output_dim = output_dim\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.layers = layers\n",
    "        self.stride = stride\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Create the blocks\n",
    "        self.biconv = BiConv1DTower(\n",
    "            filters=filters,\n",
    "            kernel_size=kernel_size,\n",
    "            n_layers=layers,\n",
    "            stride=stride,\n",
    "            dropout_rate=dropout,\n",
    "        )\n",
    "        self.conv = nn.Conv1d(\n",
    "            in_channels=filters,\n",
    "            out_channels=filters,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            padding=\"same\",\n",
    "        )\n",
    "        self.relu = nn.ReLU(inplace=False)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.fc = nn.Linear(in_features=input_len * filters, out_features=hidden_dim)\n",
    "        self.batchnorm = nn.BatchNorm1d(num_features=hidden_dim)\n",
    "        self.relu2 = nn.ReLU(inplace=False)\n",
    "        self.fc2 = nn.Linear(in_features=hidden_dim, out_features=output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.biconv(x)\n",
    "        x = self.conv(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x.view(x.shape[0], -1))\n",
    "        x = self.batchnorm(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biconv_tower = BiConv1DTower(\n",
    "    filters=256,\n",
    "    kernel_size=13,\n",
    "    input_size=4,\n",
    "    n_layers=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(10, 4, 170)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biconv_tower(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Jores21CNN(\n",
    "    input_len=170,\n",
    "    output_dim=1,\n",
    "    filters=256,\n",
    "    kernel_size=13,\n",
    "    layers=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "sys.path.append(\"/cellar/users/aklie/projects/ML4GLand/EUGENe_paper/scripts/jores21\")\n",
    "from jores21_helpers import BiConv1DTower, Jores21CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biconv_tower = BiConv1DTower(\n",
    "    filters=256,\n",
    "    kernel_size=13,\n",
    "    input_size=4,\n",
    "    n_layers=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biconv_tower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(10, 4, 170)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biconv_tower(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Jores21CNN(\n",
    "    input_len=170,\n",
    "    output_dim=1,\n",
    "    filters=256,\n",
    "    kernel_size=13,\n",
    "    layers=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eugene import plot as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.training_summary(\"/cellar/users/aklie/projects/ML4GLand/EUGENe_paper/logs/revision/jores21/jores21_cnn_nn/leaf_trial_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.training_summary(\"/cellar/users/aklie/projects/ML4GLand/EUGENe_paper/logs/revision/jores21/jores21_cnn/leaf_trial_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import importlib\n",
    "from eugene import settings, models\n",
    "settings.config_dir = \"/cellar/users/aklie/projects/ML4GLand/EUGENe_paper/configs/jores21\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_config_nn(\n",
    "    config_path, \n",
    "    **kwargs\n",
    "):\n",
    "    # If config path is just a filename, assume it's in the default config directory\n",
    "    if \"/\" not in config_path:\n",
    "        config_path = os.path.join(settings.config_dir, config_path)\n",
    "    with open(config_path, \"r\") as f:\n",
    "        config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "    module_name = config.pop(\"module\")\n",
    "    model_params = config.pop(\"model\")\n",
    "    arch_name = model_params[\"arch_name\"]\n",
    "    arch = model_params[\"arch\"]\n",
    "    model_type = getattr(importlib.import_module(\"jores21_helpers\"), arch_name)\n",
    "    model = model_type(**arch)\n",
    "    module_type = getattr(importlib.import_module(\"eugene.models\"), module_name)\n",
    "    module = module_type(model, **config, **kwargs)\n",
    "    return module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_config_nn(\"jores21_cnn_nn.yaml\", seed=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchinfo.summary(model, input_size=(10, 4, 170))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.get_layer(model, \"arch.biconv.dropouts\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.list_available_layers(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0].T[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.relu(x)[0].T[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.dropout(F.relu(x), p=0.3, training=True)[0].T[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.arch.biconv.dropouts[0](model.arch.biconv.relus[0](x))[0].T[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import importlib\n",
    "import torch\n",
    "from eugene import settings, models\n",
    "settings.config_dir = \"/cellar/users/aklie/projects/ML4GLand/EUGENe_paper/configs/jores21\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = models.load_config(\"jores21_cnn.yaml\", seed=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(10, 4, 170)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2(x) == model2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.arch.biconv.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.arch.biconv.training = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.arch.biconv.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchinfo.summary(model2, input_size=(10, 4, 170))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jores21CNN model filter activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import logging\n",
    "import os\n",
    "from typing import Callable, Dict\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self, model: nn.Module, key_word: str, index: int = None):\n",
    "        super().__init__()\n",
    "        print(\"here\")\n",
    "        self.model = model\n",
    "        layers = sorted([k for k in dict([*model.named_modules()]) if key_word in k])\n",
    "        self.features = {layer: torch.empty(0) for layer in layers}\n",
    "        self.handles = dict()\n",
    "        self.index = index\n",
    "\n",
    "        for layerID in layers:\n",
    "            layer = dict([*self.model.named_modules()])[layerID]\n",
    "            handle = layer.register_forward_hook(self.SaveOutputHook(layerID, self.index))\n",
    "            self.handles[layerID] = handle\n",
    "            \n",
    "    def SaveOutputHook(self, layerID: str, index: int = None) -> Callable:\n",
    "        def fn(layer, input, output):\n",
    "            if self.index is not None:\n",
    "                self.features[layerID] = output[self.index]\n",
    "            else:\n",
    "                self.features[layerID] = output\n",
    "        return fn\n",
    "\n",
    "    def forward(self, x, **kwargs) -> Dict[str, torch.Tensor]:\n",
    "        preds = self.model(x, **kwargs)\n",
    "        return self.features, self.handles, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_name = \"arch.conv1d_tower.layers.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = FeatureExtractor(model, layer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = sdata[\"ohe_seq\"].transpose(\"_sequence\", \"_ohe\", \"length\").values[:128]\n",
    "torch_seqs = torch.tensor(sequences, dtype=torch.float32).to(\"cuda\")\n",
    "torch_seqs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(torch_seqs)[0][layer_name][0].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "def get_layer(\n",
    "    model, \n",
    "    layer_name,\n",
    "    index=None\n",
    "):\n",
    "    if index is not None:\n",
    "        return dict([*model.named_modules()])[layer_name][index]\n",
    "    else:\n",
    "        return dict([*model.named_modules()])[layer_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = get_layer(model, layer_name, index=0)\n",
    "layer_outs = F.relu(F.conv1d(torch_seqs, layer)).detach().cpu().numpy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter viz padding fun!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the layer you want to interpret\n",
    "layer_name = \"arch.conv1d_tower.layers.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "# Grab motifs\n",
    "core_promoter_elements = md.read_meme(os.path.join(settings.dataset_dir, \"CPEs.meme\"))\n",
    "tf_clusters = md.read_meme(os.path.join(settings.dataset_dir, \"TF-clusters.meme\"))\n",
    "\n",
    "# Smush them together, make function in the future\n",
    "all_motifs = deepcopy(core_promoter_elements)\n",
    "for motif in tf_clusters:\n",
    "    all_motifs.add_motif(motif)\n",
    "all_motifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for instantiating a new randomly initialized model\n",
    "def prep_new_model(\n",
    "    config,\n",
    "    seed\n",
    "):\n",
    "    # Instantiate the model\n",
    "    model = models.load_config(config_path=config, seed=seed)\n",
    "    \n",
    "    # Initialize the model prior to conv filter initialization\n",
    "    models.init_weights(model, initializer=\"kaiming_normal\")\n",
    "\n",
    "    # Initialize the conv filters\n",
    "    if model.arch_name == \"Jores21CNN\":\n",
    "        layer_name = \"arch.biconv.kernels\"\n",
    "        list_index = 0\n",
    "    elif model.arch_name in [\"CNN\", \"Hybrid\", \"DeepSTARR\"]:\n",
    "        layer_name = \"arch.conv1d_tower.layers.0\"\n",
    "        list_index = None\n",
    "    models.init_motif_weights(\n",
    "        model=model,\n",
    "        layer_name=layer_name,\n",
    "        list_index=list_index,\n",
    "        initializer=\"xavier_uniform\",\n",
    "        motifs=all_motifs,\n",
    "        convert_to_pwm=False,\n",
    "        divide_by_bg=True,\n",
    "        motif_align=\"left\",\n",
    "        kernel_align=\"left\"\n",
    "    )\n",
    "\n",
    "    # Return the model\n",
    "    return model \n",
    "\n",
    "# Test the instantiation of each model to make sure this is working properly\n",
    "model = prep_new_model(\"jores21_cnn.yaml\", seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Biconv kernel\n",
    "kernel = models.get_layer(model, \"arch.biconv.kernels\")[0]\n",
    "bias = models.get_layer(model, \"arch.biconv.biases\")[0]\n",
    "layer = torch.nn.Conv1d(\n",
    "    in_channels=kernel.shape[1],\n",
    "    out_channels=kernel.shape[0],\n",
    "    kernel_size=kernel.shape[2],\n",
    "    padding=3,\n",
    ")\n",
    "layer.weight = torch.nn.Parameter(kernel)\n",
    "layer.bias = torch.nn.Parameter(bias)\n",
    "layer.eval().to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN kernel\n",
    "layer = models.get_layer(model, layer_name)\n",
    "layer.eval().to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer.weight[0].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_seq(X_np[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_seq(X_np[0, :, 0:13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer(X[0, :, 0:13])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer(X[0, :, 1:14])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer(X[0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_np = sdata[\"ohe_seq\"].transpose(\"_sequence\", \"_ohe\", \"length\").to_numpy()\n",
    "X = torch.tensor(X_np, dtype=torch.float32).to(device=\"cuda\")\n",
    "activations = F.relu(layer(X)).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqexplainer._utils import _k_largest_index_argsort\n",
    "from seqexplainer.preprocess._preprocess import decode_seq, ohe_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_filter = activations[:, 0, :]\n",
    "large_inds = _k_largest_index_argsort(single_filter, k=10)\n",
    "single_filter.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind in large_inds:\n",
    "    print(ind)\n",
    "    print(single_filter[ind[0], ind[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, seq in enumerate(X_np[large_inds[:, 0]]):\n",
    "    print(i)\n",
    "    start = large_inds[i, 1] - 6\n",
    "    end = large_inds[i, 1] + 7\n",
    "    print(decode_seq(seq)[start:end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate pfms from filters\n",
    "interpret.generate_pfms_sdata(\n",
    "    model,\n",
    "    sdata,\n",
    "    seq_key=\"ohe_seq\",\n",
    "    layer_name=layer_name,\n",
    "    kernel_size=13,\n",
    "    activations=activations,\n",
    "    num_filters=1,\n",
    "    padding=3,\n",
    "    seqs=sdata[\"ohe_seq\"].transpose(\"_sequence\", \"_ohe\", \"length\").to_numpy(),\n",
    "    num_seqlets=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a filter of choice\n",
    "pl.filter_viz(\n",
    "    sdata,\n",
    "    filter_num=0,\n",
    "    pfms_key=f\"{layer_name}_pfms\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data stuff (sort this later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata = sd.open_zarr(os.path.join(settings.dataset_dir, \"jores21_leaf_train.zarr\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata[\"ohe_seq\"].shape, sdata[\"train_val\"].to_dataframe().value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_key = \"ohe_seq\"\n",
    "target_keys = \"enrichment\"\n",
    "train_key = \"train_val\"\n",
    "seq_transforms = {seq_key: lambda x: torch.tensor(x, dtype=torch.float32).permute(0, 2, 1)}\n",
    "batch_size = 128\n",
    "num_workers = 4\n",
    "drop_last = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(target_keys, str):\n",
    "    target_keys = [target_keys]\n",
    "if len(target_keys) == 1:\n",
    "    sdata[\"target\"] = sdata[target_keys[0]]\n",
    "else:\n",
    "    sdata[\"target\"] = xr.concat([sdata[target_key] for target_key in target_keys], dim=\"_targets\").transpose(\"_sequence\", \"_targets\")\n",
    "targs = sdata[\"target\"].values\n",
    "if len(targs.shape) == 1:\n",
    "    nan_mask = np.isnan(targs)\n",
    "else:\n",
    "    nan_mask = np.any(np.isnan(targs), axis=1)\n",
    "print(f\"Dropping {nan_mask.sum()} sequences with NaN targets.\")\n",
    "sdata = sdata.isel(_sequence=~nan_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data into memory\n",
    "sdata[\"ohe_seq\"].load()\n",
    "sdata[\"enrichment\"].load()\n",
    "sdata[\"train_val\"].load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targs = sdata[\"enrichment\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_mask = xr.DataArray(np.isnan(targs), dims=[\"_sequence\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata = sdata.where(~nan_mask, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Dropping {int(nan_mask.sum().values)} sequences with NaN targets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata.where(sdata[\"train_val\"], drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata.where(~sdata[\"train_val\"], drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata.where(~sdata.train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask = np.where(sdata[train_key])[0]\n",
    "train_sdata = sdata.isel(_sequence=train_mask)\n",
    "val_sdata = sdata.isel(_sequence=~train_mask)\n",
    "train_dataloader = sd.get_torch_dataloader(\n",
    "    train_sdata,\n",
    "    sample_dims=[\"_sequence\"],\n",
    "    variables=[seq_key, \"target\"],\n",
    "    transforms=seq_transforms,\n",
    "    prefetch_factor=2,\n",
    "    shuffle=True,\n",
    "    drop_last=drop_last,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "val_dataloader = sd.get_torch_dataloader(\n",
    "    val_sdata,\n",
    "    sample_dims=[\"_sequence\"],\n",
    "    variables=[seq_key, \"target\"],\n",
    "    transforms=seq_transforms,\n",
    "    prefetch_factor=2,\n",
    "    shuffle=False,\n",
    "    drop_last=drop_last,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_sdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_dataloader))\n",
    "batch_ohe_seq = batch[seq_key]\n",
    "batch_target = batch[\"target\"]\n",
    "batch_ohe_seq.shape, batch_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, batch in tqdm(enumerate(train_dataloader), total=len(train_dataloader), desc=\"Looping over train dataloader\"):\n",
    "    batch_ohe_seq = batch[seq_key]\n",
    "    batch_target = batch[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, batch in tqdm(enumerate(val_dataloader), total=len(val_dataloader), desc=\"Looping over val dataloader\"):\n",
    "    batch_ohe_seq = batch[seq_key]\n",
    "    batch_target = batch[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, batch in enumerate(val_dataloader):\n",
    "    batch_ohe_seq = batch[seq_key]\n",
    "    batch_target = batch[\"target\"]\n",
    "    print(batch_ohe_seq.shape, batch_target.shape)\n",
    "    if i > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_decode = batch_ohe_seq[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_decode.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DNA = [\"A\", \"C\", \"G\", \"T\"]\n",
    "RNA = [\"A\", \"C\", \"G\", \"U\"]\n",
    "\n",
    "def _get_vocab(vocab):\n",
    "    if vocab == \"DNA\":\n",
    "        return DNA\n",
    "    elif vocab == \"RNA\":\n",
    "        return RNA\n",
    "    else:\n",
    "        raise ValueError(\"Invalid vocab, only DNA or RNA are currently supported\")\n",
    "\n",
    "# exact concise\n",
    "def _get_index_dict(vocab):\n",
    "    \"\"\"\n",
    "    Returns a dictionary mapping each token to its index in the vocabulary.\n",
    "    \"\"\"\n",
    "    return {i: l for i, l in enumerate(vocab)}\n",
    "\n",
    "# modified dinuc_shuffle\n",
    "def _one_hot2token(one_hot, neutral_value=-1, consensus=False):\n",
    "    \"\"\"\n",
    "    Converts a one-hot encoding into a vector of integers in the range [0, D]\n",
    "    where D is the number of classes in the one-hot encoding.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    one_hot : np.array\n",
    "        L x D one-hot encoding\n",
    "    neutral_value : int, optional\n",
    "        Value to use for neutral values.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    np.array\n",
    "        L-vector of integers in the range [0, D]\n",
    "    \"\"\"\n",
    "    if consensus:\n",
    "        return np.argmax(one_hot, axis=0)\n",
    "    tokens = np.tile(neutral_value, one_hot.shape[1])  # Vector of all D\n",
    "    seq_inds, dim_inds = np.where(one_hot.transpose()==1)\n",
    "    tokens[seq_inds] = dim_inds\n",
    "    return tokens\n",
    "\n",
    "def _sequencize(tvec, vocab=\"DNA\", neutral_value=-1, neutral_char=\"N\"):\n",
    "    \"\"\"\n",
    "    Converts a token vector into a sequence of symbols of a vocab.\n",
    "    \"\"\"\n",
    "    vocab = _get_vocab(vocab) \n",
    "    index_dict = _get_index_dict(vocab)\n",
    "    index_dict[neutral_value] = neutral_char\n",
    "    return \"\".join([index_dict[i] for i in tvec])\n",
    "\n",
    "def decode_seq(arr, vocab=\"DNA\", neutral_value=-1, neutral_char=\"N\"):\n",
    "    \"\"\"Convert a single one-hot encoded array back to string\"\"\"\n",
    "    if isinstance(arr, torch.Tensor):\n",
    "        arr = arr.numpy()\n",
    "    return _sequencize(\n",
    "        tvec=_one_hot2token(arr, neutral_value),\n",
    "        vocab=vocab,\n",
    "        neutral_value=neutral_value,\n",
    "        neutral_char=neutral_char,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_seq(to_decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_target[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfm_dfs = pfms_to_df_dict(pfms)\n",
    "ppms = pfms_to_ppms(pfms, pseudocount=1)\n",
    "pwms = ppms_to_pwms(ppms)\n",
    "infos = ppms_to_igms(ppms)\n",
    "ppics = per_position_ic(ppms)\n",
    "tot_ics = ppics.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by total information content\n",
    "sort_idx = np.argsort(tot_ics)[::-1]\n",
    "sort_idx[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from seqexplainer import evolution\n",
    "def evolve_seqs_sdata(\n",
    "    model: torch.nn.Module, \n",
    "    sdata, \n",
    "    rounds: int, \n",
    "    seq_key: str = \"ohe_seq\",\n",
    "    axis_order = (\"_sequence\", \"_ohe\", \"length\"),\n",
    "    add_seqs=True,\n",
    "    return_seqs: bool = False, \n",
    "    device: str = \"cpu\", \n",
    "    batch_size: int = 128,\n",
    "    copy: bool = False, \n",
    "    **kwargs\n",
    "):\n",
    "    \"\"\"\n",
    "    In silico evolve a set of sequences that are stored in a SeqData object.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model: torch.nn.Module  \n",
    "        The model to score the sequences with\n",
    "    sdata: SeqData  \n",
    "        The SeqData object containing the sequences to evolve\n",
    "    rounds: int\n",
    "        The number of rounds of evolution to perform\n",
    "    return_seqs: bool, optional\n",
    "        Whether to return the evolved sequences\n",
    "    device: str, optional\n",
    "        Whether to use a 'cpu' or 'cuda'.\n",
    "    copy: bool, optional\n",
    "        Whether to copy the SeqData object before mutating it\n",
    "    kwargs: dict, optional\n",
    "        Additional arguments to pass to the evolution function\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    sdata: SeqData\n",
    "        The SeqData object containing the evolved sequences\n",
    "    \"\"\"\n",
    "\n",
    "    sdata = sdata.copy() if copy else sdata\n",
    "\n",
    "    # Set device\n",
    "    device = \"cuda\" if settings.gpus > 0 else \"cpu\" if device is None else device\n",
    "\n",
    "    # Grab seqs\n",
    "    ohe_seqs = sdata[seq_key].transpose(*axis_order).to_numpy()\n",
    "    evolved_seqs = np.zeros(ohe_seqs.shape)\n",
    "    deltas = np.zeros((sdata_evolve.dims[\"_sequence\"], rounds))\n",
    "    \n",
    "    # Evolve seqs\n",
    "    for i, ohe_seq in tqdm(enumerate(ohe_seqs), total=len(ohe_seqs), desc=\"Evolving seqs\"):\n",
    "        evolved_seq, delta, _ = evolution(model, ohe_seq, rounds=rounds, device=device)\n",
    "        evolved_seqs[i] = evolved_seq\n",
    "        deltas[i, :] = deltas[i, :] + delta\n",
    "\n",
    "    # Get original scores\n",
    "    orig_seqs = torch.tensor(ohe_seqs, dtype=torch.float32).to(device)\n",
    "    original_scores = model.predict(orig_seqs, batch_size=batch_size, verbose=False).detach().cpu().numpy().squeeze()\n",
    "\n",
    "    # Put evolved scores into sdata\n",
    "    sdata[\"original_score\"] = xr.DataArray(original_scores, dims=\"_sequence\")\n",
    "    sdata[\"evolved_1_score\"] = xr.DataArray(original_scores + deltas[:, 0], dims=\"_sequence\")\n",
    "    for i in range(2, rounds + 1):\n",
    "        sdata[f\"evolved_{i}_score\"] = xr.DataArray(sdata[f\"evolved_{i-1}_score\"] + deltas[:, i - 1], dims=\"_sequence\")\n",
    "    if return_seqs:\n",
    "        evolved_seqs = torch.tensor(evolved_seqs, dtype=torch.float32)\n",
    "        return evolved_seqs\n",
    "    if add_seqs:\n",
    "        sdata[\"evolved_seqs\"] = xr.DataArray(evolved_seqs, dims=(\"_sequence\", \"_ohe\", \"length\"))\n",
    "    return sdata if copy else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqexplainer.preprocess._preprocess import dinuc_shuffle_seq\n",
    "consensus, dinuc_shuffle_seq(consensus), k_shuffle(consensus, k=2).tobytes().decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if using naiveISM\n",
    "sdata[\"ohe_seq\"] = sdata[\"ohe_seq\"].transpose(\"_sequence\", \"_ohe\", \"length\")\n",
    "X1 = sdata[\"ohe_seq\"].values\n",
    "X2 = (sdata[f\"{method}_attrs\"]*-1).sum(dim=\"_ohe\").values\n",
    "X1.shape, X2.shape\n",
    "# Multiply the one-hot encoded sequence with the saliency scores. X1 has shape 128,4,170 and X2 has shape 128,170.\n",
    "# We need to expand X2 to 128,4,170 to be able to multiply it with X1.\n",
    "X2 = np.expand_dims(X2, axis=1)\n",
    "X2 = np.repeat(X2, 4, axis=1)\n",
    "X2.shape\n",
    "X = X1 * X2\n",
    "sdata[f\"{method}_attrs_sum\"] = xr.DataArray(X, dims=[\"_sequence\", \"_ohe\", \"length\"], coords=sdata[\"ohe_seq\"].coords)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 ml4gland",
   "language": "python",
   "name": "ml4gland"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
