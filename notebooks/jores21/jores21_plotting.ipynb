{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "79b5bebd",
   "metadata": {},
   "source": [
    "# Jores et al 2021 Plotting \n",
    "**Authorship:**\n",
    "Adam Klie (last updated: *06/08/2023*)\n",
    "***\n",
    "**Description:**\n",
    "Notebook to generate plots for the Jores et al (2021) dataset that are not included in the other notebooks.\n",
    " - Summary table of benchmarking results for for each model type\n",
    " - Cleaner seq track plots for top sequences\n",
    " - TomTom filter annotation analysis\n",
    " - Loss and metric plots\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f89a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "from itertools import groupby\n",
    "from operator import itemgetter\n",
    "from scipy.stats import mannwhitneyu\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "# EUGENe imports and settings\n",
    "import eugene as eu\n",
    "from eugene import plot as pl\n",
    "from eugene import settings\n",
    "settings.dataset_dir = \"/cellar/users/aklie/data/eugene/revision/jores21\"\n",
    "settings.output_dir = \"/cellar/users/aklie/projects/ML4GLand/EUGENe_paper/output/revision/jores21\"\n",
    "settings.logging_dir = \"/cellar/users/aklie/projects/ML4GLand/EUGENe_paper/logs/revision/jores21\"\n",
    "settings.figure_dir = \"/cellar/users/aklie/projects/ML4GLand/EUGENe_paper/figures/revision/jores21\"\n",
    "\n",
    "# EUGENe packages\n",
    "import seqdata as sd\n",
    "import motifdata as md\n",
    "\n",
    "# For illustrator editing\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "# Print versions\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Eugene version: {eu.__version__}\")\n",
    "print(f\"SeqData version: {sd.__version__}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f025d20c",
   "metadata": {},
   "source": [
    "# Generate performance figures"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1310e70e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Leaf models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70ff176",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read in the predictions \n",
    "leaf_predictions = pd.read_csv(os.path.join(settings.output_dir, \"leaf\", \"leaf_test_predictions.tsv\"), sep=\"\\t\", index_col=0)\n",
    "sdata_leaf = sd.open_zarr(os.path.join(settings.output_dir, \"leaf\", \"leaf_test_predictions.zarr\")).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e965dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get only variables with \"predictions\" in the name\n",
    "preds_vars = [k for k in sdata_leaf.keys() if \"predictions\" in k]\n",
    "\n",
    "# Order the pred_vars from in this order [\"cnn\", \"hyrbrid\", \"jores21_cnn\", \"deepstarr\"]\n",
    "order = [\"cnn\", \"hybrid\", \"deepstarr\", \"jores21_cnn\"]\n",
    "pred_models = [k.split(\"_\")[0] if \"jores21\" not in k else \"jores21_cnn\" for k in preds_vars]\n",
    "pred_models = [order.index(m) for m in pred_models]\n",
    "preds_vars = [k for _, k in sorted(zip(pred_models, preds_vars))]\n",
    "\n",
    "# Get groups based io\n",
    "model_groups = {\"cnn\": \"cnn\", \"hybrid\": \"hybrid\", \"deepstarr\": \"deepstarr\", \"jores21_cnn\": \"jores21_cnn\"}\n",
    "groups = [model_groups[k.split(\"_\")[0]] if \"jores21\" not in k else \"jores21_cnn\" for k in preds_vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f26793",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Summarize performance across models for r2\n",
    "leaf_model_scores = pl.performance_summary(\n",
    "    sdata_leaf,\n",
    "    target_var=\"enrichment\",\n",
    "    prediction_vars=preds_vars,\n",
    "    prediction_groups=groups,\n",
    "    metrics=[\"r2\"],\n",
    "    add_swarm=False,\n",
    "    figsize=(6, 6),\n",
    "    save=os.path.join(settings.figure_dir, \"leaf\", \"leaf_performance_boxplot.pdf\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcd0932-1570-4f84-bec9-80e0250ef53a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate significance of differences between groups\n",
    "pairwise_tests = []\n",
    "compare_df = leaf_model_scores.pivot(columns=\"prediction_groups\", values=\"r2\")\n",
    "pairwise_tests.append(mannwhitneyu(compare_df[\"hybrid\"].dropna(), compare_df[\"jores21_cnn\"].dropna()).pvalue)\n",
    "pairwise_tests.append(mannwhitneyu(compare_df[\"hybrid\"].dropna(), compare_df[\"cnn\"].dropna()).pvalue)\n",
    "pairwise_tests.append(mannwhitneyu(compare_df[\"cnn\"].dropna(), compare_df[\"jores21_cnn\"].dropna()).pvalue)\n",
    "pairwise_tests.append(mannwhitneyu(compare_df[\"deepstarr\"].dropna(), compare_df[\"jores21_cnn\"].dropna()).pvalue)\n",
    "pairwise_tests.append(mannwhitneyu(compare_df[\"deepstarr\"].dropna(), compare_df[\"cnn\"].dropna()).pvalue)\n",
    "pairwise_tests.append(mannwhitneyu(compare_df[\"deepstarr\"].dropna(), compare_df[\"hybrid\"].dropna()).pvalue)\n",
    "pairwise_tests = np.array(pairwise_tests)\n",
    "multipletests(pairwise_tests, alpha=0.05, method=\"fdr_bh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8071a5d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Summarize performance across models for multiple metrics\n",
    "leaf_model_scores = pl.performance_summary(\n",
    "    sdata_leaf,\n",
    "    target_var=\"enrichment\",\n",
    "    prediction_vars=preds_vars,\n",
    "    prediction_groups=groups,\n",
    "    metrics=[\"r2\", \"mse\", \"pearson\", \"spearman\", \"kendall\"],\n",
    "    add_swarm=False,\n",
    "    figsize=(6, 6),\n",
    ")\n",
    "\n",
    "# Identify the best model from returned model scores\n",
    "r2_sorted = leaf_model_scores[\"r2\"].sort_values(ascending=False)\n",
    "r2_sorted.plot(kind=\"bar\", ylabel=\"R2\")\n",
    "plt.savefig(os.path.join(settings.figure_dir, \"leaf\", \"leaf_performance_summary.pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91405b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the performance summary as a table\n",
    "leaf_model_scores.to_csv(os.path.join(settings.output_dir, \"leaf\", \"leaf_performance_summary.tsv\"), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd66c81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the performances across species for the best model\n",
    "best_preds = r2_sorted.index[4]\n",
    "ax = pl.performance_scatter(\n",
    "    sdata_leaf, \n",
    "    target_vars=\"enrichment\", \n",
    "    prediction_vars=best_preds,\n",
    "    alpha=0.5,\n",
    "    groupby=\"sp\",\n",
    "    figsize=(8, 8),\n",
    "    rasterized=True,\n",
    "    save=os.path.join(settings.figure_dir, \"leaf\", \"leaf_best_model_performance_scatter_by_sp.pdf\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c840fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the performance for all species to use in Figure 2 \n",
    "ax = pl.performance_scatter(\n",
    "    sdata_leaf, \n",
    "    target_vars=\"enrichment\", \n",
    "    prediction_vars=best_preds,\n",
    "    alpha=0.5,\n",
    "    figsize=(4, 4),\n",
    "    rasterized=True,\n",
    "    save=os.path.join(settings.figure_dir, \"leaf\", \"leaf_best_model_performance_scatter.pdf\")\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d45842ed",
   "metadata": {},
   "source": [
    "## Proto models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd045829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the predictions \n",
    "proto_predictions = pd.read_csv(os.path.join(settings.output_dir, \"proto\", \"proto_test_predictions.tsv\"), sep=\"\\t\", index_col=0)\n",
    "sdata_proto = sd.open_zarr(os.path.join(settings.output_dir, \"proto\", \"proto_test_predictions.zarr\")).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e06488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get only variables with \"predictions\" in the name\n",
    "preds_vars = [k for k in sdata_proto.keys() if \"predictions\" in k]\n",
    "\n",
    "# Order the pred_vars from in this order [\"cnn\", \"hyrbrid\", \"jores21_cnn\", \"deepstarr\"]\n",
    "order = [\"cnn\", \"hybrid\", \"deepstarr\", \"jores21_cnn\"]\n",
    "pred_models = [k.split(\"_\")[0] if \"jores21\" not in k else \"jores21_cnn\" for k in preds_vars]\n",
    "pred_models = [order.index(m) for m in pred_models]\n",
    "preds_vars = [k for _, k in sorted(zip(pred_models, preds_vars))]\n",
    "\n",
    "# Get groups based io\n",
    "model_groups = {\"cnn\": \"cnn\", \"hybrid\": \"hybrid\", \"deepstarr\": \"deepstarr\", \"jores21_cnn\": \"jores21_cnn\"}\n",
    "groups = [model_groups[k.split(\"_\")[0]] if \"jores21\" not in k else \"jores21_cnn\" for k in preds_vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e3a984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize performance across models for r2\n",
    "proto_model_scores = pl.performance_summary(\n",
    "    sdata_proto,\n",
    "    target_var=\"enrichment\",\n",
    "    prediction_vars=preds_vars,\n",
    "    prediction_groups=groups,\n",
    "    metrics=[\"r2\"],\n",
    "    add_swarm=False,\n",
    "    figsize=(6, 6),\n",
    "    save=os.path.join(settings.figure_dir, \"proto\", \"proto_performance_boxplot.pdf\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693568c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate significance of differences between groups\n",
    "pairwise_tests = []\n",
    "compare_df = proto_model_scores.pivot(columns=\"prediction_groups\", values=\"r2\")\n",
    "pairwise_tests.append(mannwhitneyu(compare_df[\"hybrid\"].dropna(), compare_df[\"jores21_cnn\"].dropna()).pvalue)\n",
    "pairwise_tests.append(mannwhitneyu(compare_df[\"hybrid\"].dropna(), compare_df[\"cnn\"].dropna()).pvalue)\n",
    "pairwise_tests.append(mannwhitneyu(compare_df[\"cnn\"].dropna(), compare_df[\"jores21_cnn\"].dropna()).pvalue)\n",
    "pairwise_tests.append(mannwhitneyu(compare_df[\"deepstarr\"].dropna(), compare_df[\"jores21_cnn\"].dropna()).pvalue)\n",
    "pairwise_tests.append(mannwhitneyu(compare_df[\"deepstarr\"].dropna(), compare_df[\"cnn\"].dropna()).pvalue)\n",
    "pairwise_tests.append(mannwhitneyu(compare_df[\"deepstarr\"].dropna(), compare_df[\"hybrid\"].dropna()).pvalue)\n",
    "pairwise_tests = np.array(pairwise_tests)\n",
    "multipletests(pairwise_tests, alpha=0.05, method=\"fdr_bh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b46c265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize performance across models for multiple metrics\n",
    "proto_model_scores = pl.performance_summary(\n",
    "    sdata_proto,\n",
    "    target_var=\"enrichment\",\n",
    "    prediction_vars=preds_vars,\n",
    "    prediction_groups=groups,\n",
    "    metrics=[\"r2\", \"mse\", \"pearson\", \"spearman\", \"kendall\"],\n",
    "    add_swarm=False,\n",
    "    figsize=(6, 6),\n",
    ")\n",
    "\n",
    "# Identify the best model from returned model scores\n",
    "r2_sorted = proto_model_scores[\"r2\"].sort_values(ascending=False)\n",
    "r2_sorted.plot(kind=\"bar\", ylabel=\"R2\")\n",
    "plt.savefig(os.path.join(settings.figure_dir, \"proto\", \"proto_performance_summary.pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be01c9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the performance summary as a table\n",
    "proto_model_scores.to_csv(os.path.join(settings.output_dir, \"proto\", \"proto_performance_summary.tsv\"), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5579889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the performances across species for the best model\n",
    "best_preds = r2_sorted.index[0]\n",
    "ax = pl.performance_scatter(\n",
    "    sdata_proto, \n",
    "    target_vars=\"enrichment\", \n",
    "    prediction_vars=best_preds,\n",
    "    alpha=0.5,\n",
    "    groupby=\"sp\",\n",
    "    figsize=(8, 8),\n",
    "    rasterized=True,\n",
    "    save=os.path.join(settings.figure_dir, \"proto\", \"proto_best_model_performance_scatter_by_sp.pdf\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fe46e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the performance for all species to use in Figure 2 \n",
    "ax = pl.performance_scatter(\n",
    "    sdata_proto, \n",
    "    target_vars=\"enrichment\", \n",
    "    prediction_vars=best_preds,\n",
    "    alpha=0.5,\n",
    "    figsize=(4, 4),\n",
    "    rasterized=True,\n",
    "    save=os.path.join(settings.figure_dir, \"proto\", \"proto_best_model_performance_scatter.pdf\")\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4e7c6cb2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Combined models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8dfe22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the predictions \n",
    "combined_predictions = pd.read_csv(os.path.join(settings.output_dir, \"combined\", \"combined_test_predictions.tsv\"), sep=\"\\t\", index_col=0)\n",
    "sdata_combined = sd.open_zarr(os.path.join(settings.output_dir, \"combined\", \"combined_test_predictions.zarr\")).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09be7c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get only variables with \"predictions\" in the name\n",
    "preds_vars = [k for k in sdata_combined.keys() if \"predictions\" in k]\n",
    "\n",
    "# Order the pred_vars from in this order [\"cnn\", \"hyrbrid\", \"jores21_cnn\", \"deepstarr\"]\n",
    "order = [\"cnn\", \"hybrid\", \"jores21_cnn\", \"deepstarr\"]\n",
    "pred_models = [k.split(\"_\")[0] if \"jores21\" not in k else \"jores21_cnn\" for k in preds_vars]\n",
    "pred_models = [order.index(m) for m in pred_models]\n",
    "preds_vars = [k for _, k in sorted(zip(pred_models, preds_vars))]\n",
    "\n",
    "# Get groups based io\n",
    "model_groups = {\"cnn\": \"cnn\", \"hybrid\": \"hybrid\", \"jores21_cnn\": \"jores21_cnn\", \"deepstarr\": \"deepstarr\"}\n",
    "groups = [model_groups[k.split(\"_\")[0]] if \"jores21\" not in k else \"jores21_cnn\" for k in preds_vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cedeeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize performance across models for r2\n",
    "combined_model_scores = pl.performance_summary(\n",
    "    sdata_combined,\n",
    "    target_var=\"enrichment\",\n",
    "    prediction_vars=preds_vars,\n",
    "    prediction_groups=groups,\n",
    "    metrics=[\"r2\"],\n",
    "    add_swarm=False,\n",
    "    figsize=(6, 6),\n",
    "    save=os.path.join(settings.figure_dir, \"combined\", \"combined_performance_boxplot.pdf\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79436cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate significance of differences between groups\n",
    "pairwise_tests = []\n",
    "compare_df = combined_model_scores.pivot(columns=\"prediction_groups\", values=\"r2\")\n",
    "pairwise_tests.append(mannwhitneyu(compare_df[\"hybrid\"].dropna(), compare_df[\"jores21_cnn\"].dropna()).pvalue)\n",
    "pairwise_tests.append(mannwhitneyu(compare_df[\"hybrid\"].dropna(), compare_df[\"cnn\"].dropna()).pvalue)\n",
    "pairwise_tests.append(mannwhitneyu(compare_df[\"cnn\"].dropna(), compare_df[\"jores21_cnn\"].dropna()).pvalue)\n",
    "pairwise_tests.append(mannwhitneyu(compare_df[\"deepstarr\"].dropna(), compare_df[\"jores21_cnn\"].dropna()).pvalue)\n",
    "pairwise_tests.append(mannwhitneyu(compare_df[\"deepstarr\"].dropna(), compare_df[\"cnn\"].dropna()).pvalue)\n",
    "pairwise_tests.append(mannwhitneyu(compare_df[\"deepstarr\"].dropna(), compare_df[\"hybrid\"].dropna()).pvalue)\n",
    "pairwise_tests = np.array(pairwise_tests)\n",
    "multipletests(pairwise_tests, alpha=0.05, method=\"fdr_bh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef051b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize performance across models for multiple metrics\n",
    "combined_model_scores = pl.performance_summary(\n",
    "    sdata_combined,\n",
    "    target_var=\"enrichment\",\n",
    "    prediction_vars=preds_vars,\n",
    "    prediction_groups=groups,\n",
    "    metrics=[\"r2\", \"mse\", \"pearson\", \"spearman\", \"kendall\"],\n",
    "    add_swarm=False,\n",
    "    figsize=(6, 6),\n",
    ")\n",
    "\n",
    "# Identify the best model from returned model scores\n",
    "r2_sorted = combined_model_scores[\"r2\"].sort_values(ascending=False)\n",
    "r2_sorted.plot(kind=\"bar\", ylabel=\"R2\")\n",
    "plt.savefig(os.path.join(settings.figure_dir, \"combined\", \"combined_performance_summary.pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d840139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the performance summary as a table\n",
    "combined_model_scores.to_csv(os.path.join(settings.output_dir, \"combined\", \"combined_performance_summary.tsv\"), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd947082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the performances across species for the best model\n",
    "best_preds = r2_sorted.index[1]\n",
    "ax = pl.performance_scatter(\n",
    "    sdata_combined, \n",
    "    target_vars=\"enrichment\", \n",
    "    prediction_vars=best_preds,\n",
    "    alpha=0.5,\n",
    "    groupby=\"sp\",\n",
    "    figsize=(8, 8),\n",
    "    rasterized=True,\n",
    "    save=os.path.join(settings.figure_dir, \"combined\", \"combined_best_model_performance_scatter_by_sp.pdf\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e21fcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the performance for all species to use in Figure 2 \n",
    "ax = pl.performance_scatter(\n",
    "    sdata_combined, \n",
    "    target_vars=\"enrichment\", \n",
    "    prediction_vars=best_preds,\n",
    "    alpha=0.5,\n",
    "    figsize=(4, 4),\n",
    "    rasterized=True,\n",
    "    save=os.path.join(settings.figure_dir, \"combined\", \"combined_best_model_performance_scatter.pdf\")\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5a6cf2c4",
   "metadata": {},
   "source": [
    "# Performance summary table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f963128c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined everything into one dataframe\n",
    "leaf_model_scores[\"model\"] = \"leaf\"\n",
    "proto_model_scores[\"model\"] = \"proto\"\n",
    "combined_model_scores[\"model\"] = \"combined\"\n",
    "merged_model_scores = pd.concat([leaf_model_scores, proto_model_scores, combined_model_scores])\n",
    "merged_model_scores.to_csv(os.path.join(settings.output_dir, \"merged_performance_summary.tsv\"), sep=\"\\t\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f1982dc3",
   "metadata": {},
   "source": [
    "# Cleaner seq track logos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b4a06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set-up model\n",
    "model = \"leaf\"\n",
    "trial = 5\n",
    "model_type = \"hybrid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abddabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in importances\n",
    "sdata_interpretations = sd.open_zarr(os.path.join(settings.output_dir, model, f\"{model}_test_predictions_and_interpretations.zarr\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b171b969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the highest predicted seqs for the best model\n",
    "top5 = sdata_interpretations[f\"{model_type}_trial_{trial}_enrichment_predictions\"].to_series().sort_values(ascending=False).iloc[:5].index\n",
    "top5_idx = np.argsort(sdata_interpretations[f\"{model_type}_trial_{trial}_enrichment_predictions\"].values)[::-1][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eed7b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the ranges in each seq where the model gives high interpretations\n",
    "seq_num, seq_pos = np.where(np.sum(sdata_interpretations[\"DeepLift_attrs\"].values[top5_idx], axis=1) > 0.01)\n",
    "ranges = []\n",
    "\n",
    "# Find the continuous ranges of high interpretation that are longer than 3 and allow for multiple ranges per seq\n",
    "for i in np.unique(seq_num):\n",
    "    ranges_i = []\n",
    "    for k, g in groupby(enumerate(seq_pos[seq_num == i]), lambda x: x[0] - x[1]):\n",
    "        group = list(map(itemgetter(1), g))\n",
    "        if len(group) > 3:\n",
    "            ranges_i.append((group[0], group[-1]))\n",
    "    ranges.append(ranges_i)\n",
    "ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0671fa01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the top 5 with the ranges\n",
    "ids = sdata_interpretations[\"id\"].values[top5_idx]\n",
    "for i in range(5):\n",
    "    pl.seq_track(\n",
    "        sdata_interpretations,\n",
    "        seq_id=ids[i],\n",
    "        attrs_var=\"DeepLift_attrs\",\n",
    "        ylab=\"DeepLift\",\n",
    "        highlights=ranges[i],\n",
    "        figsize=(8, 1),\n",
    "        save=os.path.join(settings.figure_dir, model, f\"{model}_best_model_feature_attr_{i+1}.pdf\"),\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "527be9da",
   "metadata": {},
   "source": [
    "# TomTom annotation analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a053c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which model?\n",
    "model = \"proto\"\n",
    "trial = 3\n",
    "model_type = \"jores21_cnn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c85b642",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Grab and combine the results from annotating CPEs and TF clusters\n",
    "tomtom_cpe = pd.read_csv(os.path.join(settings.output_dir, model, f\"{model}_best_model_filters_tomtom_CPE.tsv\"), sep=\"\\t\")\n",
    "tomtom_tf = pd.read_csv(os.path.join(settings.output_dir, model, f\"{model}_best_model_filters_tomtom_TF.tsv\"), sep=\"\\t\")\n",
    "tomtom_df = pd.concat([tomtom_cpe, tomtom_tf], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad369546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as a dataframe\n",
    "tomtom_df.to_csv(os.path.join(settings.output_dir, model, f\"{model}_best_model_filters_tomtom.tsv\"), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2c47cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset to significant hits\n",
    "tomtom_sig = tomtom_df[tomtom_df[\"q-value\"] <= 0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adee51fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the filter number as a column\n",
    "tomtom_sig[\"filter_num\"] = tomtom_sig[\"Query_ID\"].str.split(\"filter_\").str[-1].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa63922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate into filters that were instantiated and those that were purely learned\n",
    "tomtom_sig_init = tomtom_sig[tomtom_sig[\"filter_num\"] <= 77]\n",
    "tomtom_sig_learned = tomtom_sig[tomtom_sig[\"filter_num\"] > 77]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd49ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many of the original filters returned significant hits?\n",
    "len(tomtom_sig_init[\"Target_ID\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6b546c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the instantiated filters into CPE and TF hits\n",
    "tomtom_sig_init_tf = tomtom_sig_init[tomtom_sig_init[\"Target_ID\"].str.contains(\"TF\")]\n",
    "tomtom_sig_init_cpe = tomtom_sig_init[(tomtom_sig_init[\"Target_ID\"].str.contains(\"TF\") == False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616540c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the cluster numbers for the TF hits\n",
    "tomtom_sig_init_tf[\"TF_cluster_number\"] = tomtom_sig_init_tf[\"Target_ID\"].str.split(\"_\").str[-1]\n",
    "tomtom_sig_init_tf[\"TF_cluster_number\"] = tomtom_sig_init_tf[\"TF_cluster_number\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205dd9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how many of the initialized TF clusters remained significant to their initialization\n",
    "(tomtom_sig_init_tf[\"TF_cluster_number\"] + 5 == tomtom_sig_init_tf[\"filter_num\"]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3db2b19-4c7c-4202-88ac-cf54afaa032a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a naming map for plotting\n",
    "core_promoter_elements = md.read_meme(os.path.join(settings.dataset_dir, 'CPEs.meme'))\n",
    "tf_clusters = md.read_meme(os.path.join(settings.dataset_dir, 'TF-clusters.meme'))\n",
    "\n",
    "# Smush them together, make function in the future\n",
    "all_motifs = deepcopy(core_promoter_elements)\n",
    "for motif in tf_clusters:\n",
    "    all_motifs.add_motif(motif)\n",
    "all_motifs\n",
    "id_map = {}\n",
    "for motif in all_motifs:\n",
    "    id_map[motif.identifier] = motif.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ce986d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the frequencies of hits to motifs in the learned filters\n",
    "plt.figure(figsize=(6, 3), dpi=300)\n",
    "tomtom_sig_learned_counts = tomtom_sig_learned[\"Target_ID\"].map(id_map).value_counts()\n",
    "tomtom_sig_learned_counts.plot(kind=\"bar\", ylabel=\"Number of filters\")\n",
    "plt.savefig(os.path.join(settings.figure_dir, model, f\"{model}_best_model_filters_tomtom_barplot.pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e83930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the counts as a dataframe\n",
    "tomtom_sig_learned_counts_df = tomtom_sig_learned_counts.to_frame()\n",
    "tomtom_sig_learned_counts_df[\"system\"] = model\n",
    "tomtom_sig_learned_counts_df.to_csv(os.path.join(settings.output_dir, model, f\"{model}_best_model_filters_tomtom_learned_motif_counts.tsv\"), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc67a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the most significant hits to each motif\n",
    "top_tomtom_sig_learned = tomtom_sig_learned.sort_values(\"q-value\").groupby(\"Target_ID\").head(1)\n",
    "top_tomtom_sig_learned.to_csv(os.path.join(settings.output_dir, model, f\"{model}_best_model_filters_tomtom_top_hits.tsv\"), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4056e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hits\n",
    "idxs = top_tomtom_sig_learned[\"filter_num\"].values\n",
    "hit_names = top_tomtom_sig_learned[\"Target_ID\"].map(id_map).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a021fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in importances\n",
    "sdata_interpretations = sd.open_zarr(os.path.join(settings.output_dir, model, f\"{model}_test_predictions_and_interpretations.zarr\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cff12bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the key for the pfms\n",
    "keys = pd.Index(sdata_interpretations.data_vars.keys())\n",
    "pfm_var = keys[keys.str.contains(\"pfms\")].values[0]\n",
    "pfm_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb369fab-5bd1-4388-b15d-83a4b9fcd3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a filter of choice\n",
    "for i, idx in enumerate(idxs):\n",
    "    pl.filter_viz(\n",
    "        sdata_interpretations,\n",
    "        pfms_var=pfm_var,\n",
    "        filter_num=idx,\n",
    "        save=os.path.join(settings.figure_dir, model, f\"{model}_best_model_filter{idx}_rank{i}_viz.pdf\"),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d7e744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a filter of choice\n",
    "pl.filter_viz(\n",
    "    sdata_interpretations,\n",
    "    pfms_var=pfm_var,\n",
    "    filter_num=179,\n",
    "    save=os.path.join(settings.figure_dir, model, f\"{model}_best_model_filter179_viz.pdf\"),\n",
    "    title=f\"Filter 179\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9dd3abdd",
   "metadata": {},
   "source": [
    "# Save all the TomTom results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbebe3c4-5c29-4d41-a186-51ad84163944",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save as a dataframe\n",
    "merged_df = pd.DataFrame()\n",
    "for model in [\"leaf\", \"proto\", \"combined\"]:\n",
    "    x = pd.read_csv(os.path.join(eu.settings.output_dir, model, f\"{model}_best_model_filters_tomtom.tsv\"), sep=\"\\t\", comment=\"#\", index_col=0)\n",
    "    x[\"system\"] = model\n",
    "    merged_df = pd.concat([merged_df, x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754a748b-100d-4b87-884a-a3376a78b107",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remove na Query_IDs\n",
    "merged_df = merged_df[~merged_df[\"Query_ID\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7163f5f-e2f5-4524-931f-a2e002f8e4fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the merged dataframe\n",
    "merged_df.to_csv(os.path.join(eu.settings.output_dir, \"best_models_filters_tomtom.tsv\"), sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ae3c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as a dataframe\n",
    "merged_counts_df = pd.DataFrame()\n",
    "for model in [\"leaf\", \"proto\", \"combined\"]:\n",
    "    x = pd.read_csv(os.path.join(settings.output_dir, model, f\"{model}_best_model_filters_tomtom_learned_motif_counts.tsv\"), sep=\"\\t\", comment=\"#\")\n",
    "    merged_counts_df = pd.concat([merged_counts_df, x])\n",
    "merged_counts_df = merged_counts_df[merged_counts_df[\"Target_ID\"] > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f27e650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the frequencies of hits to motifs in the learned filters, colored by system with 3 non-default colors\n",
    "plt.figure(figsize=(4, 3), dpi=300)\n",
    "\n",
    "# Set the color palette\n",
    "sns.set_palette(sns.color_palette(\"Set2\"))\n",
    "ax = sns.barplot(data=merged_counts_df, x=\"Unnamed: 0\", y=\"Target_ID\", hue=\"system\")\n",
    "ax.set_ylabel(\"Number of filters\")\n",
    "ax.set_xlabel(\"\")\n",
    "for item in ax.get_xticklabels():\n",
    "    item.set_rotation(90)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(settings.figure_dir, f\"best_model_filters_tomtom_barplot.pdf\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aac3e0bd",
   "metadata": {},
   "source": [
    "# Loss curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9606a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which model?\n",
    "model = \"combined\"\n",
    "trial = 5\n",
    "model_type = \"deepstarr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f4faf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot and save the training and metric curves\n",
    "pl.training_summary(\n",
    "    os.path.join(settings.logging_dir, model_type, f\"{model}_trial_{trial}\"),\n",
    "    metric=\"r2\",\n",
    "    save=os.path.join(settings.figure_dir, model, f\"{model}_best_model_training_summary.pdf\")\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2a2c6f4b",
   "metadata": {},
   "source": [
    "# DONE!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "23089b0d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1562364e",
   "metadata": {},
   "source": [
    "# Scratch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 ml4gland",
   "language": "python",
   "name": "ml4gland"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
