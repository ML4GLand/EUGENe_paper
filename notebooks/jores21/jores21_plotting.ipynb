{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79b5bebd",
   "metadata": {},
   "source": [
    "# Jores et al 2021 Plotting \n",
    "**Authorship:**\n",
    "Adam Klie, *09/12/2022*\n",
    "***\n",
    "**Description:**\n",
    "Notebook to generate plots for the Jores et al (2021) dataset that are not included in the other notebooks.\n",
    " - Summary table of benchmarking results for for each model type\n",
    " - Cleaner seq track plots for top sequences\n",
    " - TomTom filter annotation analysis\n",
    " - Loss and metric plots\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027007c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if 'autoreload' not in get_ipython().extension_manager.loaded:\n",
    "    %load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import logging\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import eugene as eu\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from scipy.stats import mannwhitneyu\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "# For illustrator editing\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14731522",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Configure directories\n",
    "eu.settings.dataset_dir = \"/cellar/users/aklie/data/eugene/jores21\"\n",
    "eu.settings.output_dir = \"/cellar/users/aklie/projects/EUGENe/EUGENe_paper/output/jores21\"\n",
    "eu.settings.logging_dir = \"/cellar/users/aklie/projects/EUGENe/EUGENe_paper/logs/jores21\"\n",
    "eu.settings.config_dir = \"/cellar/users/aklie/projects/EUGENe/EUGENe_paper/configs/jores21\"\n",
    "eu.settings.figure_dir = \"/cellar/users/aklie/projects/EUGENe/EUGENe_paper/figures/jores21\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f025d20c",
   "metadata": {},
   "source": [
    "# Generate performance figures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1310e70e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Leaf models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70ff176",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read in the predictions \n",
    "sdata_leaf = eu.dl.read_h5sd(os.path.join(eu.settings.output_dir, \"leaf\", \"leaf_test_predictions.h5sd\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f26793",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Summarize performance across models for r2\n",
    "leaf_model_scores = eu.pl.performance_summary(\n",
    "    sdata_leaf,\n",
    "    target_key=\"enrichment\",\n",
    "    prediction_groups=[\"Jores21CNN\"]*5 + [\"ssCNN\"]*5 + [\"ssHybrid\"]*5,\n",
    "    metrics=[\"r2\"],\n",
    "    add_swarm=False,\n",
    "    figsize=(6, 6),\n",
    "    save=os.path.join(eu.settings.figure_dir, \"leaf_performance_boxplot.pdf\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcd0932-1570-4f84-bec9-80e0250ef53a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate significance of differences between groups\n",
    "pairwise_tests = []\n",
    "compare_df = leaf_model_scores.pivot(columns=\"prediction_groups\", values=\"r2\")\n",
    "pairwise_tests.append(mannwhitneyu(compare_df[\"ssHybrid\"].dropna(), compare_df[\"Jores21CNN\"].dropna()).pvalue)\n",
    "pairwise_tests.append(mannwhitneyu(compare_df[\"ssHybrid\"].dropna(), compare_df[\"ssCNN\"].dropna()).pvalue)\n",
    "pairwise_tests.append(mannwhitneyu(compare_df[\"ssCNN\"].dropna(), compare_df[\"Jores21CNN\"].dropna()).pvalue)\n",
    "multipletests(pairwise_tests, alpha=0.05, method=\"fdr_bh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8071a5d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Summarize performance across models for multiple metrics\n",
    "leaf_model_scores = eu.pl.performance_summary(\n",
    "    sdata_leaf,\n",
    "    target_key=\"enrichment\",\n",
    "    prediction_groups=[\"Jores21CNN\"]*5 + [\"ssCNN\"]*5 + [\"ssHybrid\"]*5,\n",
    "    metrics=[\"r2\", \"mse\", \"pearson\", \"spearman\", \"kendall\"],\n",
    "    add_swarm=False,\n",
    "    figsize=(6, 6),\n",
    ")\n",
    "\n",
    "# Identify the best model from returned model scores\n",
    "r2_sorted = leaf_model_scores[\"r2\"].sort_values(ascending=False)\n",
    "r2_sorted.plot(kind=\"bar\", ylabel=\"R2\")\n",
    "plt.savefig(os.path.join(eu.settings.figure_dir, \"leaf_performance_summary.pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91405b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the performance summary as a table\n",
    "leaf_model_scores.to_csv(os.path.join(eu.settings.output_dir, \"leaf_performance_summary.tsv\"), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd66c81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the performances across species for the best model\n",
    "best_preds = r2_sorted.index[0]\n",
    "ax = eu.pl.performance_scatter(\n",
    "    sdata_leaf, \n",
    "    target_keys=\"enrichment\", \n",
    "    prediction_keys=best_preds,\n",
    "    alpha=0.5,\n",
    "    groupby=\"sp\",\n",
    "    figsize=(8, 8),\n",
    "    rasterized=True,\n",
    "    save=os.path.join(eu.settings.figure_dir, \"leaf_best_model_performance_scatter_by_sp.pdf\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c840fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the performance for all species to use in Figure 2 \n",
    "ax = eu.pl.performance_scatter(\n",
    "    sdata_leaf, \n",
    "    target_keys=\"enrichment\", \n",
    "    prediction_keys=best_preds,\n",
    "    alpha=0.5,\n",
    "    figsize=(4, 4),\n",
    "    rasterized=True,\n",
    "    save=os.path.join(eu.settings.figure_dir, \"leaf_best_model_performance_scatter.pdf\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b7a9e3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Proto models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5607ab1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read in if already made predictions and generated file above\n",
    "sdata_proto = eu.dl.read_h5sd(os.path.join(eu.settings.output_dir, \"proto\", \"proto_test_predictions.h5sd\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d31e40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Summarize performance across models for r2\n",
    "proto_model_scores = eu.pl.performance_summary(\n",
    "    sdata_proto,\n",
    "    target_key=\"enrichment\",\n",
    "    prediction_groups=[\"Jores21CNN\"]*5 + [\"ssCNN\"]*5 + [\"ssHybrid\"]*5,\n",
    "    metrics=[\"r2\"],\n",
    "    add_swarm=False,\n",
    "    figsize=(6, 6),\n",
    "    save=os.path.join(eu.settings.figure_dir, \"proto_performance_boxplot.pdf\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b88d0e7-2dfe-446b-88bc-0d08853b9d59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate significance of differences between groups\n",
    "pairwise_tests = []\n",
    "compare_df = proto_model_scores.pivot(columns=\"prediction_groups\", values=\"r2\")\n",
    "pairwise_tests.append(mannwhitneyu(compare_df[\"ssHybrid\"].dropna(), compare_df[\"Jores21CNN\"].dropna()).pvalue)\n",
    "pairwise_tests.append(mannwhitneyu(compare_df[\"ssHybrid\"].dropna(), compare_df[\"ssCNN\"].dropna()).pvalue)\n",
    "pairwise_tests.append(mannwhitneyu(compare_df[\"ssCNN\"].dropna(), compare_df[\"Jores21CNN\"].dropna()).pvalue)\n",
    "multipletests(pairwise_tests, alpha=0.05, method=\"fdr_bh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e16a9c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Summarize performance across models for a metric\n",
    "proto_model_scores = eu.pl.performance_summary(\n",
    "    sdata_proto,\n",
    "    target_key=\"enrichment\",\n",
    "    prediction_groups=[\"Jores21CNN\"]*5 + [\"ssCNN\"]*5 + [\"ssHybrid\"]*5,\n",
    "    metrics=[\"r2\", \"mse\", \"pearson\", \"spearman\", \"kendall\"],\n",
    "    add_swarm=False,\n",
    "    figsize=(6, 6),\n",
    ")\n",
    "\n",
    "# Identify the best model from returned model scores\n",
    "r2_sorted = proto_model_scores[\"r2\"].sort_values(ascending=False)\n",
    "r2_sorted.plot(kind=\"bar\", ylabel=\"R2\")\n",
    "plt.savefig(os.path.join(eu.settings.figure_dir, \"proto_performance_summary.pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d728d29d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the performances across species for the best model\n",
    "best_preds = r2_sorted.index[0]\n",
    "ax = eu.pl.performance_scatter(\n",
    "    sdata_proto, \n",
    "    target_keys=\"enrichment\", \n",
    "    prediction_keys=best_preds,\n",
    "    alpha=0.5,\n",
    "    groupby=\"sp\",\n",
    "    figsize=(8, 8),\n",
    "    rasterized=True,\n",
    "    save=os.path.join(eu.settings.figure_dir, \"proto_best_model_performance_scatter_by_sp.pdf\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa9aad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the performance summary as a table\n",
    "proto_model_scores.to_csv(os.path.join(eu.settings.output_dir, \"proto_performance_summary.tsv\"), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7c6cb2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Combined models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c16f4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read in if already made predictions and generated file above\n",
    "sdata_combined = eu.dl.read_h5sd(os.path.join(eu.settings.output_dir, \"combined\", \"combined_test_predictions.h5sd\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593aed53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Summarize performance across models for a metric\n",
    "combined_model_scores = eu.pl.performance_summary(\n",
    "    sdata_combined,\n",
    "    target_key=\"enrichment\",\n",
    "    prediction_groups=[\"Jores21CNN\"]*5 + [\"ssCNN\"]*5 + [\"ssHybrid\"]*5,\n",
    "    metrics=[\"r2\"],\n",
    "    add_swarm=False,\n",
    "    figsize=(6, 6),\n",
    "    save= os.path.join(eu.settings.figure_dir, \"combined_performance_boxplot.pdf\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ffa92d-172c-47e5-9d02-d27c3f34947f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate significance of differences between groups\n",
    "pairwise_tests = []\n",
    "compare_df = combined_model_scores.pivot(columns=\"prediction_groups\", values=\"r2\")\n",
    "pairwise_tests.append(mannwhitneyu(compare_df[\"ssHybrid\"].dropna(), compare_df[\"Jores21CNN\"].dropna()).pvalue)\n",
    "pairwise_tests.append(mannwhitneyu(compare_df[\"ssHybrid\"].dropna(), compare_df[\"ssCNN\"].dropna()).pvalue)\n",
    "pairwise_tests.append(mannwhitneyu(compare_df[\"ssCNN\"].dropna(), compare_df[\"Jores21CNN\"].dropna()).pvalue)\n",
    "multipletests(pairwise_tests, alpha=0.05, method=\"fdr_bh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5f4b49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Summarize performance across models for a metric\n",
    "combined_model_scores = eu.pl.performance_summary(\n",
    "    sdata_combined,\n",
    "    target_key=\"enrichment\",\n",
    "    prediction_groups=[\"Jores21CNN\"]*5 + [\"ssCNN\"]*5 + [\"ssHybrid\"]*5,\n",
    "    metrics=[\"r2\", \"mse\", \"pearson\", \"spearman\", \"kendall\"],\n",
    "    add_swarm=False,\n",
    "    figsize=(6, 6),\n",
    ")\n",
    "\n",
    "# Identify the best model from returned model scores\n",
    "r2_sorted = combined_model_scores[\"r2\"].sort_values(ascending=False)\n",
    "r2_sorted.plot(kind=\"bar\", ylabel=\"R2\")\n",
    "plt.savefig(os.path.join(eu.settings.figure_dir, \"combined_performance_summary.pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be265a5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the performances across species for the best model\n",
    "best_preds = r2_sorted.index[0]\n",
    "ax = eu.pl.performance_scatter(\n",
    "    sdata_combined, \n",
    "    target_keys=\"enrichment\", \n",
    "    prediction_keys=best_preds,\n",
    "    alpha=0.5,\n",
    "    groupby=\"sp\",\n",
    "    figsize=(8, 8),\n",
    "    rasterized=True,\n",
    "    save=os.path.join(eu.settings.figure_dir, \"combined_best_model_performance_scatter_by_sp.pdf\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b868add7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the performance summary as a table\n",
    "combined_model_scores.to_csv(os.path.join(eu.settings.output_dir, \"combined_performance_summary.tsv\"), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6cf2c4",
   "metadata": {},
   "source": [
    "# Performance summary table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f963128c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined everything into one dataframe\n",
    "leaf_model_scores[\"model\"] = \"leaf\"\n",
    "proto_model_scores[\"model\"] = \"proto\"\n",
    "combined_model_scores[\"model\"] = \"combined\"\n",
    "merged_model_scores = pd.concat([leaf_model_scores, proto_model_scores, combined_model_scores])\n",
    "merged_model_scores.to_csv(os.path.join(eu.settings.output_dir, \"merged_performance_summary.tsv\"), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1982dc3",
   "metadata": {},
   "source": [
    "# Cleaner seq track logos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b4a06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set-up model\n",
    "model = \"combined\"\n",
    "trial = 3\n",
    "model_type = \"Jores21CNN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abddabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in importances\n",
    "sdata_interpretations = eu.dl.read_h5sd(os.path.join(eu.settings.output_dir, f\"{model}_test_predictions_and_interpretations.h5sd\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b171b969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the highest predicted seqs for the best model\n",
    "top5 = sdata_interpretations[f\"{model_type}_trial_{trial}_enrichment_predictions\"].sort_values(ascending=False).iloc[:5].index\n",
    "top5_idx = np.argsort(sdata_interpretations[f\"{model_type}_trial_{trial}_enrichment_predictions\"].values)[::-1][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eed7b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the ranges in each seq where the model gives high interpretations\n",
    "seq_num, seq_pos = np.where(np.sum(sdata_interpretations.uns[\"DeepLift_imps\"][top5_idx], axis=1) > 0.2)\n",
    "ranges = []\n",
    "for j in range(5):\n",
    "    curr_pos = seq_pos[np.where(seq_num == j)]\n",
    "    start = curr_pos[0]\n",
    "    motifs = []\n",
    "    for i in range(1, len(curr_pos)):\n",
    "        if curr_pos[i] - curr_pos[i-1] > 3:\n",
    "            start = curr_pos[i]\n",
    "            if curr_pos[i] - start > 4:\n",
    "                    motifs.append((start, curr_pos[i]))\n",
    "    if curr_pos[-1] - start > 4:\n",
    "        motifs.append((start, curr_pos[-1]))\n",
    "    ranges.append(motifs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0671fa01",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    eu.pl.seq_track(\n",
    "        sdata_interpretations,\n",
    "        seq_id=top5[i],\n",
    "        uns_key=\"DeepLift_imps\",\n",
    "        ylabel=\"DeepLift\",\n",
    "        highlights=ranges[i],\n",
    "        figsize=(8, 1),\n",
    "        save=os.path.join(eu.settings.figure_dir, f\"{model}_best_model_feature_attr_{i+1}.pdf\"),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527be9da",
   "metadata": {},
   "source": [
    "# TomTom annotation analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a053c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which model?\n",
    "model = \"leaf\"\n",
    "trial = 5\n",
    "model_type = \"ssHybrid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c85b642",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Grab and combine the results from annotating CPEs and TF clusters\n",
    "tomtom_cpe = pd.read_csv(os.path.join(eu.settings.output_dir, model, f\"{model}_best_model_filters_tomtom_CPE.tsv\"), sep=\"\\t\")\n",
    "tomtom_tf = pd.read_csv(os.path.join(eu.settings.output_dir, model, f\"{model}_best_model_filters_tomtom_TF.tsv\"), sep=\"\\t\")\n",
    "tomtom_df = pd.concat([tomtom_cpe, tomtom_tf], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad369546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as a dataframe\n",
    "tomtom_df.to_csv(os.path.join(eu.settings.output_dir, f\"{model}_best_model_filters_tomtom.tsv\"), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2c47cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset to significant hits\n",
    "tomtom_sig = tomtom_df[tomtom_df[\"q-value\"] <= 0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adee51fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the filter number as a column\n",
    "tomtom_sig[\"filter_num\"] = tomtom_sig[\"Query_ID\"].str.split(\"filter\").str[-1].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa63922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate into filters that were instantiated and those that were purely learned\n",
    "tomtom_sig_init = tomtom_sig[tomtom_sig[\"filter_num\"] <= 77]\n",
    "tomtom_sig_learned = tomtom_sig[tomtom_sig[\"filter_num\"] > 77]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd49ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many of the original filters returned significant hits?\n",
    "len(tomtom_sig_init[\"Target_ID\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6b546c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the instantiated filters into CPE and TF hits\n",
    "tomtom_sig_init_tf = tomtom_sig_init[tomtom_sig_init[\"Target_ID\"].str.contains(\"TF\")]\n",
    "tomtom_sig_init_cpe = tomtom_sig_init[(tomtom_sig_init[\"Target_ID\"].str.contains(\"TF\") == False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616540c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the cluster numbers for the TF hits\n",
    "tomtom_sig_init_tf[\"TF_cluster_number\"] = tomtom_sig_init_tf[\"Target_ID\"].str.split(\"_\").str[-1]\n",
    "tomtom_sig_init_tf[\"TF_cluster_number\"] = tomtom_sig_init_tf[\"TF_cluster_number\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205dd9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how many of the initialized TF clusters remained significant to their initialization\n",
    "(tomtom_sig_init_tf[\"TF_cluster_number\"] + 5 == tomtom_sig_init_tf[\"filter_num\"]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3db2b19-4c7c-4202-88ac-cf54afaa032a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a naming map for plotting\n",
    "core_promoter_elements = eu.dl.motif.MinimalMEME(os.path.join(eu.settings.dataset_dir, 'CPEs.meme'))\n",
    "tf_groups = eu.dl.motif.MinimalMEME(os.path.join(eu.settings.dataset_dir, 'TF-clusters.meme'))\n",
    "all_motifs = {**core_promoter_elements.motifs, **tf_groups.motifs}\n",
    "id_map = {}\n",
    "for id_name, motif in all_motifs.items():\n",
    "    id_map[id_name] = motif.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ce986d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the frequencies of hits to motifs in the learned filters\n",
    "plt.figure(figsize=(6, 3), dpi=300)\n",
    "tomtom_sig_learned[\"Target_ID\"].map(id_map).value_counts().plot(kind=\"bar\", ylabel=\"Number of filters\")\n",
    "plt.savefig(os.path.join(eu.settings.figure_dir, f\"{model}_best_model_filters_tomtom_barplot.pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc67a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the most significant hits to each motif\n",
    "top_tomtom_sig_learned = tomtom_sig_learned.sort_values(\"q-value\").groupby(\"Target_ID\").head(1)\n",
    "top_tomtom_sig_learned.to_csv(os.path.join(eu.settings.output_dir, f\"{model}_best_model_filters_tomtom_top_hits.tsv\"), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fb369fab-5bd1-4388-b15d-83a4b9fcd3d2",
   "metadata": {},
   "source": [
    "# Visualize a filter of choice\n",
    "filter_num = 84\n",
    "hit_name = \"ERF\"\n",
    "eu.pl.filter_viz(\n",
    "    sdata_interpretations,\n",
    "    filter_id=filter_num,\n",
    "    save=os.path.join(eu.settings.figure_dir, \"leaf\", f\"leaf_best_model_filter{filter_num}_viz.pdf\"),\n",
    "    title=f\"Filter {filter_num}: {hit_name}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbebe3c4-5c29-4d41-a186-51ad84163944",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save as a dataframe\n",
    "merged_df = pd.DataFrame()\n",
    "for model in [\"leaf\", \"proto\", \"combined\"]:\n",
    "    x = pd.read_csv(os.path.join(eu.settings.output_dir, model, f\"{model}_best_model_filters_tomtom.tsv\"), sep=\"\\t\", comment=\"#\", index_col=0)\n",
    "    x[\"system\"] = model\n",
    "    merged_df = pd.concat([merged_df, x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754a748b-100d-4b87-884a-a3376a78b107",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged_df = merged_df[~merged_df[\"Query_ID\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7163f5f-e2f5-4524-931f-a2e002f8e4fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged_df.to_csv(os.path.join(eu.settings.output_dir, \"best_models_filters_tomtom.tsv\"), sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac3e0bd",
   "metadata": {},
   "source": [
    "# Loss curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9606a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which model?\n",
    "model = \"combined\"\n",
    "trial = 3\n",
    "model_type = \"Jores21CNN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f4faf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot and save the training and metric curves\n",
    "eu.pl.training_summary(\n",
    "    os.path.join(eu.settings.logging_dir, model_type, f\"{model}_trial_{trial}\"),\n",
    "    metric=\"r2\",\n",
    "    save=os.path.join(eu.settings.figure_dir, f\"{model}_best_model_training_summary.pdf\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987804a6",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 eugene_dev",
   "language": "python",
   "name": "eugene_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
