{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jores et al 2021 Intepretation\n",
    "**Authorship:**\n",
    "Adam Klie (last updated: *06/08/2023*)\n",
    "***\n",
    "**Description:**\n",
    "Notebook to interpret the best trained models on the Jores et al (2021) dataset.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'autoreload' not in get_ipython().extension_manager.loaded:\n",
    "    %load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# EUGENe imports and settings\n",
    "import eugene as eu\n",
    "from eugene import preprocess as pp\n",
    "from eugene import models\n",
    "from eugene import interpret\n",
    "from eugene import plot as pl\n",
    "from eugene import settings\n",
    "settings.dataset_dir = \"/cellar/users/aklie/data/eugene/revision/jores21\"\n",
    "settings.config_dir = \"/cellar/users/aklie/projects/ML4GLand/EUGENe_paper/configs/jores21\"\n",
    "settings.output_dir = \"/cellar/users/aklie/projects/ML4GLand/EUGENe_paper/output/revision/jores21/\"\n",
    "settings.logging_dir = \"/cellar/users/aklie/projects/ML4GLand/EUGENe_paper/logs/revision/jores21\"\n",
    "settings.figure_dir = \"/cellar/users/aklie/projects/ML4GLand/EUGENe_paper/figures/revision/jores21\"\n",
    "\n",
    "# EUGENe packages\n",
    "import seqdata as sd\n",
    "import motifdata as md\n",
    "import seqpro as sp\n",
    "\n",
    "# For illustrator editing\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "# Print versions\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Eugene version: {eu.__version__}\")\n",
    "print(f\"SeqData version: {sd.__version__}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load in the `leaf`, `proto` and `combined` test `SeqData`s "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the preprcoessed test data with predictions\n",
    "sdata_leaf = sd.open_zarr(os.path.join(settings.output_dir, \"leaf\", \"leaf_test_predictions.zarr\"))\n",
    "sdata_proto = sd.open_zarr(os.path.join(settings.output_dir, \"proto\", \"proto_test_predictions.zarr\"))\n",
    "sdata_combined = sd.open_zarr(os.path.join(settings.output_dir, \"combined\", \"combined_test_predictions.zarr\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load them all but will choose one\n",
    "leaf_model_file = glob.glob(os.path.join(settings.logging_dir, \"hybrid\", \"leaf_trial_3\", \"checkpoints\", \"*\"))[0]\n",
    "leaf_model_arch = models.load_config(config_path=\"hybrid.yaml\")\n",
    "leaf_model = models.SequenceModule.load_from_checkpoint(leaf_model_file, arch=leaf_model_arch.arch)\n",
    "proto_model_file = glob.glob(os.path.join(settings.logging_dir, \"jores21_cnn\", \"proto_trial_3\", \"checkpoints\", \"*\"))[0]\n",
    "proto_model_arch = models.load_config(config_path=\"jores21_cnn.yaml\")\n",
    "proto_model = models.SequenceModule.load_from_checkpoint(proto_model_file, arch=proto_model_arch.arch)\n",
    "combined_model_file = glob.glob(os.path.join(settings.logging_dir, \"deepstarr\", \"combined_trial_5\", \"checkpoints\", \"*\"))[0]\n",
    "combined_model_arch = models.load_config(config_path=\"deepstarr.yaml\")\n",
    "combined_model = models.SequenceModule.load_from_checkpoint(combined_model_file, arch=combined_model_arch.arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Choose which model you want to intepret\n",
    "name = \"leaf\"\n",
    "arch = \"hybrid\"\n",
    "trial = 3\n",
    "model = leaf_model\n",
    "sdata = sdata_leaf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Feature attribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run DeepLift with a simple all 0s reference\n",
    "method = \"DeepLift\"\n",
    "interpret.attribute_sdata(\n",
    "    model,\n",
    "    sdata,\n",
    "    method=method,\n",
    "    batch_size=128,\n",
    "    reference_type=\"zero\",\n",
    "    transforms={\"ohe_seq\": lambda x: torch.tensor(x, dtype=torch.float32).permute(0, 2, 1)}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top5 = sdata[f\"{arch}_trial_{trial}_enrichment_predictions\"].to_series().sort_values(ascending=False).iloc[:5].index\n",
    "top5_idx = np.argsort(sdata[f\"{arch}_trial_{trial}_enrichment_predictions\"].values)[::-1][:5]\n",
    "ids = sdata[\"id\"].values[top5_idx]\n",
    "pl.multiseq_track(\n",
    "    sdata,\n",
    "    seq_ids=ids,\n",
    "    attrs_keys = f\"{method}_attrs\",\n",
    "    ylabs=method,\n",
    "    height=3,\n",
    "    width=70,\n",
    "    save=os.path.join(settings.figure_dir, name, f\"{name}_best_model_feature_attr.pdf\")\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Filter viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if arch == \"jores21_cnn\":\n",
    "    model.to(\"cuda\")\n",
    "    layer_name = \"arch.biconv\"\n",
    "    seqs = sdata[\"ohe_seq\"].transpose(\"_sequence\", \"_ohe\", \"length\").to_numpy()\n",
    "    seqs_torch = torch.tensor(seqs, dtype=torch.float32).to(model.device)\n",
    "    kernel = models.get_layer(model, f\"{layer_name}.kernels\")[0].to(model.device)\n",
    "    bias = models.get_layer(model, f\"{layer_name}.biases\")[0].to(model.device)\n",
    "    activations = F.conv1d(seqs_torch, kernel, stride=1, padding=\"same\")\n",
    "    activations = torch.add(activations.transpose(1, 2), bias).transpose(1, 2)\n",
    "    activations = activations.detach().cpu().numpy()\n",
    "    padding = 6\n",
    "    transforms=None\n",
    "    kernel_size = 13\n",
    "    num_filters = 256\n",
    "else:\n",
    "    if arch == \"deepstarr\":\n",
    "        kernel_size = 7\n",
    "        padding = 3\n",
    "        layer_name = \"arch.conv1d_tower.layers.2\"\n",
    "        num_filters = 246\n",
    "    else:\n",
    "        padding = 0\n",
    "        kernel_size = 13\n",
    "        layer_name = \"arch.conv1d_tower.layers.1\"\n",
    "        num_filters = 256\n",
    "    activations = None\n",
    "    seqs = None\n",
    "    transforms={\"ohe_seq\": lambda x: torch.tensor(x, dtype=torch.float32).permute(0, 2, 1)}\n",
    "kernel_size, num_filters, padding, transforms, layer_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate pfms from filters\n",
    "interpret.generate_pfms_sdata(\n",
    "    model,\n",
    "    sdata,\n",
    "    seq_key=\"ohe_seq\",\n",
    "    layer_name=layer_name,\n",
    "    kernel_size=kernel_size,\n",
    "    activations=activations,\n",
    "    seqs=seqs,\n",
    "    num_filters=num_filters,\n",
    "    padding=padding,\n",
    "    num_seqlets=100,\n",
    "    transforms=transforms,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a filter of choice\n",
    "pl.filter_viz(\n",
    "    sdata,\n",
    "    filter_num=179,\n",
    "    pfms_key=f\"{layer_name}_pfms\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize multiple filters at once and save\n",
    "for i in range(8):\n",
    "    start_filter = i*32\n",
    "    end_filter = (i*32) + 32\n",
    "    print(f\"Plotting and saving filters {start_filter+1}-{end_filter}\")\n",
    "    pl.multifilter_viz(\n",
    "        sdata,\n",
    "        filter_nums=range(start_filter, end_filter),\n",
    "        pfms_key=f\"{layer_name}_pfms\",\n",
    "        num_rows=8,\n",
    "        num_cols=4,\n",
    "        titles=[f\"filter {i}\" for i in range(start_filter, end_filter)],\n",
    "        save=os.path.join(settings.figure_dir, name, f\"{name}_best_model_filters{start_filter+1}-{end_filter}_viz.pdf\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all the filter pfms from above as meme format for submission to TomTom\n",
    "interpret.filters_to_meme_sdata(\n",
    "    sdata,\n",
    "    filters_key=f\"{layer_name}_pfms\",\n",
    "    output_dir=os.path.join(settings.output_dir, name),\n",
    "    filename=f\"{name}_best_model_filters.meme\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the predictions and interpretations to zarr\n",
    "sd.to_zarr(sdata, os.path.join(settings.output_dir, name, f\"{name}_test_predictions_and_interpretations.zarr\"), load_first=True, mode=\"w\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *in silico* evolution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in sequences that were evolved in the published paper\n",
    "sdata_evolve = sd.read_table(\n",
    "    name=\"seq\",\n",
    "    tables=os.path.join(settings.dataset_dir, \"promoters_for_evolution.tsv\"),\n",
    "    out=os.path.join(settings.dataset_dir, \"promoters_for_evolution.zarr\"),\n",
    "    seq_col=\"sequence\",\n",
    "    fixed_length=False,\n",
    "    batch_size=310,\n",
    "    overwrite=True\n",
    ")\n",
    "pp.ohe_seqs_sdata(sdata_evolve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evolve them using the best model across 10 rounds\n",
    "interpret.evolve_seqs_sdata(\n",
    "    model,\n",
    "    sdata_evolve,\n",
    "    rounds=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of scores at different rounds of evolution\n",
    "ax = pl.violinplot(\n",
    "    sdata_evolve,\n",
    "    groupby=[\"original_score\", \"evolved_3_score\", \"evolved_5_score\", \"evolved_10_score\"],\n",
    "    xlabel=\"Evolution Round\",\n",
    "    ylabel=\"Score\",\n",
    "    color = \"lightblue\",\n",
    "    return_axes=True,\n",
    ")\n",
    "ax.set_ylim(-3.5, 13)\n",
    "plt.savefig(os.path.join(settings.figure_dir, name, f\"{name}_best_model_evolution_summary.pdf\"), dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write out the evolved sequences and their scores (along with the original sequences)\n",
    "sd.to_zarr(sdata_evolve, os.path.join(settings.output_dir, name, f\"jores21_{name}_evolved_sequences.zarr\"), load_first=True, mode=\"w\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Positional GIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reread in the evolved sequences and their scores\n",
    "sdata_evolve = sd.open_zarr(os.path.join(settings.output_dir, name, f\"{name}_evolved_sequences.zarr\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the motif\n",
    "motif_set = md.read_meme(os.path.join(settings.dataset_dir, \"CPEs.meme\"))\n",
    "motif = motif_set[\"TATA\"]\n",
    "feat_name = motif.name\n",
    "pfm = motif.pfm\n",
    "consensus = motif.consensus\n",
    "consensus_ohe = sp.ohe(consensus, alphabet=sp.alphabets.DNA)\n",
    "\n",
    "# Generate some baseline sequences\n",
    "zero_pfm = np.zeros(pfm.shape)\n",
    "rand_pfm = sp.ohe(sp.random_seq(pfm.shape[0]), alphabet=sp.alphabets.DNA)\n",
    "shuffled_pfm = sp.ohe(sp.k_shuffle(consensus, k=1).tobytes().decode(), alphabet=sp.alphabets.DNA)\n",
    "zero_pfm.shape, rand_pfm.shape, shuffled_pfm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slide the TATA motif across the sequences\n",
    "interpret.positional_gia_sdata(\n",
    "    model,\n",
    "    sdata_evolve,\n",
    "    seq_key=\"ohe_seq\",\n",
    "    id_key=\"name\",\n",
    "    feature=consensus_ohe,\n",
    "    feature_name=feat_name,\n",
    "    encoding=\"onehot\",\n",
    "    store_key=f\"slide_{feat_name}\",\n",
    ")\n",
    "\n",
    "# Slide a random seq across the sequences\n",
    "interpret.positional_gia_sdata(\n",
    "    model,\n",
    "    sdata_evolve,\n",
    "    seq_key=\"ohe_seq\",\n",
    "    id_key=\"name\",\n",
    "    feature=rand_pfm,\n",
    "    feature_name=\"random\",\n",
    "    encoding=\"onehot\",\n",
    "    store_key=f\"slide_random\",\n",
    ")\n",
    "\n",
    "# Slide a zero ohe seq across the sequences \n",
    "interpret.positional_gia_sdata(\n",
    "    model,\n",
    "    sdata_evolve,\n",
    "    seq_key=\"ohe_seq\",\n",
    "    id_key=\"name\",\n",
    "    feature=zero_pfm,\n",
    "    feature_name=\"zero\",\n",
    "    encoding=\"onehot\",\n",
    "    store_key=f\"slide_zero\",\n",
    ")\n",
    "\n",
    "# Slide a TATA shuffled ohe seq across the sequences\n",
    "interpret.positional_gia_sdata(\n",
    "    model,\n",
    "    sdata_evolve,\n",
    "    seq_key=\"ohe_seq\",\n",
    "    id_key=\"name\",\n",
    "    feature=shuffled_pfm,\n",
    "    feature_name=\"shuffled\",\n",
    "    encoding=\"onehot\",\n",
    "    store_key=f\"slide_shuffled\",\n",
    ")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check the average percentage increase across the sequences and positions\n",
    "mean_original = sdata_evolve[\"original_score\"].values.mean()\n",
    "avg_increase = np.mean(np.subtract(sdata_evolve[\"slide_TATA\"].values, np.expand_dims(sdata_evolve[\"original_score\"].values, axis=1)), axis=1)\n",
    "(avg_increase.mean()/mean_original).mean()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a line plot\n",
    "pl.positional_gia_plot(\n",
    "    sdata_evolve,\n",
    "    keys=[f\"slide_{feat_name}\", \"slide_shuffled\", \"slide_zero\", \"slide_random\"],\n",
    "    id_key=\"name\",\n",
    "    save=os.path.join(settings.figure_dir, name, f\"{name}_best_model_feature_implant_TATA.pdf\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the evolved sequences  with the TATA implanted scores as well\n",
    "sd.to_zarr(sdata_evolve, os.path.join(settings.output_dir, name, f\"{name}_evolved_sequences_with_TATA_implant.zarr\"), load_first=True, mode=\"w\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DONE!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd.open_zarr(os.path.join(settings.output_dir, name, f\"jores21_{name}_test_predictions_and_interpretations.zarr\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd.open_zarr(os.path.join(settings.output_dir, name, f\"jores21_{name}_evolved_sequences.zarr\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 ml4gland",
   "language": "python",
   "name": "ml4gland"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
