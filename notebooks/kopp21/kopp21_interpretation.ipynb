{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kopp et al 2021 Intepretation\n",
    "**Authorship:**\n",
    "Adam Klie (last updated: *06/10/2023*)\n",
    "***\n",
    "**Description:**\n",
    "Notebook to interpret the best trained models on the Kopp et al (2021) dataset.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# General imports\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import torch\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# EUGENe imports and settings\n",
    "import eugene as eu\n",
    "from eugene import preprocess as pp\n",
    "from eugene import models\n",
    "from eugene import interpret\n",
    "from eugene import plot as pl\n",
    "from eugene import settings\n",
    "settings.dataset_dir = \"/cellar/users/aklie/data/eugene/revision/kopp21\"\n",
    "settings.config_dir = \"/cellar/users/aklie/projects/ML4GLand/EUGENe_paper/configs/kopp21\"\n",
    "settings.output_dir = \"/cellar/users/aklie/projects/ML4GLand/EUGENe_paper/output/revision/kopp21/\"\n",
    "settings.logging_dir = \"/cellar/users/aklie/projects/ML4GLand/EUGENe_paper/logs/revision/kopp21\"\n",
    "settings.figure_dir = \"/cellar/users/aklie/projects/ML4GLand/EUGENe_paper/figures/revision/kopp21\"\n",
    "\n",
    "# EUGENe packages\n",
    "import seqdata as sd\n",
    "import motifdata as md\n",
    "import seqpro as sp\n",
    "\n",
    "# For illustrator editing\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "# Print versions\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Xarray version: {xr.__version__}\")\n",
    "print(f\"Eugene version: {eu.__version__}\")\n",
    "print(f\"SeqData version: {sd.__version__}\")\n",
    "print(f\"MotifData version: {md.__version__}\")\n",
    "print(f\"SeqPro version: {sp.__version__}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in the test `SeqData`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read in the predictions \n",
    "sdata_test = sd.open_zarr(os.path.join(settings.output_dir, \"test_predictions_all.zarr\")).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give the sequences a unique ID\n",
    "sdata_test[\"id\"] = sdata_test[\"chrom\"] + \":\" + sdata_test[\"chromStart\"].astype(str) + \"-\" + sdata_test[\"chromEnd\"].astype(str)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the model type and trial\n",
    "model_type = \"dsfcn\"\n",
    "trial = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load up the model form the checkpoint\n",
    "model_file = glob.glob(os.path.join(settings.logging_dir, f\"{model_type}\", f\"trial_{trial}\", \"checkpoints\", \"*\"))[0]\n",
    "model_arch = models.load_config(config_path=f\"{model_type}.yaml\")\n",
    "model = models.SequenceModule.load_from_checkpoint(model_file, arch=model_arch.arch)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature attribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run GradientShap with a simple all 0s reference\n",
    "method = \"GradientShap\"\n",
    "interpret.attribute_sdata(\n",
    "    model,\n",
    "    sdata_test,\n",
    "    method=method,\n",
    "    batch_size=128,\n",
    "    reference_type=\"zero\",\n",
    "    transforms={\"ohe_seq\": lambda x: torch.tensor(x, dtype=torch.float32).permute(0, 2, 1)}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the reverse complement of the one-hot encoded sequence\n",
    "sdata_test[\"rc_ohe_seq\"] = sp.reverse_complement(sdata_test[\"ohe_seq\"], sp.alphabets.DNA, length_axis=1, ohe_axis=2)\n",
    "interpret.attribute_sdata(\n",
    "    model,\n",
    "    sdata_test,\n",
    "    method=method,\n",
    "    batch_size=128,\n",
    "    reference_type=\"zero\",\n",
    "    seq_var=\"rc_ohe_seq\",\n",
    "    transforms={\"rc_ohe_seq\": lambda x: torch.tensor(x, dtype=torch.float32).permute(0, 2, 1)},\n",
    "    suffix=\"_rc\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the top 10 predicted sequences, identify the positions where we see significant attribution signal\n",
    "top10 = sdata_test[f\"{model_type}_trial_{trial}_target_predictions\"].to_series().sort_values(ascending=False).iloc[:10].index\n",
    "top10_idx = np.argsort(sdata_test[f\"{model_type}_trial_{trial}_target_predictions\"].values)[::-1][:10]\n",
    "ids = sdata_test[\"id\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a test sequence\n",
    "pl.seq_track(\n",
    "    sdata_test,\n",
    "    seq_id=ids[top10[0]],\n",
    "    attrs_var=\"GradientShap_attrs\",\n",
    "    ylab=\"GradientShap Forward\",\n",
    "    figsize=(18, 3),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the rev comp\n",
    "pl.seq_track(\n",
    "    sdata_test,\n",
    "    seq_id=ids[top10[0]],\n",
    "    attrs_var=\"GradientShap_attrs_rc\",\n",
    "    ylab=\"GradientShap Reverse\",\n",
    "    figsize=(18, 3),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter viz (only for convnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "if model_type == \"kopp21_cnn\":\n",
    "    model.to(\"cuda\")\n",
    "    layer_name = \"arch.conv\"\n",
    "    layer = models.get_layer(model, layer_name)\n",
    "    seqs = sdata_test[\"ohe_seq\"].transpose(\"_sequence\", \"_ohe\", \"length\").to_numpy()\n",
    "    seqs_torch = torch.tensor(seqs, dtype=torch.float32).to(model.device)\n",
    "    activations = F.relu(layer(seqs_torch)).detach().cpu().numpy()\n",
    "    transforms = None\n",
    "elif \"ds\" in model_type:\n",
    "    model.to(\"cuda\")\n",
    "    layer_name = \"arch.conv1d_tower.layers.0\"\n",
    "    layer = models.get_layer(model, layer_name)\n",
    "    seqs = sdata_test[\"ohe_seq\"].transpose(\"_sequence\", \"_ohe\", \"length\").to_numpy()\n",
    "    seqs_torch = torch.tensor(seqs, dtype=torch.float32).to(model.device)\n",
    "    activations = F.relu(layer(seqs_torch)).detach().cpu().numpy()\n",
    "    transforms = None\n",
    "else:\n",
    "    layer_name = \"arch.conv1d_tower.layers.1\"\n",
    "    transforms = {\"ohe_seq\": lambda x: torch.tensor(x, dtype=torch.float32).permute(0, 2, 1)}\n",
    "    activations = None\n",
    "    seqs = None\n",
    "kernel_size = 11\n",
    "num_filters = 10\n",
    "num_seqlets = 100\n",
    "layer_name, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate pfms from filters\n",
    "interpret.generate_pfms_sdata(\n",
    "    model,\n",
    "    sdata_test,\n",
    "    seq_var=\"ohe_seq\",\n",
    "    layer_name=layer_name,\n",
    "    activations=activations,\n",
    "    seqs=seqs,\n",
    "    kernel_size=11,\n",
    "    num_filters=10,\n",
    "    num_seqlets=100,\n",
    "    transforms=transforms,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all the filters for the current model\n",
    "pl.multifilter_viz(\n",
    "    sdata_test,\n",
    "    filter_nums=range(0, 10),\n",
    "    pfms_var=f\"{layer_name}_pfms\",\n",
    "    num_rows=2,\n",
    "    num_cols=5,\n",
    "    figsize=(10, 3),\n",
    "    titles=[f\"filter {i}\" for i in range(0, 10)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save all the filter pfms from above as meme format for submission to TomTom\n",
    "interpret.filters_to_meme_sdata(\n",
    "    sdata_test,\n",
    "    filters_var=f\"{layer_name}_pfms\", \n",
    "    axis_order=(f\"_{layer_name}_10_filters\", \"_ohe\", f\"_{layer_name}_11_kernel_size\"),\n",
    "    output_dir=os.path.join(settings.output_dir, model_type),\n",
    "    filename=f\"best_model_{model_type}_filters.meme\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the predictions and interpretations to zarr\n",
    "sd.to_zarr(sdata_test, os.path.join(settings.output_dir, model_type, f\"test_predictions_and_interpretations.zarr\"), mode=\"w\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In silico interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prep feature from meme file\n",
    "meme = md.read_meme(os.path.join(settings.dataset_dir, \"MA0491.1.meme\"))\n",
    "motif = meme.motifs[\"MA0491.1\"]\n",
    "feat_name = motif.name\n",
    "pfm = motif.pfm\n",
    "consensus = motif.consensus\n",
    "consensus_ohe = sp.ohe(consensus, sp.alphabets.DNA)\n",
    "pfm.shape, consensus_ohe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get some background sequences\n",
    "zero_pfm = np.zeros(pfm.shape)\n",
    "rand_pfm = sp.ohe(sp.random_seq(pfm.shape[0]), alphabet=sp.alphabets.DNA)\n",
    "shuffled_pfm = sp.ohe(sp.k_shuffle(consensus, k=1).tobytes().decode(), alphabet=sp.alphabets.DNA)\n",
    "zero_pfm.shape, rand_pfm.shape, shuffled_pfm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random seqs to implant into\n",
    "random_seqs = sp.ohe(sp.random_seqs(10, 500), alphabet=sp.alphabets.DNA).transpose(0, 2, 1)\n",
    "sdata_implant = xr.Dataset({\"ohe_seq\": xr.DataArray(random_seqs, dims=(\"_sequence\", \"_ohe\", \"length\"))})\n",
    "pp.make_unique_ids_sdata(sdata_implant, id_var=\"name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slide the JUND motif across the sequences\n",
    "interpret.positional_gia_sdata(\n",
    "    model,\n",
    "    sdata_implant,\n",
    "    seq_var=\"ohe_seq\",\n",
    "    id_var=\"name\",\n",
    "    feature=consensus_ohe,\n",
    "    feature_name=feat_name,\n",
    "    encoding=\"onehot\",\n",
    "    store_var=f\"slide_{feat_name}\",\n",
    ")\n",
    "\n",
    "# Slide a random seq across the sequences\n",
    "interpret.positional_gia_sdata(\n",
    "    model,\n",
    "    sdata_implant,\n",
    "    seq_var=\"ohe_seq\",\n",
    "    id_var=\"name\",\n",
    "    feature=rand_pfm,\n",
    "    feature_name=\"random\",\n",
    "    encoding=\"onehot\",\n",
    "    store_var=f\"slide_random\",\n",
    ")\n",
    "\n",
    "# Slide a zero ohe seq across the sequences \n",
    "interpret.positional_gia_sdata(\n",
    "    model,\n",
    "    sdata_implant,\n",
    "    seq_var=\"ohe_seq\",\n",
    "    id_var=\"name\",\n",
    "    feature=zero_pfm,\n",
    "    feature_name=\"zero\",\n",
    "    encoding=\"onehot\",\n",
    "    store_var=f\"slide_zero\",\n",
    ")\n",
    "\n",
    "# Slide a TATA shuffled ohe seq across the sequences\n",
    "interpret.positional_gia_sdata(\n",
    "    model,\n",
    "    sdata_implant,\n",
    "    seq_var=\"ohe_seq\",\n",
    "    id_var=\"name\",\n",
    "    feature=shuffled_pfm,\n",
    "    feature_name=\"shuffled\",\n",
    "    encoding=\"onehot\",\n",
    "    store_var=f\"slide_shuffled\",\n",
    ")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the original predictions values\n",
    "orig_preds = model.predict(torch.tensor(sdata_implant[\"ohe_seq\"].values, dtype=torch.float32).to(model.device)).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "np.min(orig_preds), np.max(orig_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the implanted scores across positions\n",
    "ax = pl.positional_gia_plot(\n",
    "    sdata_implant,\n",
    "    vars=[f\"slide_{feat_name}\", \"slide_shuffled\", \"slide_zero\", \"slide_random\"],\n",
    "    id_var=\"name\",\n",
    "    save=os.path.join(eu.settings.figure_dir, model_type, f\"best_{model_type}_model_feature_implant_jund.pdf\"),\n",
    "    ylim=(-4.5, 4.2),\n",
    "    return_axes=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the original scores for the sequences\n",
    "plt.boxplot(orig_preds)\n",
    "plt.ylim(-4.5, 4.2)\n",
    "plt.savefig(os.path.join(eu.settings.figure_dir, model_type, f\"best_{model_type}_model_random_seq_scores.pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the evolved sequences  with the TATA implanted scores as well\n",
    "sd.to_zarr(sdata_implant, os.path.join(settings.output_dir, model_type, f\"implant_JUND_{model_type}.zarr\"), mode=\"w\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DONE!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 ml4gland",
   "language": "python",
   "name": "ml4gland"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
